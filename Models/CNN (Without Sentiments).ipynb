{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lm0MUSM5y8v"
   },
   "outputs": [],
   "source": [
    "# import io \n",
    "# from google.colab import drive\n",
    "# drive.mount('drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Skj0BrN57gT"
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3A7ctC06Gew"
   },
   "outputs": [],
   "source": [
    "import ta\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sleoPEBg-iNz"
   },
   "source": [
    "# Utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxSFcFuh-uND"
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install winsound (cannot since it is running on linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPQBh3Pw-aBm"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions\n",
    "\"\"\"\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ta.momentum import *\n",
    "from ta.trend import *\n",
    "from ta.volume import *\n",
    "from ta.others import *\n",
    "from ta.volatility import *\n",
    "from tqdm.auto import tqdm\n",
    "from stockstats import StockDataFrame as sdf\n",
    "from ta import *\n",
    "from matplotlib import pyplot as plt\n",
    "# import winsound\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQrh1iGc-d64"
   },
   "outputs": [],
   "source": [
    "def seconds_to_minutes(seconds):\n",
    "    return str(seconds // 60) + \" minutes \" + str(np.round(seconds % 60)) + \" seconds\"\n",
    "\n",
    "\n",
    "def print_time(text, stime):\n",
    "    seconds = (time.time() - stime)\n",
    "    print(text, seconds_to_minutes(seconds))\n",
    "\n",
    "\n",
    "def get_readable_ctime():\n",
    "    return time.strftime(\"%d-%m-%Y %H_%M_%S\")\n",
    "\n",
    "\n",
    "def download_save(url, path_to_save, logger=None):\n",
    "    if logger:\n",
    "        logger.append_log(\"Starting download \" + re.sub(r'apikey=[A-Za-z0-9]+&', 'apikey=my_api_key&', url))\n",
    "    else:\n",
    "        print(\"Starting download \" + re.sub(r'apikey=[A-Za-z0-9]+&', 'apikey=my_api_key&', url))\n",
    "    urllib.request.urlretrieve(url, path_to_save)\n",
    "    if logger:\n",
    "        logger.append_log(path_to_save + \" downloaded and saved\")\n",
    "    else:\n",
    "        print(path_to_save + \" downloaded and saved\")\n",
    "\n",
    "\n",
    "def remove_dir(path):\n",
    "    shutil.rmtree(path)\n",
    "    print(path, \"deleted\")\n",
    "    # os.rmdir(path)\n",
    "\n",
    "\n",
    "def save_array_as_images(x, img_width, img_height, path, file_names):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        print(\"deleted old files\")\n",
    "\n",
    "    os.makedirs(path)\n",
    "    print(\"Image Directory created\", path)\n",
    "    x_temp = np.zeros((len(x), img_height, img_width))\n",
    "    print(\"saving images...\")\n",
    "    stime = time.time()\n",
    "    for i in tqdm(range(x.shape[0])):\n",
    "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
    "        img = Image.fromarray(x_temp[i], 'RGB')\n",
    "        img.save(os.path.join(path, str(file_names[i]) + '.png'))\n",
    "\n",
    "    print_time(\"Images saved at \" + path, stime)\n",
    "    return x_temp\n",
    "\n",
    "\n",
    "def reshape_as_image(x, img_width, img_height):\n",
    "    x_temp = np.zeros((len(x), img_height, img_width))\n",
    "    for i in range(x.shape[0]):\n",
    "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
    "\n",
    "    return x_temp\n",
    "\n",
    "\n",
    "def show_images(rows, columns, path):\n",
    "    w = 15\n",
    "    h = 15\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    files = os.listdir(path)\n",
    "    for i in range(1, columns * rows + 1):\n",
    "        index = np.random.randint(len(files))\n",
    "        img = np.asarray(Image.open(os.path.join(path, files[index])))\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.title(files[i], fontsize=10)\n",
    "        plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def dict_to_str(d):\n",
    "    return str(d).replace(\"{\", '').replace(\"}\", '').replace(\"'\", \"\").replace(' ', '')\n",
    "\n",
    "\n",
    "def cleanup_file_path(path):\n",
    "    return path.replace('\\\\', '/').replace(\" \", \"_\").replace(':', '_')\n",
    "\n",
    "\n",
    "def white_noise_check(tags_list, logger=None, *pd_series_args):\n",
    "    if len(tags_list) != len(pd_series_args):\n",
    "        raise Exception(\"Length of tags_list and series params different. Should be same.\")\n",
    "    for idx, s in enumerate(pd_series_args):\n",
    "        # logger.append_log(\"1st, 2nd element {}, {}\".format(s.iloc[0], s.iloc[1]))\n",
    "        m = s.mean()\n",
    "        std = s.std()\n",
    "        logger.append_log(\"mean & std for {} is {}, {}\".format(tags_list[idx], m, std))\n",
    "\n",
    "\n",
    "def plot(y, title, output_path, x=None):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    # x = x if x is not None else np.arange(len(y))\n",
    "    plt.title(title)\n",
    "    if x is not None:\n",
    "        plt.plot(x, y, 'o-')\n",
    "    else:\n",
    "        plt.plot(y, 'o-')\n",
    "        plt.savefig(output_path)\n",
    "\n",
    "\n",
    "def col1_gt_col2(col1, col2, df):\n",
    "    compare_series = df[col1] > df[col2]\n",
    "    print(df.iloc[compare_series[compare_series == True].index])\n",
    "\n",
    "\n",
    "# def sound_alert(repeat_count=5):\n",
    "#     duration = 1000  # millisecond\n",
    "#     freq = 440  # Hz\n",
    "#     for i in range(0, repeat_count):\n",
    "#         winsound.Beep(freq, duration)\n",
    "#         time.sleep(1)\n",
    "\n",
    "\n",
    "def console_pretty_print_df(df):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(df)\n",
    "\n",
    "\n",
    "############### Technical indicators ########################\n",
    "\n",
    "\n",
    "# not used\n",
    "def get_RSI(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    stockstats lib seems to use 'close' column by default so col_name\n",
    "    not used here.\n",
    "    This calculates non-smoothed RSI\n",
    "    \"\"\"\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in intervals:\n",
    "        df['rsi_' + str(i)] = df_ss['rsi_' + str(i)]\n",
    "\n",
    "        del df['close_-1_s']\n",
    "        del df['close_-1_d']\n",
    "        del df['rs_' + str(i)]\n",
    "\n",
    "        df['rsi_' + str(intervals[0])] = rsi(df['close'], i, fillna=True)\n",
    "    print(\"RSI with stockstats done\")\n",
    "\n",
    "\n",
    "def get_RSI_smooth(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Momentum indicator\n",
    "    As per https://www.investopedia.com/terms/r/rsi.asp\n",
    "    RSI_1 = 100 - (100/ (1 + (avg gain% / avg loss%) ) )\n",
    "    RSI_2 = 100 - (100/ (1 + (prev_avg_gain*13+avg gain% / prev_avg_loss*13 + avg loss%) ) )\n",
    "    E.g. if period==6, first RSI starts from 7th index because difference of first row is NA\n",
    "    http://cns.bu.edu/~gsc/CN710/fincast/Technical%20_indicators/Relative%20Strength%20Index%20(RSI).htm\n",
    "    https://school.stockcharts.com/doku.php?id=technical_indicators:relative_strength_index_rsi\n",
    "    Verified!\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Calculating RSI\")\n",
    "    stime = time.time()\n",
    "    prev_rsi = np.inf\n",
    "    prev_avg_gain = np.inf\n",
    "    prev_avg_loss = np.inf\n",
    "    rolling_count = 0\n",
    "\n",
    "    def calculate_RSI(series, period):\n",
    "        # nonlocal rolling_count\n",
    "        nonlocal prev_avg_gain\n",
    "        nonlocal prev_avg_loss\n",
    "        nonlocal rolling_count\n",
    "\n",
    "        # num_gains = (series >= 0).sum()\n",
    "        # num_losses = (series < 0).sum()\n",
    "        # sum_gains = series[series >= 0].sum()\n",
    "        # sum_losses = np.abs(series[series < 0].sum())\n",
    "        curr_gains = series.where(series >= 0, 0)  # replace 0 where series not > 0\n",
    "        curr_losses = np.abs(series.where(series < 0, 0))\n",
    "        avg_gain = curr_gains.sum() / period  # * 100\n",
    "        avg_loss = curr_losses.sum() / period  # * 100\n",
    "        rsi = -1\n",
    "\n",
    "        if rolling_count == 0:\n",
    "            # first RSI calculation\n",
    "            rsi = 100 - (100 / (1 + (avg_gain / avg_loss)))\n",
    "            # print(rolling_count,\"rs1=\",rs, rsi)\n",
    "        else:\n",
    "            # smoothed RSI\n",
    "            # current gain and loss should be used, not avg_gain & avg_loss\n",
    "            rsi = 100 - (100 / (1 + ((prev_avg_gain * (period - 1) + curr_gains.iloc[-1]) /\n",
    "                                     (prev_avg_loss * (period - 1) + curr_losses.iloc[-1]))))\n",
    "            # print(rolling_count,\"rs2=\",rs, rsi)\n",
    "\n",
    "        # df['rsi_'+str(period)+'_own'][period + rolling_count] = rsi\n",
    "        rolling_count = rolling_count + 1\n",
    "        prev_avg_gain = avg_gain\n",
    "        prev_avg_loss = avg_loss\n",
    "        return rsi\n",
    "\n",
    "    diff = df[col_name].diff()[1:]  # skip na\n",
    "    for period in tqdm(intervals):\n",
    "        df['rsi_' + str(period)] = np.nan\n",
    "        # df['rsi_'+str(period)+'_own_1'] = np.nan\n",
    "        rolling_count = 0\n",
    "        res = diff.rolling(period).apply(calculate_RSI, args=(period,), raw=False)\n",
    "        df['rsi_' + str(period)][1:] = res\n",
    "\n",
    "    # df.drop(['diff'], axis = 1, inplace=True)\n",
    "    print_time(\"Calculation of RSI Done\", stime)\n",
    "\n",
    "\n",
    "# not used: +1, ready to use\n",
    "def get_IBR(df):\n",
    "    return (df['close'] - df['low']) / (df['high'] - df['low'])\n",
    "\n",
    "\n",
    "def get_williamR(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    both libs gave same result\n",
    "    Momentum indicator\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating WilliamR\")\n",
    "    # df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        # df['wr_'+str(i)] = df_ss['wr_'+str(i)]\n",
    "        df[\"wr_\" + str(i)] = wr(df['high'], df['low'], df['close'], i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of WilliamR Done\", stime)\n",
    "\n",
    "\n",
    "def get_mfi(df, intervals):\n",
    "    \"\"\"\n",
    "    momentum type indicator\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.time()\n",
    "    print(\"Calculating MFI\")\n",
    "    for i in tqdm(intervals):\n",
    "        df['mfi_' + str(i)] = money_flow_index(df['high'], df['low'], df['close'], df['volume'], n=i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of MFI done\", stime)\n",
    "\n",
    "\n",
    "def get_SMA(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Momentum indicator\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating SMA\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        df[col_name + '_sma_' + str(i)] = df_ss[col_name + '_' + str(i) + '_sma']\n",
    "        del df[col_name + '_' + str(i) + '_sma']\n",
    "\n",
    "    print_time(\"Calculation of SMA Done\", stime)\n",
    "\n",
    "\n",
    "def get_EMA(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Needs validation\n",
    "    Momentum indicator\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating EMA\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        df['ema_' + str(i)] = df_ss[col_name + '_' + str(i) + '_ema']\n",
    "        del df[col_name + '_' + str(i) + '_ema']\n",
    "        # df[\"ema_\"+str(intervals[0])+'_1'] = ema_indicator(df['close'], i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of EMA Done\", stime)\n",
    "\n",
    "\n",
    "def get_WMA(df, col_name, intervals, hma_step=0):\n",
    "    \"\"\"\n",
    "    Momentum indicator\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    if (hma_step == 0):\n",
    "        # don't show progress for internal WMA calculation for HMA\n",
    "        print(\"Calculating WMA\")\n",
    "\n",
    "    def wavg(rolling_prices, period):\n",
    "        weights = pd.Series(range(1, period + 1))\n",
    "        return np.multiply(rolling_prices.values, weights.values).sum() / weights.sum()\n",
    "\n",
    "    temp_col_count_dict = {}\n",
    "    for i in tqdm(intervals, disable=(hma_step != 0)):\n",
    "        res = df[col_name].rolling(i).apply(wavg, args=(i,), raw=False)\n",
    "        # print(\"interval {} has unique values {}\".format(i, res.unique()))\n",
    "        if hma_step == 0:\n",
    "            df['wma_' + str(i)] = res\n",
    "        elif hma_step == 1:\n",
    "            if 'hma_wma_' + str(i) in temp_col_count_dict.keys():\n",
    "                temp_col_count_dict['hma_wma_' + str(i)] = temp_col_count_dict['hma_wma_' + str(i)] + 1\n",
    "            else:\n",
    "                temp_col_count_dict['hma_wma_' + str(i)] = 0\n",
    "            # after halving the periods and rounding, there may be two intervals with same value e.g.\n",
    "            # 2.6 & 2.8 both would lead to same value (3) after rounding. So save as diff columns\n",
    "            df['hma_wma_' + str(i) + '_' + str(temp_col_count_dict['hma_wma_' + str(i)])] = 2 * res\n",
    "        elif hma_step == 3:\n",
    "            import re\n",
    "            expr = r\"^hma_[0-9]{1}\"\n",
    "            columns = list(df.columns)\n",
    "            # print(\"searching\", expr, \"in\", columns, \"res=\", list(filter(re.compile(expr).search, columns)))\n",
    "            df['hma_' + str(len(list(filter(re.compile(expr).search, columns))))] = res\n",
    "\n",
    "    if hma_step == 0:\n",
    "        print_time(\"Calculation of WMA Done\", stime)\n",
    "\n",
    "\n",
    "def get_HMA(df, col_name, intervals):\n",
    "    import re\n",
    "    stime = time.time()\n",
    "    print(\"Calculating HMA\")\n",
    "    expr = r\"^wma_.*\"\n",
    "\n",
    "    if len(list(filter(re.compile(expr).search, list(df.columns)))) > 0:\n",
    "        print(\"WMA calculated already. Proceed with HMA\")\n",
    "    else:\n",
    "        print(\"Need WMA first...\")\n",
    "        get_WMA(df, col_name, intervals)\n",
    "\n",
    "    intervals_half = np.round([i / 2 for i in intervals]).astype(int)\n",
    "\n",
    "    # step 1 = WMA for interval/2\n",
    "    # this creates cols with prefix 'hma_wma_*'\n",
    "    get_WMA(df, col_name, intervals_half, 1)\n",
    "    # print(\"step 1 done\", list(df.columns))\n",
    "\n",
    "    # step 2 = step 1 - WMA\n",
    "    columns = list(df.columns)\n",
    "    expr = r\"^hma_wma.*\"\n",
    "    hma_wma_cols = list(filter(re.compile(expr).search, columns))\n",
    "    rest_cols = [x for x in columns if x not in hma_wma_cols]\n",
    "    expr = r\"^wma.*\"\n",
    "    wma_cols = list(filter(re.compile(expr).search, rest_cols))\n",
    "\n",
    "    df[hma_wma_cols] = df[hma_wma_cols].sub(df[wma_cols].values,\n",
    "                                            fill_value=0)  # .rename(index=str, columns={\"close\": \"col1\", \"rsi_6\": \"col2\"})\n",
    "    # df[0:10].copy().reset_index(drop=True).merge(temp.reset_index(drop=True), left_index=True, right_index=True)\n",
    "\n",
    "    # step 3 = WMA(step 2, interval = sqrt(n))\n",
    "    intervals_sqrt = np.round([np.sqrt(i) for i in intervals]).astype(int)\n",
    "    for i, col in tqdm(enumerate(hma_wma_cols)):\n",
    "        # print(\"step 3\", col, intervals_sqrt[i])\n",
    "        get_WMA(df, col, [intervals_sqrt[i]], 3)\n",
    "    df.drop(columns=hma_wma_cols, inplace=True)\n",
    "    print_time(\"Calculation of HMA Done\", stime)\n",
    "\n",
    "\n",
    "def get_TRIX(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    TA lib actually calculates percent rate of change of a triple exponentially\n",
    "    smoothed moving average not Triple EMA.\n",
    "    Momentum indicator\n",
    "    Need validation!\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating TRIX\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        # df['trix_'+str(i)] = df_ss['trix_'+str(i)+'_sma']\n",
    "        df['trix_' + str(i)] = trix(df['close'], i, fillna=True)\n",
    "\n",
    "    # df.drop(columns=['trix','trix_6_sma',])\n",
    "    print_time(\"Calculation of TRIX Done\", stime)\n",
    "\n",
    "\n",
    "def get_DMI(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    trend indicator\n",
    "    TA gave same/wrong result\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating DMI\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        # df['dmi_'+str(i)] = adx(df['high'], df['low'], df['close'], n=i, fillna=True)\n",
    "        df['dmi_' + str(i)] = df_ss['adx_' + str(i) + '_ema']\n",
    "\n",
    "    drop_columns = ['high_delta', 'um', 'low_delta', 'dm', 'pdm', 'pdm_14_ema', 'pdm_14',\n",
    "                    'close_-1_s', 'tr', 'tr_14_smma', 'atr_14']\n",
    "    # drop_columns = ['high_delta', 'um', 'low_delta', 'dm', 'pdm', 'pdm_14_ema',\n",
    "    #                 'pdm_14', 'close_-1_s', 'tr', 'atr_14', 'pdi_14', 'pdi',\n",
    "    #                 'mdm', 'mdm_14_ema', 'mdm_14', 'mdi_14', 'mdi', 'dx_14',\n",
    "    #                 'dx', 'adx', 'adxr']\n",
    "    expr1 = r'dx_\\d+_ema'\n",
    "    expr2 = r'adx_\\d+_ema'\n",
    "    import re\n",
    "    drop_columns.extend(list(filter(re.compile(expr1).search, list(df.columns)[9:])))\n",
    "    drop_columns.extend(list(filter(re.compile(expr2).search, list(df.columns)[9:])))\n",
    "    df.drop(columns=drop_columns, inplace=True)\n",
    "    print_time(\"Calculation of DMI done\", stime)\n",
    "\n",
    "\n",
    "def get_CCI(df, col_name, intervals):\n",
    "    stime = time.time()\n",
    "    print(\"Calculating CCI\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        # df['cci_'+str(i)] = df_ss['cci_'+str(i)]\n",
    "        df['cci_' + str(i)] = cci(df['high'], df['low'], df['close'], i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of CCI Done\", stime)\n",
    "\n",
    "\n",
    "def get_BB_MAV(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    volitility indicator\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.time()\n",
    "    print(\"Calculating Bollinger Band MAV\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        df['bb_' + str(i)] = bollinger_mavg(df['close'], n=i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of Bollinger Band MAV done\", stime)\n",
    "\n",
    "\n",
    "def get_CMO(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Chande Momentum Oscillator\n",
    "    As per https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/cmo\n",
    "    CMO = 100 * ((Sum(ups) - Sum(downs))/ ( (Sum(ups) + Sum(downs) ) )\n",
    "    range = +100 to -100\n",
    "    params: df -> dataframe with financial instrument history\n",
    "            col_name -> column name for which CMO is to be calculated\n",
    "            intervals -> list of periods for which to calculated\n",
    "    return: None (adds the result in a column)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Calculating CMO\")\n",
    "    stime = time.time()\n",
    "\n",
    "    def calculate_CMO(series, period):\n",
    "        # num_gains = (series >= 0).sum()\n",
    "        # num_losses = (series < 0).sum()\n",
    "        sum_gains = series[series >= 0].sum()\n",
    "        sum_losses = np.abs(series[series < 0].sum())\n",
    "        cmo = 100 * ((sum_gains - sum_losses) / (sum_gains + sum_losses))\n",
    "        return np.round(cmo, 3)\n",
    "\n",
    "    diff = df[col_name].diff()[1:]  # skip na\n",
    "    for period in tqdm(intervals):\n",
    "        df['cmo_' + str(period)] = np.nan\n",
    "        res = diff.rolling(period).apply(calculate_CMO, args=(period,), raw=False)\n",
    "        df['cmo_' + str(period)][1:] = res\n",
    "\n",
    "    print_time(\"Calculation of CMO Done\", stime)\n",
    "\n",
    "\n",
    "# not used. on close(12,16): +3, ready to use\n",
    "def get_MACD(df):\n",
    "    \"\"\"\n",
    "    Not used\n",
    "    Same for both\n",
    "    calculated for same 12 and 26 periods on close only!! Not different periods.\n",
    "    creates colums macd, macds, macdh\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating MACD\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    df['macd'] = df_ss['macd']\n",
    "    # df['macd_'+str(i)] = macd(df['close'], fillna=True)\n",
    "\n",
    "    del df['macd_']\n",
    "    del df['close_12_ema']\n",
    "    del df['close_26_ema']\n",
    "    print_time(\"Calculation of MACD done\", stime)\n",
    "\n",
    "\n",
    "# not implemented. period 12,26: +1, ready to use\n",
    "def get_PPO(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    As per https://www.investopedia.com/terms/p/ppo.asp\n",
    "    uses EMA(12) and EMA(26) to calculate PPO value\n",
    "    params: df -> dataframe with financial instrument history\n",
    "            col_name -> column name for which CMO is to be calculated\n",
    "            intervals -> list of periods for which to calculated\n",
    "    return: None (adds the result in a column)\n",
    "    calculated for same 12 and 26 periods only!!\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating PPO\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    df['ema_' + str(12)] = df_ss[col_name + '_' + str(12) + '_ema']\n",
    "    del df['close_' + str(12) + '_ema']\n",
    "    df['ema_' + str(26)] = df_ss[col_name + '_' + str(26) + '_ema']\n",
    "    del df['close_' + str(26) + '_ema']\n",
    "    df['ppo'] = ((df['ema_12'] - df['ema_26']) / df['ema_26']) * 100\n",
    "\n",
    "    del df['ema_12']\n",
    "    del df['ema_26']\n",
    "\n",
    "    print_time(\"Calculation of PPO Done\", stime)\n",
    "\n",
    "\n",
    "def get_ROC(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Momentum oscillator\n",
    "    As per implement https://www.investopedia.com/terms/p/pricerateofchange.asp\n",
    "    https://school.stockcharts.com/doku.php?id=technical_indicators:rate_of_change_roc_and_momentum\n",
    "    ROC = (close_price_n - close_price_(n-1) )/close_price_(n-1) * 100\n",
    "    params: df -> dataframe with financial instrument history\n",
    "            col_name -> column name for which CMO is to be calculated\n",
    "            intervals -> list of periods for which to calculated\n",
    "    return: None (adds the result in a column)\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating ROC\")\n",
    "\n",
    "    def calculate_roc(series, period):\n",
    "        return ((series.iloc[-1] - series.iloc[0]) / series.iloc[0]) * 100\n",
    "\n",
    "    for period in intervals:\n",
    "        df['roc_' + str(period)] = np.nan\n",
    "        # for 12 day period, 13th day price - 1st day price\n",
    "        res = df['close'].rolling(period + 1).apply(calculate_roc, args=(period,), raw=False)\n",
    "        # print(len(df), len(df[period:]), len(res))\n",
    "        df['roc_' + str(period)] = res\n",
    "\n",
    "    print_time(\"Calculation of ROC done\", stime)\n",
    "\n",
    "\n",
    "# not implemented, can't find\n",
    "def get_PSI(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    TODO implement\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_DPO(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Trend Oscillator type indicator\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.time()\n",
    "    print(\"Calculating DPO\")\n",
    "    for i in tqdm(intervals):\n",
    "        df['dpo_' + str(i)] = dpo(df['close'], n=i)\n",
    "\n",
    "    print_time(\"Calculation of DPO done\", stime)\n",
    "\n",
    "\n",
    "def get_kst(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    Trend Oscillator type indicator\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.time()\n",
    "    print(\"Calculating KST\")\n",
    "    for i in tqdm(intervals):\n",
    "        df['kst_' + str(i)] = kst(df['close'], i)\n",
    "\n",
    "    print_time(\"Calculation of KST done\", stime)\n",
    "\n",
    "\n",
    "def get_CMF(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    An oscillator type indicator & volume type\n",
    "    No other implementation found\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating CMF\")\n",
    "    for i in tqdm(intervals):\n",
    "        df['cmf_' + str(i)] = chaikin_money_flow(df['high'], df['low'], df['close'], df['volume'], i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of CMF done\", stime)\n",
    "\n",
    "\n",
    "def get_force_index(df, intervals):\n",
    "    stime = time.time()\n",
    "    print(\"Calculating Force Index\")\n",
    "    for i in tqdm(intervals):\n",
    "        df['fi_' + str(i)] = force_index(df['close'], df['volume'], 5, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of Force Index done\", stime)\n",
    "\n",
    "\n",
    "def get_EOM(df, col_name, intervals):\n",
    "    \"\"\"\n",
    "    An Oscillator type indicator and volume type\n",
    "    Ease of Movement : https://www.investopedia.com/terms/e/easeofmovement.asp\n",
    "    \"\"\"\n",
    "    stime = time.time()\n",
    "    print(\"Calculating EOM\")\n",
    "    for i in tqdm(intervals):\n",
    "        df['eom_' + str(i)] = ease_of_movement(df['high'], df['low'], df['volume'], n=i, fillna=True)\n",
    "\n",
    "    print_time(\"Calculation of EOM done\", stime)\n",
    "\n",
    "\n",
    "# not used. +1\n",
    "def get_volume_delta(df):\n",
    "    stime = time.time()\n",
    "    print(\"Calculating volume delta\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    df_ss['volume_delta']\n",
    "\n",
    "    print_time(\"Calculation of Volume Delta done\", stime)\n",
    "\n",
    "\n",
    "# not used. +2 for each interval kdjk and rsv\n",
    "def get_kdjk_rsv(df, intervals):\n",
    "    stime = time.time()\n",
    "    print(\"Calculating KDJK, RSV\")\n",
    "    df_ss = sdf.retype(df)\n",
    "    for i in tqdm(intervals):\n",
    "        df['kdjk_' + str(i)] = df_ss['kdjk_' + str(i)]\n",
    "\n",
    "    print_time(\"Calculation of EMA Done\", stime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mxJ1uTV-Xhx"
   },
   "source": [
    "# Logger.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QMfJUbW-Npt"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import threading\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nN_YUCfZAm4f"
   },
   "outputs": [],
   "source": [
    "class Logger:\n",
    "\n",
    "\tLOG_QUEUE_SIZE = 50\n",
    "\n",
    "\tdef __init__(self, log_file_path=\"/content/drive/My Drive/Colab Notebooks/inputs/\", log_file_name_prefix=\"nasdaq\", log_queue_size=LOG_QUEUE_SIZE):\n",
    "\t\tif not os.path.exists(log_file_path):\n",
    "\t\t\tos.makedirs(log_file_path)\n",
    "\t\tLOG_QUEUE_SIZE = log_queue_size\n",
    "\t\tself.LOGGING_LEVELS = {0: \"INFO\", 1: \"DEBUG\", 2: \"WARN\", 3: \"ERROR\", 4: \"CRITICAL\"}\n",
    "\t\tself.init_file_writing(log_file_path, log_file_name_prefix)\n",
    "\n",
    "\tdef init_file_writing(self, LOG_PATH, LOG_FILE_NAME_PREFIX):\n",
    "\t\tself.file_path = self.cleanup_file_path(LOG_PATH+os.sep+LOG_FILE_NAME_PREFIX+\n",
    "\t\t\t\"_\"+self.get_readable_ctime()+\".log\")\n",
    "\t\tself.log_queue = deque([])\n",
    "\t\tself.append_log(\"Initialized logging at path {}\".format(self.file_path), self.LOGGING_LEVELS[0])\n",
    "\n",
    "\tdef cleanup_file_path(self, path):\n",
    "\t\treturn path.replace('\\\\', '/').replace(\" \", \"_\").replace(':', '_')\n",
    "\n",
    "\tdef get_log_prefix_format(self, level=None):\n",
    "\t\tlevel = self.LOGGING_LEVELS[1] if level is None else level\n",
    "\t\treturn \" \".join([self.get_readable_ctime(), threading.current_thread().name, level])\n",
    "\n",
    "\tdef append_log(self, text, level=None):\n",
    "\t\tlevel = self.LOGGING_LEVELS[1] if level is None else level\n",
    "\t\tlog_str = self.get_log_prefix_format(level)+r\"\\ \"+text\n",
    "\t\tself.log_queue.append(log_str)\n",
    "\t\tprint(len(self.log_queue), \")\",log_str)\n",
    "\t\tif len(self.log_queue) >= self.LOG_QUEUE_SIZE:\n",
    "\t\t\tlog_file = open(self.cleanup_file_path(self.file_path), \"a+\")\n",
    "\t\t\twhile len(self.log_queue) > 0:\n",
    "\t\t\t\tlog_file.write(self.log_queue.popleft()+\"\\n\")\n",
    "\n",
    "\t\t\tlog_file.close()\n",
    "\t\t\tprint(\"logs written...\")\t\n",
    "\n",
    "\tdef flush(self):\n",
    "\t\tprint(\"test\", (self.cleanup_file_path(self.file_path)))\n",
    "\t\tlog_file = open(self.cleanup_file_path(self.file_path), \"a+\")\n",
    "\t\twhile len(self.log_queue) > 0:\n",
    "\t\t\tlog_file.write(self.log_queue.popleft()+\"\\n\")\n",
    "\n",
    "\t\tlog_file.close()\n",
    "\t\tprint(\"logs flushed...\")\n",
    "\n",
    "\tdef get_readable_ctime(self):\n",
    "\t\treturn time.strftime(\"%d-%m-%Y %H_%M_%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmJB6-oY6VUW"
   },
   "source": [
    "# Defining Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ND8Tgyw58X5Z",
    "outputId": "2b3fd6fc-45e6-4b1a-c162-3bffd22d495a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install logger\n",
    "# !pip install python-secrets\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "9ofHdiDE6-ic",
    "outputId": "1e8fd97e-d020-45aa-877e-5c9fe4000909"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>4366.799805</td>\n",
       "      <td>4440.490234</td>\n",
       "      <td>4344.490234</td>\n",
       "      <td>4422.500000</td>\n",
       "      <td>4422.500000</td>\n",
       "      <td>1983570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>4424.790039</td>\n",
       "      <td>4440.009766</td>\n",
       "      <td>4419.839844</td>\n",
       "      <td>4426.819824</td>\n",
       "      <td>4426.819824</td>\n",
       "      <td>1674970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-20</td>\n",
       "      <td>4468.290039</td>\n",
       "      <td>4478.680176</td>\n",
       "      <td>4456.410156</td>\n",
       "      <td>4458.540039</td>\n",
       "      <td>4458.540039</td>\n",
       "      <td>2825670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-23</td>\n",
       "      <td>4454.149902</td>\n",
       "      <td>4466.339844</td>\n",
       "      <td>4445.520020</td>\n",
       "      <td>4445.540039</td>\n",
       "      <td>4445.540039</td>\n",
       "      <td>1608880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-24</td>\n",
       "      <td>4444.390137</td>\n",
       "      <td>4467.790039</td>\n",
       "      <td>4430.970215</td>\n",
       "      <td>4430.990234</td>\n",
       "      <td>4430.990234</td>\n",
       "      <td>1611670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>8166.259766</td>\n",
       "      <td>8224.730469</td>\n",
       "      <td>7900.990234</td>\n",
       "      <td>8006.120117</td>\n",
       "      <td>8006.120117</td>\n",
       "      <td>4273890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>7452.759766</td>\n",
       "      <td>7808.310059</td>\n",
       "      <td>7255.620117</td>\n",
       "      <td>7263.649902</td>\n",
       "      <td>7263.649902</td>\n",
       "      <td>5066530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>7683.040039</td>\n",
       "      <td>7998.509766</td>\n",
       "      <td>7301.879883</td>\n",
       "      <td>7995.259766</td>\n",
       "      <td>7995.259766</td>\n",
       "      <td>4685890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>7502.259766</td>\n",
       "      <td>7563.450195</td>\n",
       "      <td>6993.609863</td>\n",
       "      <td>7020.379883</td>\n",
       "      <td>7020.379883</td>\n",
       "      <td>4594360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>7198.529785</td>\n",
       "      <td>7550.129883</td>\n",
       "      <td>6959.149902</td>\n",
       "      <td>7473.950195</td>\n",
       "      <td>7473.950195</td>\n",
       "      <td>4900000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp         open  ...    adj close      volume\n",
       "0     2015-03-18  4366.799805  ...  4422.500000  1983570000\n",
       "1     2015-03-19  4424.790039  ...  4426.819824  1674970000\n",
       "2     2015-03-20  4468.290039  ...  4458.540039  2825670000\n",
       "3     2015-03-23  4454.149902  ...  4445.540039  1608880000\n",
       "4     2015-03-24  4444.390137  ...  4430.990234  1611670000\n",
       "...          ...          ...  ...          ...         ...\n",
       "1254  2020-03-11  8166.259766  ...  8006.120117  4273890000\n",
       "1255  2020-03-12  7452.759766  ...  7263.649902  5066530000\n",
       "1256  2020-03-13  7683.040039  ...  7995.259766  4685890000\n",
       "1257  2020-03-16  7502.259766  ...  7020.379883  4594360000\n",
       "1258  2020-03-17  7198.529785  ...  7473.950195  4900000000\n",
       "\n",
       "[1259 rows x 7 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/inputs/nasdaq.csv')\n",
    "# sentiments = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/ML_sentiments.csv')\n",
    "# sentiments_groupby = sentiments.groupby(['pub_date'], as_index = False)['polarity'].agg(sum)\n",
    "# sentiments_groupby.columns = ['Date', 'polarity']\n",
    "# df = pd.merge(df, sentiments_groupby, how = 'left', on = ['Date'])\n",
    "df = df.rename(columns={\"Date\": \"timestamp\"})\n",
    "df.columns = map(str.lower, df.columns)\n",
    "display(df)\n",
    "df.to_csv('/content/drive/My Drive/Colab Notebooks/inputs/NASDAQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMpVY1I07zqQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tqdm.auto import tqdm\n",
    "# from logger import Logger\n",
    "# from secrets import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGJN8bD08USZ"
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, company_code=\"NASDAQ\", data_path='/content/drive/My Drive/Colab Notebooks/inputs/', output_path='/content/drive/My Drive/Colab Notebooks/inputs/', strategy_type='original',\n",
    "                 update=False, logger: Logger = None):\n",
    "        self.company_code = company_code\n",
    "        self.strategy_type = strategy_type\n",
    "        self.data_path = data_path\n",
    "        self.logger = Logger()\n",
    "        # self.BASE_URL = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED\" \\\n",
    "                        # \"&outputsize=full&apikey=\" + api_key + \"&datatype=csv&symbol=\"  # api key from alpha vantage service\n",
    "        self.output_path = output_path\n",
    "        self.start_col = 'open'\n",
    "        self.end_col = 'eom_26'\n",
    "        self.update = update\n",
    "        self.download_stock_data()\n",
    "        self.df = self.create_features()\n",
    "        self.feat_idx = self.feature_selection()\n",
    "        self.one_hot_enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "        self.one_hot_enc.fit(self.df['labels'].values.reshape(-1, 1))\n",
    "        self.batch_start_date = self.df.head(1).iloc[0][\"timestamp\"]\n",
    "        self.test_duration_years = 1\n",
    "        self.logger.append_log(\"{} has data for {} to {}\".format(data_path, self.batch_start_date,\n",
    "                                                                 self.df.tail(1).iloc[0]['timestamp']))\n",
    "\n",
    "    def log(self, text):\n",
    "        if self.logger:\n",
    "            self.logger.append_log(text)\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "    def download_stock_data(self):\n",
    "        path_to_company_data = self.data_path\n",
    "        print(\"path to company data:\", path_to_company_data)\n",
    "        parent_path = os.sep.join(path_to_company_data.split(os.sep)[:-1])\n",
    "        if not os.path.exists(parent_path):\n",
    "            os.makedirs(parent_path)\n",
    "            print(\"Company Directory created\", parent_path)\n",
    "\n",
    "        if not os.path.exists(path_to_company_data):\n",
    "            self.log(\"Downloading \" + self.company_code + \" data\")\n",
    "            download_save(self.BASE_URL + self.company_code, path_to_company_data, self.logger)\n",
    "        else:\n",
    "            self.log(\"Data for \" + self.company_code + \" ready to use\")\n",
    "\n",
    "    def calculate_technical_indicators(self, df, col_name, intervals):\n",
    "        # get_RSI(df, col_name, intervals)  # faster but non-smoothed RSI\n",
    "        get_RSI_smooth(df, col_name, intervals)  # momentum\n",
    "        get_williamR(df, col_name, intervals)  # momentum\n",
    "        get_mfi(df, intervals)  # momentum\n",
    "        # get_MACD(df, col_name, intervals)  # momentum, ready to use +3\n",
    "        # get_PPO(df, col_name, intervals)  # momentum, ready to use +1\n",
    "        get_ROC(df, col_name, intervals)  # momentum\n",
    "        get_CMF(df, col_name, intervals)  # momentum, volume EMA\n",
    "        get_CMO(df, col_name, intervals)  # momentum\n",
    "        get_SMA(df, col_name, intervals)\n",
    "        get_SMA(df, 'open', intervals)\n",
    "        get_EMA(df, col_name, intervals)\n",
    "        get_WMA(df, col_name, intervals)\n",
    "        get_HMA(df, col_name, intervals)\n",
    "        get_TRIX(df, col_name, intervals)  # trend\n",
    "        get_CCI(df, col_name, intervals)  # trend\n",
    "        get_DPO(df, col_name, intervals)  # Trend oscillator\n",
    "        get_kst(df, col_name, intervals)  # Trend\n",
    "        get_DMI(df, col_name, intervals)  # trend\n",
    "        get_BB_MAV(df, col_name, intervals)  # volatility\n",
    "        # get_PSI(df, col_name, intervals)  # can't find formula\n",
    "        get_force_index(df, intervals)  # volume\n",
    "        get_kdjk_rsv(df, intervals)  # ready to use, +2*len(intervals), 2 rows\n",
    "        get_EOM(df, col_name, intervals)  # volume momentum\n",
    "        get_volume_delta(df)  # volume +1\n",
    "        get_IBR(df)  # ready to use +1\n",
    "\n",
    "    def create_labels(self, df, col_name, window_size=11):\n",
    "        \"\"\"\n",
    "        Data is labeled as per the logic in research paper\n",
    "        Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "        params :\n",
    "            df => Dataframe with data\n",
    "            col_name => name of column which should be used to determine strategy\n",
    "        returns : numpy array with integer codes for labels with\n",
    "                  size = total-(window_size)+1\n",
    "        \"\"\"\n",
    "\n",
    "        self.log(\"creating label with original paper strategy\")\n",
    "        row_counter = 0\n",
    "        total_rows = len(df)\n",
    "        labels = np.zeros(total_rows)\n",
    "        labels[:] = np.nan\n",
    "        print(\"Calculating labels\")\n",
    "        pbar = tqdm(total=total_rows)\n",
    "\n",
    "        while row_counter < total_rows:\n",
    "            if row_counter >= window_size - 1:\n",
    "                window_begin = row_counter - (window_size - 1)\n",
    "                window_end = row_counter\n",
    "                window_middle = (window_begin + window_end) / 2\n",
    "\n",
    "                min_ = np.inf\n",
    "                min_index = -1\n",
    "                max_ = -np.inf\n",
    "                max_index = -1\n",
    "                for i in range(window_begin, window_end + 1):\n",
    "                    price = df.iloc[i][col_name]\n",
    "                    if price < min_:\n",
    "                        min_ = price\n",
    "                        min_index = i\n",
    "                    if price > max_:\n",
    "                        max_ = price\n",
    "                        max_index = i\n",
    "\n",
    "                if max_index == window_middle:\n",
    "                    labels[row_counter] = 0\n",
    "                elif min_index == window_middle:\n",
    "                    labels[row_counter] = 1\n",
    "                else:\n",
    "                    labels[row_counter] = 2\n",
    "\n",
    "            row_counter = row_counter + 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        return labels\n",
    "\n",
    "    def create_labels_price_rise(self, df, col_name):\n",
    "        \"\"\"\n",
    "        labels data based on price rise on next day\n",
    "          next_day - prev_day\n",
    "        ((s - s.shift()) > 0).astype(np.int)\n",
    "        \"\"\"\n",
    "\n",
    "        df[\"labels\"] = ((df[col_name] - df[col_name].shift()) > 0).astype(np.int)\n",
    "        df = df[1:]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def create_label_mean_reversion(self, df, col_name):\n",
    "        \"\"\"\n",
    "        strategy as described at \"https://decodingmarkets.com/mean-reversion-trading-strategy\"\n",
    "        Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "        params :\n",
    "            df => Dataframe with data\n",
    "            col_name => name of column which should be used to determine strategy\n",
    "        returns : numpy array with integer codes for labels\n",
    "        \"\"\"\n",
    "\n",
    "        self.log(\"creating labels with mean mean-reversion-trading-strategy\")\n",
    "        get_RSI_smooth(df, col_name, [3])  # new column 'rsi_3' added to df\n",
    "        rsi_3_series = df['rsi_3']\n",
    "        ibr = get_IBR(df)\n",
    "        total_rows = len(df)\n",
    "        labels = np.zeros(total_rows)\n",
    "        labels[:] = np.nan\n",
    "        count = 0\n",
    "        for i, rsi_3 in enumerate(rsi_3_series):\n",
    "            if rsi_3 < 15:  # buy\n",
    "                count = count + 1\n",
    "\n",
    "                if 3 <= count < 8 and ibr.iloc[i] < 0.2:  # TODO implement upto 5 BUYS\n",
    "                    labels[i] = 1\n",
    "\n",
    "                if count >= 8:\n",
    "                    count == 0\n",
    "            elif ibr.iloc[i] > 0.7:  # sell\n",
    "                labels[i] = 0\n",
    "            else:\n",
    "                labels[i] = 2\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def create_label_short_long_ma_crossover(self, df, col_name, short, long):\n",
    "        \"\"\"\n",
    "        if short = 30 and long = 90,\n",
    "        Buy when 30 day MA < 90 day MA\n",
    "        Sell when 30 day MA > 90 day MA\n",
    "        Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "        params :\n",
    "            df => Dataframe with data\n",
    "            col_name => name of column which should be used to determine strategy\n",
    "        returns : numpy array with integer codes for labels\n",
    "        \"\"\"\n",
    "\n",
    "        self.log(\"creating label with {}_{}_ma\".format(short, long))\n",
    "\n",
    "        def detect_crossover(diff_prev, diff):\n",
    "            if diff_prev >= 0 > diff:\n",
    "                # buy\n",
    "                return 1\n",
    "            elif diff_prev <= 0 < diff:\n",
    "                return 0\n",
    "            else:\n",
    "                return 2\n",
    "\n",
    "        get_SMA(df, 'close', [short, long])\n",
    "        labels = np.zeros((len(df)))\n",
    "        labels[:] = np.nan\n",
    "        diff = df['close_sma_' + str(short)] - df['close_sma_' + str(long)]\n",
    "        diff_prev = diff.shift()\n",
    "        df['diff_prev'] = diff_prev\n",
    "        df['diff'] = diff\n",
    "\n",
    "        res = df.apply(lambda row: detect_crossover(row['diff_prev'], row['diff']), axis=1)\n",
    "        print(\"labels count\", np.unique(res, return_counts=True))\n",
    "        df.drop(columns=['diff_prev', 'diff'], inplace=True)\n",
    "        return res\n",
    "\n",
    "    def create_features(self):\n",
    "        if not os.path.exists(os.path.join(self.output_path, self.company_code+\".csv\")) or self.update:\n",
    "            df = pd.read_csv(self.data_path, engine='python')\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.sort_values('timestamp', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            intervals = range(6, 27)  # 21\n",
    "            self.calculate_technical_indicators(df, 'close', intervals)\n",
    "            self.log(\"Saving dataframe...\")\n",
    "            df.to_csv(os.path.join(self.output_path, \"df_\" + self.company_code+\".csv\"), index=False)\n",
    "        else:\n",
    "            self.log(\"Technical indicators already calculated. Loading...\")\n",
    "            df = pd.read_csv(os.path.join(self.output_path, self.company_code+\".csv\"))\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.sort_values('timestamp', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            intervals = range(6, 27)  # 21\n",
    "            self.calculate_technical_indicators(df, 'close', intervals)\n",
    "            self.log(\"Saving dataframe...\")\n",
    "            df.to_csv(os.path.join(self.output_path, \"df_\" + self.company_code+\".csv\"), index=False)\n",
    "            # pickle.load(open(os.path.join(self.output_path, \"df_\" + self.company_code), \"rb\"))\n",
    "\n",
    "        prev_len = len(df)\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        self.logger.append_log(\"Dropped {0} nan rows before label calculation\".format(prev_len - len(df)))\n",
    "\n",
    "        if 'labels' not in df.columns or self.update:\n",
    "            if re.match(r\"\\d+_\\d+_ma\", self.strategy_type):\n",
    "                short = self.strategy_type.split('_')[0]\n",
    "                long = self.strategy_type.split('_')[1]\n",
    "                df['labels'] = self.create_label_short_long_ma_crossover(df, 'close', short, long)\n",
    "            else:\n",
    "                df['labels'] = self.create_labels(df, 'close')\n",
    "\n",
    "            prev_len = len(df)\n",
    "            df.dropna(inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            self.logger.append_log(\"Dropped {0} nan rows after label calculation\".format(prev_len - len(df)))\n",
    "            # df.drop(columns=['dividend_amount', 'split_coefficient'], inplace=True)\n",
    "            df.to_csv(os.path.join(self.output_path, \"df_\" + self.company_code + \".csv\"), index=False)\n",
    "        else:\n",
    "            print(\"labels already calculated\")\n",
    "\n",
    "        # pickle.dump(df, open(os.path.join(self.output_path, \"df_\" + self.company_code), 'wb'))\n",
    "        # console_pretty_print_df(df.head())\n",
    "        self.log(\"Number of Technical indicator columns for train/test are {}\".format(len(list(df.columns)[7:])))\n",
    "        display(df)\n",
    "        return df\n",
    "\n",
    "    def feature_selection(self):\n",
    "        df_batch = self.df_by_date(None, 10)\n",
    "        list_features = list(df_batch.loc[:, self.start_col:self.end_col].columns)\n",
    "        mm_scaler = MinMaxScaler(feature_range=(0, 1))  # or StandardScaler?\n",
    "        x_train = mm_scaler.fit_transform(df_batch.loc[:, self.start_col:self.end_col].values)\n",
    "        y_train = df_batch['labels'].values\n",
    "        num_features = 225  # should be a perfect square\n",
    "        topk = 350\n",
    "        select_k_best = SelectKBest(f_classif, k=topk)\n",
    "        select_k_best.fit(x_train, y_train)\n",
    "        selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "\n",
    "        select_k_best = SelectKBest(mutual_info_classif, k=topk)\n",
    "        select_k_best.fit(x_train, y_train)\n",
    "        selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "\n",
    "        common = list(set(selected_features_anova).intersection(selected_features_mic))\n",
    "        self.log(\"common selected featues:\" + str(len(common)) + \", \" + str(common))\n",
    "        if len(common) < num_features:\n",
    "            raise Exception(\n",
    "                'number of common features found {} < {} required features. Increase \"topK\"'.format(len(common),\n",
    "                                                                                                    num_features))\n",
    "        feat_idx = []\n",
    "        for c in common:\n",
    "            feat_idx.append(list_features.index(c))\n",
    "        feat_idx = sorted(feat_idx[0:225])\n",
    "        self.log(str(feat_idx))\n",
    "        return feat_idx\n",
    "\n",
    "    def df_by_date(self, start_date=None, years=5):\n",
    "        if not start_date:\n",
    "            start_date = self.df.head(1).iloc[0][\"timestamp\"]\n",
    "\n",
    "        end_date = start_date + pd.offsets.DateOffset(years=years)\n",
    "        df_batch = self.df[(self.df[\"timestamp\"] >= start_date) & (self.df[\"timestamp\"] <= end_date)]\n",
    "        return df_batch\n",
    "\n",
    "    def get_data(self, start_date=None, years=5):\n",
    "        df_batch = self.df_by_date(start_date, years)\n",
    "        x = df_batch.loc[:, self.start_col:self.end_col].values\n",
    "        x = x[:, self.feat_idx]\n",
    "        mm_scaler = MinMaxScaler(feature_range=(0, 1))  # or StandardScaler?\n",
    "        x = mm_scaler.fit_transform(x)\n",
    "        dim = int(np.sqrt(x.shape[1]))\n",
    "        x = reshape_as_image(x, dim, dim)\n",
    "        x = np.stack((x,) * 3, axis=-1)\n",
    "\n",
    "        y = df_batch['labels'].values\n",
    "        sample_weights = self.get_sample_weights(y)\n",
    "        y = self.one_hot_enc.transform(y.reshape(-1, 1))\n",
    "\n",
    "        return x, y, df_batch, sample_weights\n",
    "\n",
    "    def get_sample_weights(self, y):\n",
    "        \"\"\"\n",
    "        calculate the sample weights based on class weights. Used for models with\n",
    "        imbalanced data and one hot encoding prediction.\n",
    "        params:\n",
    "            y: class labels as integers\n",
    "        \"\"\"\n",
    "\n",
    "        y = y.astype(int)  # compute_class_weight needs int labels\n",
    "        class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "        print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
    "        print(\"value_counts\", np.unique(y, return_counts=True))\n",
    "        sample_weights = y.copy().astype(float)\n",
    "        for i in np.unique(y):\n",
    "            sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
    "            # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
    "\n",
    "        return sample_weights\n",
    "\n",
    "    def get_rolling_data_next(self, start_date=None, window_size_yrs=6, cross_val_split=0.2):\n",
    "        if not start_date:\n",
    "            start_date = self.batch_start_date\n",
    "\n",
    "        x_train, y_train, df_batch_train, sample_weights = self.get_data(start_date, window_size_yrs)\n",
    "        train_end_date = df_batch_train.tail(1).iloc[0][\"timestamp\"]\n",
    "        test_start_date = train_end_date + pd.offsets.DateOffset(days=1)\n",
    "        test_end_date = test_start_date + pd.offsets.DateOffset(years=self.test_duration_years)\n",
    "        x_test, y_test, df_batch_test, _ = self.get_data(test_start_date, self.test_duration_years)\n",
    "        x_train, x_cv, y_train, y_cv, sample_weights, _ = train_test_split(x_train, y_train, sample_weights,\n",
    "                                                                           train_size=1 - cross_val_split,\n",
    "                                                                           test_size=cross_val_split,\n",
    "                                                                           random_state=2, shuffle=True,\n",
    "                                                                           stratify=y_train)\n",
    "        self.logger.append_log(\"data generated: train duration={}-{}, test_duration={}-{}, size={}, {}, {}\".format(\n",
    "            self.batch_start_date, train_end_date, test_start_date, test_end_date, x_train.shape, x_cv.shape,\n",
    "            x_test.shape))\n",
    "\n",
    "        self.batch_start_date = self.batch_start_date + pd.offsets.DateOffset(years=1)\n",
    "        is_last_batch = False\n",
    "        if (self.df.tail(1).iloc[0][\"timestamp\"] - test_end_date).days < 180:  # 6 months\n",
    "            is_last_batch = True\n",
    "        return x_train, y_train, x_cv, y_cv, x_test, y_test, df_batch_train, df_batch_test, \\\n",
    "               sample_weights, is_last_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4a8acc6cc12d43afba1b2f8f38280be7",
      "71aff620da6c4fd1b430e1bb1bcb2d9d",
      "66b5bb6c6d844a96b419f83a600e382e",
      "7900c8adc13a4594853e10d2b6bac6a1",
      "09839334122342b5b4caa30b26ec5c0b",
      "65b127e3f63a4a55a310f48375ea47b6",
      "41db5c499d47415cba26b8697d5d625d",
      "d444b51aadf24fe6b6a81e0fece9020e",
      "a7305bcf024a4c27bab65de63e299d5e",
      "ef8be51b5d2b4ef7ba3bca2e4c8ca30f",
      "da318d4e4fcc4736a3aaf0f0a97a2965",
      "a93d077f01df4f83922d940ed1eb3205",
      "cd1baf459a004106a2a87ee5d73661fc",
      "97992ef125824d62847596a0fb2db05b",
      "e2a97501720d490293c1148277502dce",
      "01ae67cd0a9d4efeb2e20ed4a66c63d1",
      "650e5386dc14417f9e64362f2c25a29e",
      "69fd5dd6942d4a6a8af467e48fc46ffd",
      "27c60905265b459e8e3b46dab7ff84e5",
      "82a56e2fc3b744b1b8fae5b8cf616a92",
      "db5b59af5e6a4703843f95eeccce94ca",
      "bc14e06d73de49a6b606d8bc3dcd4109",
      "2fac6f0a80564d3494612eb1da4b633e",
      "43910c49210f4ca5bc76c40d1634eb85",
      "951abd488d5c4e4ebf62dcaab085caed",
      "2a1176d868254285ab0bcb5d81354ce0",
      "660c447a80bb480e81f36ab9df519215",
      "c843ad0c66e4438b9394cb8141047a15",
      "2edb4ad9554d4cae9c041447d9babedc",
      "60519771bbcf4e2cab050c747a6392e4",
      "89887da8a61943e1829ccb9059ff69a5",
      "326b756495a7458cb0977bc89b30f49a",
      "70af28b309c54e499d53894566baf071",
      "6d5427a4009f447a9e3e775351cc1ddb",
      "eed55ce024ec4defbcf75d9b45fa1646",
      "d62cde84a2994136a198c8399a2f8b60",
      "18a754719a0843e4989d90c3a81d6c00",
      "1eb035604fe243a0888e1a0809404021",
      "7c6c7ecf234544398a0c65a9343fe5e3",
      "a8169e8c3cee42178fd585eeaf16f240",
      "7a0bc724007845699743c67d8d1e931b",
      "0dc3fef18a95477999010b3d48d0cfed",
      "c27fa700103444ab85c4e7e743f82e67",
      "99fffc50683e4440bfc4f270918d90b6",
      "f005f01b4dc74a2ba012bacf349cd3b8",
      "6d3b7546ce3749e4a1d9df6dae725c14",
      "61a3c83016cb4def868ac7151b88d8a0",
      "e049d88fdd234c2c9ccb252dcf7f0e22",
      "6efc1ad12e664dfc874621537d50f012",
      "43b345adc4e24ed6be202f57d7cb937c",
      "352ea20759b14465a07d267e41239325",
      "cb1658bf31064250a6401ba5beeeb6c6",
      "0761d4f6f80b40a2b44c3a9d4a37c523",
      "0614912bc11e41afb3aaca59bb5bc897",
      "07c4ec4c40534ebc9f198b45ed4d401e",
      "f6197a270ca641bf874484983166d45f",
      "440c95fafd9b42669ec3b65b959718af",
      "519f2f50dfd64fe799859f21f901ab74",
      "9aa3ffdb566e42848fe407b4134690a9",
      "74b77a1585334c52ac9874fe24fe0ec4",
      "4865af1774de48b19a65d5885c9a7b0f",
      "74738398ade143c0af1bafcdd992c526",
      "9d996941a9de4f19a4734866a345df46",
      "574f64422d8a42d9b96fd0235f7b7f73",
      "7c81a66c1eaf473485ba1ed03668bf1a",
      "ae732ef2221541d7870f37e6ba7f3ebc",
      "a6b85d1d9f7a4e4a97ee5241c0d34de4",
      "712127d8a2f44648b33af907ee0a5369",
      "7040ecec65a94b0c99dbb3be68fba73c",
      "2aabe89dc7e74025bd11c35dcd2a58d9",
      "6bf28b23a2404a688b5209d8906fe37c",
      "32be88bb3e734feb849e0b9ab2122e08",
      "10890ed21887419d8eb2373dfe040e22",
      "4006080f11e94ef68ef60e242ff04f93",
      "3dd3ed71bbe94b10b160d51426455fd3",
      "2309c7a489be4cf993c546a8709328d3",
      "3dc71009ee4549bf8195d659becab687",
      "7e194c1e27f74fcaac53956b5c2d23f4",
      "9184d5bf77ef4c92b1a9d8f3dcd2698e",
      "de4dcebd102f4126a2b00ff7822c33b0",
      "fdb6a825d3024b3faa4f9283ee10bbdc",
      "8d58491d17cc4ccb8dc000febae4fafc",
      "762a0912d4b04be896cb1eefbced75ba",
      "c86e9997bd5d4549b1c578fb406fdb69",
      "8e0fae300fe54616996d7a8c57428113",
      "378f441ab6d143f2b2f871c5316a0509",
      "ec2c830161e6492eaba93c492a553e67",
      "1e2ede8aaf7d4e3ea914ea51d95e0d4d",
      "314d574139464c9e96c408113fc937a5",
      "f415406fb038471fb8acde6052aacd3b",
      "553596b1a8b14b42aa4824ba640dd342",
      "7d1213448dd04e0f9333c234868698d6",
      "51f1fc397e8549b58efc04b045a7a1af",
      "6af6f38653ce484aa528d7eebead2c98",
      "0ffd634a8ef047698c737716816db9d5",
      "9c1e874ab8aa4e10801bd7bb520b1402",
      "21ac5a39e8d74613a0b1cb7d54b1af6a",
      "22a17159740c4056b1f7bcd6c4986fe1",
      "c21ecb9244134ba9a755e70c4aa9ce60",
      "1de81f9a9af848f6ae47150d6abcd2a5",
      "dbafcbad760e46259c7547254fb40422",
      "2622d06ecacb465391ed302c213bb41d",
      "6aacb5769eba4da1877b24302eae253b",
      "83298fe3d4a94fe89cb2d893d69fdaf3",
      "8634a4e95d474ab6ac931a1c941f3093",
      "f2f0e9d99f3a4e22815fcc60409bfe1f",
      "5a02839558f34e1e803ed700d03e268f",
      "82588216b02f4bf9bfdae19b2d44309a",
      "eeabfba080444eeeb79027f4e6690ac7",
      "ca6314938bc34cf8934ffe02f5f66aab",
      "cdb2a58e1ab4448cb44dd97a586bc0fa",
      "622073b8d6bf45ad8e431cc911169547",
      "130cbf45f8d644d69e92450f8a7d641e",
      "aed49ef6598d4edf8ca15450c02f26fc",
      "e64fcb3239d0435cb451594180983a7b",
      "56fce9af36d24f36a4cc0ef76b070ea1",
      "a6d30f6bb3764891b430afa6fa0be4d5",
      "0696d9d321c84cb4852a979567f78d4c",
      "7578e5eb20384debad7a59896d236dfc",
      "f832020735bb43d6a473a1946dac2e7e",
      "9cfee08fa5bc43e09263c235ecf952ae",
      "830fec76a0234999aa45a3382b79dc84",
      "b572c9e1eac04a10918c8c9ef8e53b9d",
      "1fa09044523c4d12ba6f20b5341b7ffa",
      "6820314d5fdd421bbd0ab098ad7b6d97",
      "969b1dec7b384109bfd066f06fc7eb1f",
      "0c049603a126498eacf07207bda7ce0e",
      "0c030a196eb64c46981a10d3884895ed",
      "11c5c103a57d4527bf7e39b88e05d3b5",
      "aa3b8d2e6f2348eaab7d4ba077aba51a",
      "1a1ef815f6304e33a8484125e66c1781",
      "92c341bba3bd4dc2a492f5edca87c5f9",
      "2fe3bb50154f47c38e70f501563c4fa3",
      "f7b84e6242664454acaf9e0e695ad6af",
      "fe912619d71f4a8aaa0ef8eb6359fc1c",
      "9f99cc264b8e41cb8181e55830e18334",
      "75915d5d34a24b10a752a39acc104ab6",
      "2c41da071c8a4c59920b09161e004c24",
      "31e417dadc404936bc8a10f6aefec0b0",
      "d88ae53a0542444fa58c2c84fb2e6ba4",
      "3172522c8af24419a399bb17921b5074",
      "f82b4f2e1b404e7484a830a75fac2b3d",
      "e2352837cf6b4d9cba5da219b0ea9736",
      "f526180e0b9e43b9aa4f312c902d79a0",
      "f1e0c11a0670473a9370fc6b5969b02f",
      "2724e94a000743289da58c82f87c72fc",
      "e0ffd983779d4b96b5feead72ca0ced1",
      "55f311d50f9f470e8a67d04705ceb59c",
      "4f0f924547fb4400a7397fbd01a081b0",
      "6a1c811760fb4cbc853e2a16539a07ce",
      "2a5364d8c6e940c98b622dde8bfc6d3a",
      "970b943576584f54bfcb686b4351e8ba",
      "65a457b099714e32991c04b7cf3bd70e",
      "6c83d0e9abc74f448d2ed580bb0059ca",
      "b11da0d4cad242a389d97248988147de",
      "29a54a5ac7ec469385b8d4210ae5ca38",
      "060725c9a10049aca8828560223b771e",
      "b2209049bf3c4a8d8920c86f299acded",
      "e99b054546bc42929687aba29b675ed3",
      "653fbb0b52914a01829532f7a5e0859f"
     ]
    },
    "colab_type": "code",
    "id": "pLqfPoTnEjIq",
    "outputId": "97f32701-3b21-4382-def8-9a442282ac05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) 23-03-2020 10_49_15 MainThread INFO\\ Initialized logging at path /content/drive/My_Drive/Colab_Notebooks/inputs//nasdaq_23-03-2020_10_49_15.log\n",
      "path to company data: /content/drive/My Drive/Colab Notebooks/inputs/\n",
      "2 ) 23-03-2020 10_49_15 MainThread DEBUG\\ Data for NASDAQ ready to use\n",
      "3 ) 23-03-2020 10_49_15 MainThread DEBUG\\ Technical indicators already calculated. Loading...\n",
      "Calculating RSI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8acc6cc12d43afba1b2f8f38280be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of RSI Done 0.0 minutes 46.0 seconds\n",
      "Calculating WilliamR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7305bcf024a4c27bab65de63e299d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of WilliamR Done 0.0 minutes 0.0 seconds\n",
      "Calculating MFI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650e5386dc14417f9e64362f2c25a29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of MFI done 0.0 minutes 1.0 seconds\n",
      "Calculating ROC\n",
      "Calculation of ROC done 0.0 minutes 2.0 seconds\n",
      "Calculating CMF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951abd488d5c4e4ebf62dcaab085caed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of CMF done 0.0 minutes 0.0 seconds\n",
      "Calculating CMO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70af28b309c54e499d53894566baf071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:445: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of CMO Done 0.0 minutes 39.0 seconds\n",
      "Calculating SMA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0bc724007845699743c67d8d1e931b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of SMA Done 0.0 minutes 0.0 seconds\n",
      "Calculating SMA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efc1ad12e664dfc874621537d50f012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of SMA Done 0.0 minutes 0.0 seconds\n",
      "Calculating EMA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440c95fafd9b42669ec3b65b959718af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of EMA Done 0.0 minutes 0.0 seconds\n",
      "Calculating WMA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c81a66c1eaf473485ba1ed03668bf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of WMA Done 0.0 minutes 7.0 seconds\n",
      "Calculating HMA\n",
      "WMA calculated already. Proceed with HMA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10890ed21887419d8eb2373dfe040e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of HMA Done 0.0 minutes 15.0 seconds\n",
      "Calculating TRIX\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb6a825d3024b3faa4f9283ee10bbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of TRIX Done 0.0 minutes 0.0 seconds\n",
      "Calculating CCI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314d574139464c9e96c408113fc937a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of CCI Done 0.0 minutes 1.0 seconds\n",
      "Calculating DPO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ac5a39e8d74613a0b1cb7d54b1af6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of DPO done 0.0 minutes 0.0 seconds\n",
      "Calculating KST\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8634a4e95d474ab6ac931a1c941f3093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of KST done 0.0 minutes 0.0 seconds\n",
      "Calculating DMI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130cbf45f8d644d69e92450f8a7d641e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of DMI done 0.0 minutes 0.0 seconds\n",
      "Calculating Bollinger Band MAV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfee08fa5bc43e09263c235ecf952ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of Bollinger Band MAV done 0.0 minutes 0.0 seconds\n",
      "Calculating Force Index\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c5c103a57d4527bf7e39b88e05d3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of Force Index done 0.0 minutes 0.0 seconds\n",
      "Calculating KDJK, RSV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75915d5d34a24b10a752a39acc104ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of EMA Done 0.0 minutes 0.0 seconds\n",
      "Calculating EOM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e0c11a0670473a9370fc6b5969b02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of EOM done 0.0 minutes 0.0 seconds\n",
      "Calculating volume delta\n",
      "Calculation of Volume Delta done 0.0 minutes 0.0 seconds\n",
      "4 ) 23-03-2020 10_51_07 MainThread DEBUG\\ Saving dataframe...\n",
      "5 ) 23-03-2020 10_51_08 MainThread DEBUG\\ Dropped 26 nan rows before label calculation\n",
      "6 ) 23-03-2020 10_51_08 MainThread DEBUG\\ creating label with original paper strategy\n",
      "Calculating labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a457b099714e32991c04b7cf3bd70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1233), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 ) 23-03-2020 10_51_16 MainThread DEBUG\\ Dropped 10 nan rows after label calculation\n",
      "8 ) 23-03-2020 10_51_17 MainThread DEBUG\\ Number of Technical indicator columns for train/test are 444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi_6</th>\n",
       "      <th>rsi_7</th>\n",
       "      <th>rsi_8</th>\n",
       "      <th>rsi_9</th>\n",
       "      <th>rsi_10</th>\n",
       "      <th>rsi_11</th>\n",
       "      <th>rsi_12</th>\n",
       "      <th>rsi_13</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>rsi_15</th>\n",
       "      <th>rsi_16</th>\n",
       "      <th>rsi_17</th>\n",
       "      <th>rsi_18</th>\n",
       "      <th>rsi_19</th>\n",
       "      <th>rsi_20</th>\n",
       "      <th>rsi_21</th>\n",
       "      <th>rsi_22</th>\n",
       "      <th>rsi_23</th>\n",
       "      <th>rsi_24</th>\n",
       "      <th>rsi_25</th>\n",
       "      <th>rsi_26</th>\n",
       "      <th>wr_6</th>\n",
       "      <th>wr_7</th>\n",
       "      <th>wr_8</th>\n",
       "      <th>wr_9</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "      <th>wr_14</th>\n",
       "      <th>wr_15</th>\n",
       "      <th>wr_16</th>\n",
       "      <th>...</th>\n",
       "      <th>kdjk_18</th>\n",
       "      <th>rsv_19</th>\n",
       "      <th>kdjk_19</th>\n",
       "      <th>rsv_20</th>\n",
       "      <th>kdjk_20</th>\n",
       "      <th>rsv_21</th>\n",
       "      <th>kdjk_21</th>\n",
       "      <th>rsv_22</th>\n",
       "      <th>kdjk_22</th>\n",
       "      <th>rsv_23</th>\n",
       "      <th>kdjk_23</th>\n",
       "      <th>rsv_24</th>\n",
       "      <th>kdjk_24</th>\n",
       "      <th>rsv_25</th>\n",
       "      <th>kdjk_25</th>\n",
       "      <th>rsv_26</th>\n",
       "      <th>kdjk_26</th>\n",
       "      <th>eom_6</th>\n",
       "      <th>eom_7</th>\n",
       "      <th>eom_8</th>\n",
       "      <th>eom_9</th>\n",
       "      <th>eom_10</th>\n",
       "      <th>eom_11</th>\n",
       "      <th>eom_12</th>\n",
       "      <th>eom_13</th>\n",
       "      <th>eom_14</th>\n",
       "      <th>eom_15</th>\n",
       "      <th>eom_16</th>\n",
       "      <th>eom_17</th>\n",
       "      <th>eom_18</th>\n",
       "      <th>eom_19</th>\n",
       "      <th>eom_20</th>\n",
       "      <th>eom_21</th>\n",
       "      <th>eom_22</th>\n",
       "      <th>eom_23</th>\n",
       "      <th>eom_24</th>\n",
       "      <th>eom_25</th>\n",
       "      <th>eom_26</th>\n",
       "      <th>volume_delta</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>2015-05-08</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>4466.169922</td>\n",
       "      <td>4441.729980</td>\n",
       "      <td>4458.649902</td>\n",
       "      <td>4458.649902</td>\n",
       "      <td>1978760000</td>\n",
       "      <td>47.305031</td>\n",
       "      <td>43.469762</td>\n",
       "      <td>42.110781</td>\n",
       "      <td>40.653658</td>\n",
       "      <td>48.623734</td>\n",
       "      <td>50.390670</td>\n",
       "      <td>52.910416</td>\n",
       "      <td>54.630584</td>\n",
       "      <td>59.896629</td>\n",
       "      <td>53.490992</td>\n",
       "      <td>52.990289</td>\n",
       "      <td>54.886258</td>\n",
       "      <td>53.927442</td>\n",
       "      <td>52.906107</td>\n",
       "      <td>54.105923</td>\n",
       "      <td>55.854880</td>\n",
       "      <td>57.693214</td>\n",
       "      <td>57.168802</td>\n",
       "      <td>59.025927</td>\n",
       "      <td>59.261391</td>\n",
       "      <td>57.656967</td>\n",
       "      <td>-32.278747</td>\n",
       "      <td>-32.278747</td>\n",
       "      <td>-34.929379</td>\n",
       "      <td>-41.929342</td>\n",
       "      <td>-48.813665</td>\n",
       "      <td>-48.813665</td>\n",
       "      <td>-48.813665</td>\n",
       "      <td>-48.813665</td>\n",
       "      <td>-48.813665</td>\n",
       "      <td>-48.813665</td>\n",
       "      <td>-45.231690</td>\n",
       "      <td>...</td>\n",
       "      <td>44.123955</td>\n",
       "      <td>54.768310</td>\n",
       "      <td>44.446330</td>\n",
       "      <td>54.768310</td>\n",
       "      <td>44.710811</td>\n",
       "      <td>54.768310</td>\n",
       "      <td>45.109787</td>\n",
       "      <td>54.768310</td>\n",
       "      <td>46.267670</td>\n",
       "      <td>54.768310</td>\n",
       "      <td>48.341615</td>\n",
       "      <td>54.768310</td>\n",
       "      <td>51.101499</td>\n",
       "      <td>62.761222</td>\n",
       "      <td>53.782176</td>\n",
       "      <td>62.761222</td>\n",
       "      <td>53.795986</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>74.650219</td>\n",
       "      <td>-64200000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>2015-05-11</td>\n",
       "      <td>4457.620117</td>\n",
       "      <td>4468.750000</td>\n",
       "      <td>4437.529785</td>\n",
       "      <td>4438.640137</td>\n",
       "      <td>4438.640137</td>\n",
       "      <td>1731390000</td>\n",
       "      <td>53.718689</td>\n",
       "      <td>42.393471</td>\n",
       "      <td>39.373432</td>\n",
       "      <td>38.406842</td>\n",
       "      <td>37.292048</td>\n",
       "      <td>45.550911</td>\n",
       "      <td>47.450410</td>\n",
       "      <td>50.100245</td>\n",
       "      <td>51.918016</td>\n",
       "      <td>57.374868</td>\n",
       "      <td>51.430029</td>\n",
       "      <td>50.986752</td>\n",
       "      <td>52.934909</td>\n",
       "      <td>52.052245</td>\n",
       "      <td>51.107667</td>\n",
       "      <td>52.337244</td>\n",
       "      <td>54.122567</td>\n",
       "      <td>55.999484</td>\n",
       "      <td>55.511547</td>\n",
       "      <td>57.406009</td>\n",
       "      <td>57.652969</td>\n",
       "      <td>-44.742781</td>\n",
       "      <td>-44.742781</td>\n",
       "      <td>-44.742781</td>\n",
       "      <td>-46.905567</td>\n",
       "      <td>-52.617193</td>\n",
       "      <td>-58.234462</td>\n",
       "      <td>-58.234462</td>\n",
       "      <td>-58.234462</td>\n",
       "      <td>-58.234462</td>\n",
       "      <td>-58.234462</td>\n",
       "      <td>-58.234462</td>\n",
       "      <td>...</td>\n",
       "      <td>44.762242</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>44.977159</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>45.153479</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>45.419463</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>46.191385</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>47.574016</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>49.413938</td>\n",
       "      <td>46.038816</td>\n",
       "      <td>51.201056</td>\n",
       "      <td>55.574321</td>\n",
       "      <td>54.388764</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-1.460688</td>\n",
       "      <td>-247370000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2015-05-12</td>\n",
       "      <td>4412.819824</td>\n",
       "      <td>4441.399902</td>\n",
       "      <td>4380.520020</td>\n",
       "      <td>4420.649902</td>\n",
       "      <td>4420.649902</td>\n",
       "      <td>1705870000</td>\n",
       "      <td>36.336244</td>\n",
       "      <td>50.584218</td>\n",
       "      <td>40.390560</td>\n",
       "      <td>37.624967</td>\n",
       "      <td>36.731507</td>\n",
       "      <td>35.703800</td>\n",
       "      <td>43.849997</td>\n",
       "      <td>45.732659</td>\n",
       "      <td>48.370431</td>\n",
       "      <td>50.184917</td>\n",
       "      <td>55.667518</td>\n",
       "      <td>50.052384</td>\n",
       "      <td>49.631162</td>\n",
       "      <td>51.580636</td>\n",
       "      <td>50.741282</td>\n",
       "      <td>49.842502</td>\n",
       "      <td>51.072569</td>\n",
       "      <td>52.861828</td>\n",
       "      <td>54.746511</td>\n",
       "      <td>54.279605</td>\n",
       "      <td>56.184578</td>\n",
       "      <td>-42.175111</td>\n",
       "      <td>-55.948855</td>\n",
       "      <td>-55.948855</td>\n",
       "      <td>-55.948855</td>\n",
       "      <td>-57.673031</td>\n",
       "      <td>-62.226349</td>\n",
       "      <td>-66.704445</td>\n",
       "      <td>-66.704445</td>\n",
       "      <td>-66.704445</td>\n",
       "      <td>-66.704445</td>\n",
       "      <td>-66.704445</td>\n",
       "      <td>...</td>\n",
       "      <td>42.571617</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>42.714895</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>42.832441</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>43.009764</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>43.524379</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>44.446132</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>45.672748</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>46.864159</td>\n",
       "      <td>38.190366</td>\n",
       "      <td>48.989298</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-150.533701</td>\n",
       "      <td>-25520000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>4436.080078</td>\n",
       "      <td>4460.540039</td>\n",
       "      <td>4421.750000</td>\n",
       "      <td>4426.560059</td>\n",
       "      <td>4426.560059</td>\n",
       "      <td>1672260000</td>\n",
       "      <td>37.906700</td>\n",
       "      <td>38.811053</td>\n",
       "      <td>52.230506</td>\n",
       "      <td>41.747182</td>\n",
       "      <td>38.873915</td>\n",
       "      <td>37.927190</td>\n",
       "      <td>36.851682</td>\n",
       "      <td>44.754485</td>\n",
       "      <td>46.572366</td>\n",
       "      <td>49.131123</td>\n",
       "      <td>50.890693</td>\n",
       "      <td>56.240947</td>\n",
       "      <td>50.603784</td>\n",
       "      <td>50.174816</td>\n",
       "      <td>52.083551</td>\n",
       "      <td>51.237377</td>\n",
       "      <td>50.332140</td>\n",
       "      <td>51.537787</td>\n",
       "      <td>53.294465</td>\n",
       "      <td>55.146425</td>\n",
       "      <td>54.676477</td>\n",
       "      <td>-35.507493</td>\n",
       "      <td>-37.342595</td>\n",
       "      <td>-52.267432</td>\n",
       "      <td>-52.267432</td>\n",
       "      <td>-52.267432</td>\n",
       "      <td>-54.135701</td>\n",
       "      <td>-59.069546</td>\n",
       "      <td>-63.921884</td>\n",
       "      <td>-63.921884</td>\n",
       "      <td>-63.921884</td>\n",
       "      <td>-63.921884</td>\n",
       "      <td>...</td>\n",
       "      <td>40.407117</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>42.066177</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>42.144541</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>42.262757</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>42.605833</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>43.220335</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>44.038079</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>44.832353</td>\n",
       "      <td>40.768741</td>\n",
       "      <td>46.249113</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>70.017796</td>\n",
       "      <td>-33610000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>2015-05-14</td>\n",
       "      <td>4461.069824</td>\n",
       "      <td>4496.250000</td>\n",
       "      <td>4448.379883</td>\n",
       "      <td>4495.040039</td>\n",
       "      <td>4495.040039</td>\n",
       "      <td>1741970000</td>\n",
       "      <td>71.171103</td>\n",
       "      <td>53.901567</td>\n",
       "      <td>54.189316</td>\n",
       "      <td>62.039520</td>\n",
       "      <td>51.632705</td>\n",
       "      <td>48.577528</td>\n",
       "      <td>47.521033</td>\n",
       "      <td>46.328746</td>\n",
       "      <td>52.112471</td>\n",
       "      <td>53.456561</td>\n",
       "      <td>55.388286</td>\n",
       "      <td>56.729112</td>\n",
       "      <td>60.924186</td>\n",
       "      <td>55.400145</td>\n",
       "      <td>54.965103</td>\n",
       "      <td>56.521065</td>\n",
       "      <td>55.678422</td>\n",
       "      <td>54.775418</td>\n",
       "      <td>55.770527</td>\n",
       "      <td>57.232692</td>\n",
       "      <td>58.785840</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>-0.826929</td>\n",
       "      <td>-0.826929</td>\n",
       "      <td>-9.611419</td>\n",
       "      <td>-9.611419</td>\n",
       "      <td>-9.611419</td>\n",
       "      <td>-13.149258</td>\n",
       "      <td>-22.492215</td>\n",
       "      <td>-31.680824</td>\n",
       "      <td>-31.680824</td>\n",
       "      <td>-31.680824</td>\n",
       "      <td>...</td>\n",
       "      <td>49.711136</td>\n",
       "      <td>68.319176</td>\n",
       "      <td>50.817177</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>51.644339</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>51.723149</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>51.951866</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>52.361535</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>52.906697</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>53.436213</td>\n",
       "      <td>70.643933</td>\n",
       "      <td>54.380719</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>85.656344</td>\n",
       "      <td>69710000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1254</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>8166.259766</td>\n",
       "      <td>8224.730469</td>\n",
       "      <td>7900.990234</td>\n",
       "      <td>8006.120117</td>\n",
       "      <td>8006.120117</td>\n",
       "      <td>4273890000</td>\n",
       "      <td>31.121980</td>\n",
       "      <td>41.112523</td>\n",
       "      <td>41.741908</td>\n",
       "      <td>36.383660</td>\n",
       "      <td>37.168526</td>\n",
       "      <td>34.703062</td>\n",
       "      <td>31.541336</td>\n",
       "      <td>30.192421</td>\n",
       "      <td>29.564694</td>\n",
       "      <td>31.019621</td>\n",
       "      <td>31.130668</td>\n",
       "      <td>31.580192</td>\n",
       "      <td>31.464070</td>\n",
       "      <td>32.928621</td>\n",
       "      <td>32.951731</td>\n",
       "      <td>34.644890</td>\n",
       "      <td>34.317166</td>\n",
       "      <td>35.413643</td>\n",
       "      <td>35.872857</td>\n",
       "      <td>38.562767</td>\n",
       "      <td>40.191070</td>\n",
       "      <td>-89.998300</td>\n",
       "      <td>-90.438128</td>\n",
       "      <td>-90.438128</td>\n",
       "      <td>-90.438128</td>\n",
       "      <td>-90.438128</td>\n",
       "      <td>-90.712002</td>\n",
       "      <td>-91.804592</td>\n",
       "      <td>-91.875086</td>\n",
       "      <td>-93.790356</td>\n",
       "      <td>-94.202098</td>\n",
       "      <td>-94.272662</td>\n",
       "      <td>...</td>\n",
       "      <td>17.227331</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.231351</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.244800</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.244822</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.244931</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.244959</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.245138</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.245182</td>\n",
       "      <td>5.727338</td>\n",
       "      <td>17.245441</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-730.402257</td>\n",
       "      <td>-158040000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>1255</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>7452.759766</td>\n",
       "      <td>7808.310059</td>\n",
       "      <td>7255.620117</td>\n",
       "      <td>7263.649902</td>\n",
       "      <td>7263.649902</td>\n",
       "      <td>5066530000</td>\n",
       "      <td>25.647967</td>\n",
       "      <td>23.634643</td>\n",
       "      <td>32.349312</td>\n",
       "      <td>32.924247</td>\n",
       "      <td>29.524692</td>\n",
       "      <td>30.241402</td>\n",
       "      <td>28.606268</td>\n",
       "      <td>26.435679</td>\n",
       "      <td>25.491759</td>\n",
       "      <td>25.051456</td>\n",
       "      <td>26.372628</td>\n",
       "      <td>26.478106</td>\n",
       "      <td>26.890938</td>\n",
       "      <td>26.812312</td>\n",
       "      <td>28.152872</td>\n",
       "      <td>28.177326</td>\n",
       "      <td>29.737066</td>\n",
       "      <td>29.499305</td>\n",
       "      <td>30.516017</td>\n",
       "      <td>30.944626</td>\n",
       "      <td>33.460195</td>\n",
       "      <td>-99.500812</td>\n",
       "      <td>-99.526683</td>\n",
       "      <td>-99.539798</td>\n",
       "      <td>-99.539798</td>\n",
       "      <td>-99.539798</td>\n",
       "      <td>-99.539798</td>\n",
       "      <td>-99.548193</td>\n",
       "      <td>-99.583552</td>\n",
       "      <td>-99.585942</td>\n",
       "      <td>-99.656609</td>\n",
       "      <td>-99.673401</td>\n",
       "      <td>...</td>\n",
       "      <td>11.592773</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.595453</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604419</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604434</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604507</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604525</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604645</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604674</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>11.604847</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>-5791.349748</td>\n",
       "      <td>792640000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>1256</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>7683.040039</td>\n",
       "      <td>7998.509766</td>\n",
       "      <td>7301.879883</td>\n",
       "      <td>7995.259766</td>\n",
       "      <td>7995.259766</td>\n",
       "      <td>4685890000</td>\n",
       "      <td>38.164000</td>\n",
       "      <td>43.623213</td>\n",
       "      <td>40.293103</td>\n",
       "      <td>45.748493</td>\n",
       "      <td>45.932317</td>\n",
       "      <td>41.707045</td>\n",
       "      <td>42.091530</td>\n",
       "      <td>40.019513</td>\n",
       "      <td>37.292272</td>\n",
       "      <td>36.055676</td>\n",
       "      <td>35.447352</td>\n",
       "      <td>36.396686</td>\n",
       "      <td>36.435110</td>\n",
       "      <td>36.711179</td>\n",
       "      <td>36.578989</td>\n",
       "      <td>37.570096</td>\n",
       "      <td>37.562561</td>\n",
       "      <td>38.732748</td>\n",
       "      <td>38.435311</td>\n",
       "      <td>39.199617</td>\n",
       "      <td>39.513190</td>\n",
       "      <td>-43.807471</td>\n",
       "      <td>-54.018818</td>\n",
       "      <td>-56.401774</td>\n",
       "      <td>-57.609883</td>\n",
       "      <td>-57.609883</td>\n",
       "      <td>-57.609883</td>\n",
       "      <td>-57.609883</td>\n",
       "      <td>-58.383143</td>\n",
       "      <td>-61.640134</td>\n",
       "      <td>-61.860287</td>\n",
       "      <td>-68.369568</td>\n",
       "      <td>...</td>\n",
       "      <td>17.666101</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.667888</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.673865</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.673875</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.673923</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.673936</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.674015</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.674035</td>\n",
       "      <td>29.812757</td>\n",
       "      <td>17.674150</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>1757.667540</td>\n",
       "      <td>-380640000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1257</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>7502.259766</td>\n",
       "      <td>7563.450195</td>\n",
       "      <td>6993.609863</td>\n",
       "      <td>7020.379883</td>\n",
       "      <td>7020.379883</td>\n",
       "      <td>4594360000</td>\n",
       "      <td>27.798509</td>\n",
       "      <td>26.250936</td>\n",
       "      <td>31.905992</td>\n",
       "      <td>30.208323</td>\n",
       "      <td>35.659173</td>\n",
       "      <td>36.029274</td>\n",
       "      <td>33.390039</td>\n",
       "      <td>33.872741</td>\n",
       "      <td>32.551762</td>\n",
       "      <td>30.734104</td>\n",
       "      <td>29.918897</td>\n",
       "      <td>29.533475</td>\n",
       "      <td>30.466994</td>\n",
       "      <td>30.544533</td>\n",
       "      <td>30.839743</td>\n",
       "      <td>30.772695</td>\n",
       "      <td>31.730931</td>\n",
       "      <td>31.750557</td>\n",
       "      <td>32.875692</td>\n",
       "      <td>32.676841</td>\n",
       "      <td>33.418182</td>\n",
       "      <td>-98.064114</td>\n",
       "      <td>-98.303838</td>\n",
       "      <td>-98.568892</td>\n",
       "      <td>-98.633137</td>\n",
       "      <td>-98.666068</td>\n",
       "      <td>-98.666068</td>\n",
       "      <td>-98.666068</td>\n",
       "      <td>-98.666068</td>\n",
       "      <td>-98.687274</td>\n",
       "      <td>-98.777720</td>\n",
       "      <td>-98.783900</td>\n",
       "      <td>...</td>\n",
       "      <td>12.105390</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.103910</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.107895</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.107901</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.107933</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.107942</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.107995</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.108008</td>\n",
       "      <td>0.975954</td>\n",
       "      <td>12.108084</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-4609.773515</td>\n",
       "      <td>-91530000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1258</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>7198.529785</td>\n",
       "      <td>7550.129883</td>\n",
       "      <td>6959.149902</td>\n",
       "      <td>7473.950195</td>\n",
       "      <td>7473.950195</td>\n",
       "      <td>4900000000</td>\n",
       "      <td>38.940815</td>\n",
       "      <td>37.510255</td>\n",
       "      <td>35.180243</td>\n",
       "      <td>39.581714</td>\n",
       "      <td>37.426416</td>\n",
       "      <td>41.866329</td>\n",
       "      <td>42.076638</td>\n",
       "      <td>39.101546</td>\n",
       "      <td>39.450216</td>\n",
       "      <td>37.947706</td>\n",
       "      <td>35.907146</td>\n",
       "      <td>34.970180</td>\n",
       "      <td>34.511085</td>\n",
       "      <td>35.301250</td>\n",
       "      <td>35.344904</td>\n",
       "      <td>35.581932</td>\n",
       "      <td>35.487048</td>\n",
       "      <td>36.310762</td>\n",
       "      <td>36.311832</td>\n",
       "      <td>37.287025</td>\n",
       "      <td>37.059368</td>\n",
       "      <td>-63.677151</td>\n",
       "      <td>-63.677151</td>\n",
       "      <td>-68.078953</td>\n",
       "      <td>-72.976937</td>\n",
       "      <td>-74.169066</td>\n",
       "      <td>-74.780887</td>\n",
       "      <td>-74.780887</td>\n",
       "      <td>-74.780887</td>\n",
       "      <td>-74.780887</td>\n",
       "      <td>-75.175153</td>\n",
       "      <td>-76.859064</td>\n",
       "      <td>...</td>\n",
       "      <td>14.582968</td>\n",
       "      <td>18.685490</td>\n",
       "      <td>14.297770</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250328</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250333</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250354</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250360</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250395</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250403</td>\n",
       "      <td>18.535195</td>\n",
       "      <td>14.250455</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>-288.134539</td>\n",
       "      <td>305640000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1223 rows Ã— 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unnamed: 0  timestamp         open  ...       eom_26  volume_delta  labels\n",
       "0             36 2015-05-08  4445.000000  ...    74.650219   -64200000.0     2.0\n",
       "1             37 2015-05-11  4457.620117  ...    -1.460688  -247370000.0     2.0\n",
       "2             38 2015-05-12  4412.819824  ...  -150.533701   -25520000.0     2.0\n",
       "3             39 2015-05-13  4436.080078  ...    70.017796   -33610000.0     1.0\n",
       "4             40 2015-05-14  4461.069824  ...    85.656344    69710000.0     2.0\n",
       "...          ...        ...          ...  ...          ...           ...     ...\n",
       "1218        1254 2020-03-11  8166.259766  ...  -730.402257  -158040000.0     0.0\n",
       "1219        1255 2020-03-12  7452.759766  ... -5791.349748   792640000.0     2.0\n",
       "1220        1256 2020-03-13  7683.040039  ...  1757.667540  -380640000.0     2.0\n",
       "1221        1257 2020-03-16  7502.259766  ... -4609.773515   -91530000.0     2.0\n",
       "1222        1258 2020-03-17  7198.529785  ...  -288.134539   305640000.0     2.0\n",
       "\n",
       "[1223 rows x 451 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ) 23-03-2020 10_51_22 MainThread DEBUG\\ common selected featues:312, ['roc_9', 'cci_8', 'dpo_9', 'dpo_13', 'fi_6', 'cmo_19', 'wr_26', 'roc_12', 'trix_17', 'rsv_7', 'kdjk_9', 'roc_17', 'eom_8', 'rsv_17', 'cmo_12', 'mfi_16', 'eom_13', 'hma_4', 'rsi_13', 'wr_17', 'roc_11', 'dpo_26', 'roc_23', 'rsv_26', 'roc_22', 'dpo_10', 'wr_22', 'dpo_25', 'fi_18', 'cmo_17', 'dpo_22', 'fi_23', 'hma_7', 'dmi_15', 'rsv_12', 'dpo_6', 'fi_25', 'wr_24', 'trix_26', 'hma_19', 'cci_19', 'dpo_24', 'wr_6', 'dpo_18', 'eom_22', 'dpo_23', 'cmo_6', 'cmo_9', 'cci_25', 'cmf_24', 'dpo_15', 'rsi_12', 'fi_12', 'cci_13', 'rsi_15', 'roc_19', 'trix_19', 'rsi_22', 'rsv_13', 'cci_24', 'dmi_12', 'fi_20', 'cci_21', 'dmi_20', 'eom_24', 'rsi_6', 'cmo_14', 'mfi_23', 'cmo_22', 'eom_14', 'fi_14', 'trix_11', 'cci_10', 'fi_15', 'rsi_23', 'rsv_19', 'eom_21', 'cci_12', 'cci_20', 'dmi_25', 'mfi_6', 'trix_14', 'kst_25', 'trix_8', 'kdjk_17', 'rsv_23', 'rsi_18', 'trix_20', 'cci_15', 'mfi_13', 'kst_19', 'eom_25', 'hma_18', 'cmf_18', 'cmo_13', 'cmf_14', 'dmi_14', 'dpo_19', 'fi_10', 'rsi_14', 'kdjk_26', 'fi_9', 'rsi_25', 'cmo_8', 'hma_3', 'mfi_19', 'cmf_13', 'kdjk_12', 'cmf_11', 'rsv_25', 'hma_20', 'kst_13', 'kst_6', 'dmi_11', 'wr_21', 'dmi_8', 'wr_10', 'hma_11', 'kst_14', 'eom_9', 'kdjk_18', 'kst_15', 'mfi_22', 'eom_16', 'cmf_10', 'cmo_23', 'rsi_26', 'dmi_6', 'roc_24', 'kst_22', 'kdjk_6', 'kst_16', 'kdjk_16', 'dpo_20', 'roc_10', 'rsi_7', 'kst_11', 'kdjk_15', 'kdjk_7', 'dpo_12', 'wr_16', 'cmo_10', 'rsv_16', 'cmf_12', 'cci_11', 'dpo_7', 'cci_16', 'rsv_10', 'rsv_18', 'rsv_22', 'eom_18', 'kst_7', 'wma_7', 'kdjk_8', 'kdjk_23', 'wr_20', 'trix_25', 'wr_8', 'dpo_14', 'fi_19', 'wr_15', 'trix_22', 'trix_18', 'roc_15', 'dpo_8', 'wr_13', 'kdjk_20', 'eom_20', 'hma_12', 'kst_8', 'kst_21', 'dmi_7', 'kdjk_10', 'trix_23', 'rsv_8', 'trix_10', 'wr_14', 'cmo_24', 'rsv_24', 'rsi_8', 'mfi_7', 'dmi_21', 'dmi_18', 'fi_22', 'eom_12', 'hma_9', 'cci_14', 'wr_7', 'cmo_16', 'kst_20', 'hma_14', 'rsi_21', 'dmi_19', 'mfi_12', 'rsv_9', 'wr_25', 'eom_6', 'eom_7', 'hma_6', 'kdjk_25', 'eom_17', 'dpo_17', 'cmf_7', 'wma_8', 'dpo_11', 'trix_12', 'cci_9', 'hma_16', 'wr_19', 'cmo_15', 'mfi_8', 'trix_15', 'kdjk_13', 'dmi_17', 'dmi_26', 'cmo_11', 'rsv_15', 'rsi_20', 'kst_12', 'kst_17', 'fi_8', 'cmo_7', 'cmo_18', 'trix_13', 'dmi_13', 'rsv_6', 'kdjk_11', 'kdjk_19', 'eom_26', 'fi_17', 'fi_21', 'cci_23', 'fi_24', 'hma_15', 'kst_10', 'rsv_21', 'roc_21', 'kdjk_24', 'rsi_16', 'fi_16', 'cmf_25', 'dmi_24', 'eom_23', 'mfi_10', 'cmf_6', 'wma_9', 'eom_10', 'kst_24', 'hma_5', 'dpo_21', 'bb_8', 'dpo_16', 'kdjk_14', 'eom_11', 'cci_7', 'fi_7', 'dmi_22', 'kdjk_21', 'trix_24', 'dmi_10', 'wr_11', 'roc_18', 'cmo_20', 'cci_22', 'rsi_10', 'rsi_17', 'rsi_11', 'mfi_9', 'cmf_26', 'roc_6', 'roc_7', 'trix_9', 'dmi_16', 'fi_13', 'roc_8', 'cmf_8', 'hma_13', 'fi_26', 'hma_10', 'cci_18', 'bb_7', 'cci_26', 'trix_21', 'trix_7', 'wr_12', 'wr_23', 'trix_16', 'hma_17', 'wr_9', 'cci_17', 'cci_6', 'mfi_17', 'dmi_9', 'rsv_11', 'rsv_20', 'rsv_14', 'kdjk_22', 'bb_6', 'trix_6', 'kst_18', 'fi_11', 'eom_19', 'kst_9', 'rsi_9', 'cmo_21', 'mfi_24', 'hma_8', 'kst_23', 'dmi_23', 'kst_26', 'eom_15', 'wr_18']\n",
      "10 ) 23-03-2020 10_51_22 MainThread DEBUG\\ [6, 7, 8, 12, 13, 14, 15, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 54, 55, 58, 61, 64, 65, 72, 73, 74, 75, 78, 80, 82, 85, 86, 87, 91, 94, 95, 96, 97, 98, 102, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 129, 196, 197, 219, 220, 222, 223, 225, 227, 228, 230, 232, 234, 235, 236, 239, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 253, 254, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 271, 272, 273, 276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 316, 319, 321, 322, 323, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 340, 341, 363, 365, 366, 367, 369, 371, 372, 375, 376, 377, 379, 380, 382, 385, 386, 387, 388, 389, 390, 391, 392, 393, 396, 397, 398, 399, 402, 403, 404, 405, 406, 407, 408, 409, 410, 413, 416, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 436, 437, 438, 440, 441, 442, 444, 445]\n",
      "11 ) 23-03-2020 10_51_22 MainThread DEBUG\\ /content/drive/My Drive/Colab Notebooks/inputs/ has data for 2015-05-08 00:00:00 to 2020-03-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "new_df = DataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56mNVIAf6wYd"
   },
   "source": [
    "# Start CNN processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7TkA_5A7Nzk"
   },
   "outputs": [],
   "source": [
    "df = new_df.df\n",
    "\n",
    "# df = df.iloc[:4*len(new_df)//5]\n",
    "\n",
    "# test = new_df.iloc[4*len(new_df)//5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kVTyJMAs61TH",
    "outputId": "f185f47a-0d0f-4917-fd48-41b2d2caee8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features 447\n",
      "train_split = 0.8\n",
      "Shape of x, y train/cv/test (782, 447) (782,) (196, 447) (196,) (245, 447) (245,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "list_features = list(df.loc[:, 'open':'eom_26'].columns)\n",
    "print('Total number of features', len(list_features))\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'open':'eom_26'].values, df['labels'].values, train_size=0.8, \n",
    "                                                    # test_size=0.2, random_state=2, shuffle=True, stratify=df['labels'].values)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'open':'eom_26'], df['labels'], train_size=0.8, \n",
    "                                                    test_size=0.2, random_state=2, shuffle=True, stratify=df['labels'])\n",
    "x_test_copy = x_test.copy(deep=True)\n",
    "x_train = x_train.loc[:, 'open':'eom_26'].values\n",
    "x_test = x_test.loc[:, 'open':'eom_26'].values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "if 0.7*x_train.shape[0] < 2500:\n",
    "    train_split = 0.8\n",
    "else:\n",
    "    train_split = 0.7\n",
    "# train_split = 0.7\n",
    "print('train_split =',train_split)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, train_size=train_split, test_size=1-train_split, \n",
    "                                                random_state=2, shuffle=True, stratify=y_train)\n",
    "mm_scaler = MinMaxScaler(feature_range=(0, 1)) # or StandardScaler?\n",
    "x_train = mm_scaler.fit_transform(x_train)\n",
    "x_cv = mm_scaler.transform(x_cv)\n",
    "x_test = mm_scaler.transform(x_test)\n",
    "\n",
    "x_main = x_train.copy()\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZYLAJBoD--1"
   },
   "outputs": [],
   "source": [
    "num_features = 225  # should be a perfect square\n",
    "selection_method = 'all'\n",
    "topk = 320 if selection_method == 'all' else num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "nWzf72jIOSRp",
    "outputId": "0d3f9cd6-323e-46c9-da72-f13891a37c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('open', 'high', 'low', 'close', 'adj close', 'rsi_6', 'rsi_7', 'rsi_8', 'rsi_9', 'rsi_10', 'rsi_11', 'rsi_12', 'rsi_13', 'rsi_14', 'rsi_15', 'rsi_16', 'rsi_17', 'rsi_18', 'rsi_19', 'rsi_20', 'rsi_21', 'rsi_22', 'rsi_23', 'rsi_24', 'rsi_25', 'rsi_26', 'wr_6', 'wr_7', 'wr_8', 'wr_9', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'wr_14', 'wr_15', 'wr_16', 'wr_17', 'wr_18', 'wr_19', 'wr_20', 'wr_21', 'wr_22', 'wr_23', 'wr_24', 'wr_25', 'wr_26', 'mfi_6', 'mfi_7', 'mfi_8', 'mfi_9', 'mfi_10', 'mfi_11', 'mfi_12', 'mfi_13', 'mfi_14', 'mfi_15', 'mfi_16', 'mfi_17', 'mfi_18', 'mfi_19', 'mfi_20', 'mfi_21', 'mfi_22', 'mfi_23', 'mfi_24', 'mfi_25', 'mfi_26', 'roc_6', 'roc_7', 'roc_8', 'roc_9', 'roc_10', 'roc_11', 'roc_12', 'roc_13', 'roc_14', 'roc_15', 'roc_16', 'roc_17', 'roc_18', 'roc_19', 'roc_20', 'roc_21', 'roc_22', 'roc_23', 'roc_24', 'roc_25', 'roc_26', 'cmf_6', 'cmf_7', 'cmf_8', 'cmf_9', 'cmf_10', 'cmf_11', 'cmf_12', 'cmf_13', 'cmf_14', 'cmf_15', 'cmf_16', 'cmf_21', 'cmf_22', 'cmf_23', 'cmf_24', 'cmf_25', 'cmf_26', 'cmo_6', 'cmo_7', 'cmo_8', 'cmo_9', 'cmo_10', 'cmo_11', 'cmo_12', 'cmo_13', 'cmo_14', 'cmo_15', 'cmo_16', 'cmo_17', 'cmo_18', 'cmo_19', 'cmo_20', 'cmo_21', 'cmo_22', 'cmo_23', 'cmo_24', 'cmo_25', 'cmo_26', 'hma_0', 'hma_1', 'hma_2', 'hma_3', 'trix_6', 'trix_7', 'trix_8', 'trix_9', 'trix_10', 'trix_11', 'trix_12', 'trix_13', 'trix_14', 'trix_15', 'trix_16', 'trix_17', 'trix_18', 'trix_19', 'trix_20', 'trix_21', 'trix_22', 'trix_23', 'trix_24', 'trix_25', 'trix_26', 'cci_6', 'cci_7', 'cci_8', 'cci_9', 'cci_10', 'cci_11', 'cci_12', 'cci_13', 'cci_14', 'cci_15', 'cci_16', 'cci_17', 'cci_18', 'cci_19', 'cci_20', 'cci_21', 'cci_22', 'cci_23', 'cci_24', 'cci_25', 'cci_26', 'dpo_6', 'dpo_7', 'dpo_8', 'dpo_9', 'dpo_10', 'dpo_11', 'dpo_12', 'dpo_13', 'dpo_14', 'dpo_15', 'dpo_16', 'dpo_17', 'dpo_18', 'dpo_19', 'dpo_20', 'dpo_21', 'dpo_22', 'dpo_23', 'dpo_24', 'dpo_25', 'dpo_26', 'kst_6', 'kst_7', 'kst_8', 'kst_9', 'kst_10', 'kst_11', 'kst_12', 'kst_13', 'kst_14', 'kst_15', 'kst_16', 'kst_17', 'kst_18', 'kst_19', 'kst_20', 'kst_21', 'kst_22', 'kst_23', 'kst_24', 'kst_25', 'kst_26', 'dmi_6', 'dmi_7', 'dmi_8', 'dmi_9', 'dmi_10', 'dmi_11', 'dmi_12', 'dmi_13', 'dmi_14', 'dmi_15', 'dmi_16', 'dmi_17', 'dmi_18', 'dmi_19', 'dmi_20', 'dmi_21', 'dmi_22', 'dmi_23', 'dmi_24', 'dmi_25', 'dmi_26', 'fi_6', 'fi_7', 'fi_8', 'fi_9', 'fi_10', 'fi_11', 'fi_12', 'fi_13', 'fi_14', 'fi_15', 'fi_16', 'fi_17', 'fi_18', 'fi_19', 'fi_20', 'fi_21', 'fi_22', 'fi_23', 'fi_24', 'fi_25', 'fi_26', 'rsv_6', 'kdjk_6', 'rsv_7', 'kdjk_7', 'rsv_8', 'kdjk_8', 'rsv_9', 'kdjk_9', 'rsv_10', 'kdjk_10', 'rsv_11', 'kdjk_11', 'rsv_12', 'kdjk_12', 'rsv_13', 'kdjk_13', 'rsv_14', 'kdjk_14', 'rsv_15', 'kdjk_15', 'rsv_16', 'kdjk_16', 'rsv_17', 'kdjk_17', 'rsv_18', 'kdjk_18', 'rsv_19', 'kdjk_19', 'rsv_20', 'kdjk_20', 'rsv_21', 'kdjk_21', 'rsv_22', 'kdjk_22', 'rsv_23', 'kdjk_23', 'rsv_24', 'kdjk_24', 'rsv_25', 'kdjk_25', 'rsv_26', 'kdjk_26', 'eom_6', 'eom_7', 'eom_8', 'eom_9', 'eom_10', 'eom_11', 'eom_12', 'eom_13', 'eom_14', 'eom_15', 'eom_16', 'eom_17', 'eom_18', 'eom_19', 'eom_20', 'eom_21', 'eom_22', 'eom_23', 'eom_24', 'eom_25', 'eom_26')\n",
      "[  0   1   2   3   4   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 216 217 218 219 237 238 239 240 241 242 243 244 245 246 247 248 249\n",
      " 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267\n",
      " 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285\n",
      " 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303\n",
      " 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321\n",
      " 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339\n",
      " 340 341 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446]\n",
      "****************************************\n",
      "320 ('volume', 'rsi_6', 'rsi_7', 'rsi_8', 'rsi_9', 'rsi_10', 'rsi_11', 'rsi_12', 'rsi_13', 'rsi_14', 'rsi_15', 'rsi_17', 'rsi_20', 'rsi_21', 'rsi_22', 'rsi_23', 'rsi_24', 'rsi_25', 'rsi_26', 'wr_6', 'wr_7', 'wr_8', 'wr_9', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'wr_14', 'wr_15', 'wr_16', 'wr_17', 'wr_18', 'wr_19', 'wr_20', 'wr_21', 'wr_22', 'wr_23', 'wr_24', 'wr_25', 'wr_26', 'mfi_6', 'mfi_7', 'mfi_8', 'mfi_9', 'mfi_10', 'mfi_12', 'mfi_13', 'mfi_14', 'mfi_15', 'mfi_17', 'mfi_19', 'mfi_21', 'mfi_22', 'mfi_23', 'mfi_24', 'roc_6', 'roc_7', 'roc_8', 'roc_9', 'roc_10', 'roc_11', 'roc_12', 'roc_14', 'roc_15', 'roc_19', 'roc_23', 'roc_24', 'roc_25', 'cmf_6', 'cmf_7', 'cmf_8', 'cmf_9', 'cmf_10', 'cmf_11', 'cmf_12', 'cmf_13', 'cmf_14', 'cmf_16', 'cmf_25', 'cmf_26', 'cmo_6', 'cmo_7', 'cmo_8', 'cmo_9', 'cmo_10', 'cmo_11', 'cmo_12', 'cmo_13', 'cmo_14', 'cmo_15', 'cmo_16', 'cmo_18', 'cmo_19', 'cmo_20', 'cmo_21', 'cmo_22', 'cmo_23', 'cmo_24', 'cmo_25', 'cmo_26', 'hma_11', 'hma_12', 'hma_13', 'hma_14', 'hma_15', 'hma_16', 'hma_17', 'hma_18', 'hma_19', 'hma_20', 'trix_6', 'trix_7', 'trix_8', 'trix_9', 'trix_10', 'trix_11', 'trix_12', 'trix_13', 'trix_14', 'trix_15', 'trix_16', 'trix_17', 'trix_18', 'trix_19', 'trix_20', 'trix_21', 'trix_22', 'trix_23', 'trix_24', 'trix_25', 'trix_26', 'cci_6', 'cci_7', 'cci_8', 'cci_9', 'cci_10', 'cci_11', 'cci_12', 'cci_13', 'cci_14', 'cci_15', 'cci_16', 'cci_17', 'cci_18', 'cci_19', 'cci_20', 'cci_21', 'cci_22', 'cci_23', 'cci_24', 'cci_25', 'cci_26', 'dpo_6', 'dpo_7', 'dpo_8', 'dpo_9', 'dpo_10', 'dpo_11', 'dpo_12', 'dpo_13', 'dpo_14', 'dpo_15', 'dpo_16', 'dpo_17', 'dpo_18', 'dpo_19', 'dpo_20', 'dpo_21', 'dpo_22', 'dpo_23', 'dpo_24', 'dpo_25', 'dpo_26', 'kst_6', 'kst_7', 'kst_8', 'kst_9', 'kst_10', 'kst_11', 'kst_12', 'kst_13', 'kst_14', 'kst_15', 'kst_16', 'kst_17', 'kst_18', 'kst_19', 'kst_20', 'kst_21', 'kst_22', 'kst_23', 'kst_24', 'kst_25', 'kst_26', 'dmi_6', 'dmi_7', 'dmi_8', 'dmi_9', 'dmi_10', 'dmi_11', 'dmi_12', 'dmi_13', 'dmi_14', 'dmi_15', 'dmi_16', 'dmi_17', 'dmi_18', 'dmi_19', 'dmi_20', 'dmi_21', 'dmi_22', 'dmi_23', 'dmi_24', 'dmi_25', 'dmi_26', 'bb_6', 'bb_7', 'bb_8', 'bb_9', 'bb_10', 'bb_11', 'bb_12', 'bb_13', 'bb_14', 'bb_15', 'bb_16', 'bb_17', 'bb_18', 'bb_19', 'bb_20', 'bb_21', 'bb_22', 'bb_23', 'bb_24', 'bb_25', 'bb_26', 'fi_6', 'fi_7', 'fi_8', 'fi_9', 'fi_10', 'fi_11', 'fi_12', 'fi_13', 'fi_14', 'fi_15', 'fi_16', 'fi_17', 'fi_18', 'fi_19', 'fi_20', 'fi_21', 'fi_22', 'fi_23', 'fi_24', 'fi_25', 'fi_26', 'rsv_6', 'kdjk_6', 'rsv_7', 'kdjk_7', 'rsv_8', 'kdjk_8', 'rsv_9', 'kdjk_9', 'rsv_10', 'kdjk_10', 'rsv_11', 'kdjk_11', 'rsv_12', 'kdjk_12', 'rsv_13', 'kdjk_13', 'rsv_14', 'kdjk_14', 'rsv_15', 'kdjk_15', 'rsv_16', 'kdjk_16', 'rsv_17', 'kdjk_17', 'rsv_18', 'kdjk_18', 'rsv_19', 'kdjk_19', 'rsv_20', 'kdjk_20', 'rsv_21', 'kdjk_21', 'rsv_22', 'kdjk_22', 'rsv_23', 'kdjk_23', 'rsv_24', 'kdjk_24', 'rsv_25', 'kdjk_25', 'rsv_26', 'kdjk_26', 'eom_6', 'eom_7', 'eom_8', 'eom_9', 'eom_10', 'eom_11', 'eom_12', 'eom_13', 'eom_14', 'eom_15', 'eom_16', 'eom_17', 'eom_18', 'eom_19', 'eom_20', 'eom_21', 'eom_22', 'eom_23', 'eom_24', 'eom_25', 'eom_26')\n",
      "[  5   6   7   8   9  10  11  12  13  14  15  17  20  21  22  23  24  25\n",
      "  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43\n",
      "  44  45  46  47  48  49  50  51  52  54  55  56  57  59  61  63  64  65\n",
      "  66  69  70  71  72  73  74  75  77  78  82  86  87  88  90  91  92  93\n",
      "  94  95  96  97  98 100 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 123 124 125 126 127 128 129 130 131 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
      " 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n",
      " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446]\n",
      "CPU times: user 3.18 s, sys: 32.7 ms, total: 3.21 s\n",
      "Wall time: 3.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from operator import itemgetter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "if selection_method == 'anova' or selection_method == 'all':\n",
    "    select_k_best = SelectKBest(f_classif, k=topk)\n",
    "    if selection_method != 'all':\n",
    "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
    "        x_cv = select_k_best.transform(x_cv)\n",
    "        x_test = select_k_best.transform(x_test)\n",
    "    else:\n",
    "        select_k_best.fit(x_main, y_train)\n",
    "    \n",
    "    selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "    print(selected_features_anova)\n",
    "    print(select_k_best.get_support(indices=True))\n",
    "    print(\"****************************************\")\n",
    "    \n",
    "if selection_method == 'mutual_info' or selection_method == 'all':\n",
    "    select_k_best = SelectKBest(mutual_info_classif, k=topk)\n",
    "    if selection_method != 'all':\n",
    "        x_train = select_k_best.fit_transform(x_main, y_train)\n",
    "        x_cv = select_k_best.transform(x_cv)\n",
    "        x_test = select_k_best.transform(x_test)\n",
    "    else:\n",
    "        select_k_best.fit(x_main, y_train)\n",
    "\n",
    "    selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "    print(len(selected_features_mic), selected_features_mic)\n",
    "    print(select_k_best.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ORzOUGTvOWDx",
    "outputId": "6d06db96-6426-498f-e285-416d59ef8e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common selected featues 288 ['mfi_21', 'roc_9', 'cci_8', 'dpo_9', 'dpo_13', 'cmo_19', 'wr_26', 'roc_12', 'trix_17', 'fi_6', 'rsv_7', 'eom_8', 'roc_14', 'rsv_17', 'cmo_12', 'eom_13', 'rsi_24', 'rsi_13', 'wr_17', 'roc_11', 'dpo_26', 'roc_23', 'rsv_26', 'dpo_10', 'wr_22', 'dpo_25', 'fi_18', 'dpo_22', 'fi_23', 'dmi_15', 'rsv_12', 'dpo_6', 'fi_25', 'wr_24', 'trix_26', 'cci_19', 'dpo_24', 'wr_6', 'dpo_18', 'eom_22', 'dpo_23', 'cmo_6', 'cmo_9', 'cci_25', 'dpo_15', 'rsi_12', 'fi_12', 'cci_13', 'rsi_15', 'roc_19', 'trix_19', 'rsi_22', 'rsv_13', 'cci_24', 'dmi_12', 'fi_20', 'cci_21', 'dmi_20', 'eom_24', 'rsi_6', 'cmo_14', 'mfi_23', 'cmo_22', 'eom_14', 'fi_14', 'trix_11', 'cci_10', 'fi_15', 'rsi_23', 'rsv_19', 'eom_21', 'cci_12', 'cci_20', 'cmf_9', 'dmi_25', 'mfi_6', 'trix_14', 'kst_25', 'trix_8', 'kdjk_17', 'rsv_23', 'trix_20', 'cci_15', 'eom_25', 'mfi_13', 'kst_19', 'cmo_13', 'cmf_14', 'dmi_14', 'kdjk_9', 'dpo_19', 'fi_10', 'rsi_14', 'kdjk_26', 'fi_9', 'rsi_25', 'cmo_8', 'mfi_19', 'cmf_13', 'kdjk_12', 'cmf_11', 'cmf_16', 'cmo_26', 'rsv_25', 'kst_13', 'kst_6', 'dmi_11', 'wr_21', 'dmi_8', 'wr_10', 'kst_14', 'cmo_25', 'eom_9', 'kdjk_18', 'kst_15', 'mfi_22', 'eom_16', 'cmf_10', 'cmo_23', 'rsi_26', 'dmi_6', 'roc_24', 'kst_22', 'kdjk_6', 'kst_16', 'kdjk_16', 'dpo_20', 'roc_10', 'rsi_7', 'kst_11', 'kdjk_15', 'kdjk_7', 'dpo_12', 'wr_16', 'cmo_10', 'rsv_16', 'cmf_12', 'cci_11', 'dpo_7', 'cci_16', 'rsv_10', 'rsv_18', 'rsv_22', 'eom_18', 'kst_7', 'kdjk_23', 'kdjk_8', 'wr_20', 'trix_25', 'wr_8', 'dpo_14', 'fi_19', 'wr_15', 'trix_22', 'trix_18', 'roc_15', 'dpo_8', 'wr_13', 'kdjk_20', 'eom_20', 'kst_8', 'kst_21', 'dmi_7', 'kdjk_10', 'trix_23', 'rsv_8', 'trix_10', 'wr_14', 'cmo_24', 'rsv_24', 'rsi_8', 'mfi_7', 'dmi_21', 'dmi_18', 'fi_22', 'eom_12', 'cci_14', 'kst_20', 'wr_7', 'cmo_16', 'rsv_9', 'rsi_21', 'dmi_19', 'mfi_12', 'wr_25', 'eom_6', 'mfi_14', 'eom_7', 'kdjk_25', 'dpo_17', 'cmf_7', 'dpo_11', 'trix_12', 'cci_9', 'trix_15', 'wr_19', 'cmo_15', 'mfi_8', 'kdjk_13', 'dmi_17', 'dmi_26', 'cmo_11', 'rsv_15', 'rsi_20', 'kst_12', 'kst_17', 'fi_8', 'cmo_7', 'cmo_18', 'trix_13', 'dmi_13', 'rsv_6', 'kdjk_11', 'roc_25', 'kdjk_19', 'eom_26', 'fi_17', 'fi_21', 'cci_23', 'fi_24', 'kst_10', 'rsv_21', 'kdjk_24', 'fi_16', 'cmf_25', 'dmi_24', 'eom_23', 'mfi_10', 'cmf_6', 'eom_10', 'kst_24', 'dpo_21', 'dpo_16', 'kdjk_14', 'eom_11', 'cci_7', 'mfi_15', 'fi_7', 'dmi_22', 'kdjk_21', 'trix_24', 'dmi_10', 'wr_11', 'cmo_20', 'cci_22', 'rsi_10', 'rsi_17', 'rsi_11', 'mfi_9', 'cmf_26', 'roc_6', 'roc_7', 'trix_9', 'dmi_16', 'fi_13', 'roc_8', 'cmf_8', 'fi_26', 'cci_18', 'cci_26', 'trix_21', 'trix_7', 'wr_12', 'wr_23', 'trix_16', 'dmi_9', 'wr_9', 'cci_17', 'cci_6', 'mfi_17', 'rsv_11', 'rsv_20', 'kdjk_22', 'rsv_14', 'eom_17', 'trix_6', 'kst_18', 'fi_11', 'eom_19', 'kst_9', 'rsi_9', 'cmo_21', 'mfi_24', 'kst_23', 'dmi_23', 'kst_26', 'eom_15', 'wr_18']\n",
      "[6, 7, 8, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 54, 55, 56, 61, 63, 64, 65, 72, 73, 74, 75, 77, 78, 82, 86, 87, 88, 91, 93, 94, 95, 96, 97, 98, 100, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 127, 128, 129, 130, 131, 239, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 253, 254, 256, 257, 260, 261, 262, 263, 264, 265, 266, 267, 268, 271, 272, 273, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 316, 319, 321, 322, 323, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 340, 341, 363, 365, 366, 367, 369, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 396, 397, 398, 399, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 413, 414, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 436, 438, 440, 441, 442, 444, 445, 446]\n"
     ]
    }
   ],
   "source": [
    "if selection_method == 'all':\n",
    "    common = list(set(selected_features_anova).intersection(selected_features_mic))\n",
    "    print(\"common selected featues\", len(common), common)\n",
    "    if len(common) < num_features:\n",
    "        raise Exception('number of common features found {} < {} required features. Increase \"topk variable\"'.format(len(common), num_features))\n",
    "    feat_idx = []\n",
    "    for c in common:\n",
    "        feat_idx.append(list_features.index(c))\n",
    "    feat_idx = sorted(feat_idx[0:225])\n",
    "    print(feat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUorXH4NtUw7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MiA_if7_OwP8",
    "outputId": "4af08c09-00fc-4fff-ecbc-933499195314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x, y train/cv/test (782, 225) (782,) (196, 225) (196,) (245, 225) (245,)\n"
     ]
    }
   ],
   "source": [
    "if selection_method == 'all':\n",
    "    x_train = x_train[:, feat_idx]\n",
    "    x_cv = x_cv[:, feat_idx]\n",
    "    x_test = x_test[:, feat_idx]\n",
    "\n",
    "print(\"Shape of x, y train/cv/test {} {} {} {} {} {}\".format(x_train.shape, \n",
    "                                                             y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YJvwHxUGOx8F",
    "outputId": "f425cb9b-b04a-4043-c884-c9df654b97e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of class 0 = 5.626598465473146, class 1 = 5.88235294117647\n"
     ]
    }
   ],
   "source": [
    "_labels, _counts = np.unique(y_train, return_counts=True)\n",
    "print(\"percentage of class 0 = {}, class 1 = {}\".format(_counts[0]/len(y_train) * 100, _counts[1]/len(y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "yELdkxfJO0GG",
    "outputId": "bc89ecda-feed-4c9e-aa72-ebfe389a5df5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "def get_sample_weights(y):\n",
    "    \"\"\"\n",
    "    calculate the sample weights based on class weights. Used for models with\n",
    "    imbalanced data and one hot encoding prediction.\n",
    "\n",
    "    params:\n",
    "        y: class labels as integers\n",
    "    \"\"\"\n",
    "\n",
    "    y = y.astype(int)  # compute_class_weight needs int labels\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "    \n",
    "    print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
    "    print(\"value_counts\", np.unique(y, return_counts=True))\n",
    "    sample_weights = y.copy().astype(float)\n",
    "    for i in np.unique(y):\n",
    "        sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
    "        # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
    "\n",
    "    return sample_weights\n",
    "\n",
    "def reshape_as_image(x, img_width, img_height):\n",
    "    x_temp = np.zeros((len(x), img_height, img_width))\n",
    "    for i in range(x.shape[0]):\n",
    "        # print(type(x), type(x_temp), x.shape)\n",
    "        x_temp[i] = np.reshape(x[i], (img_height, img_width))\n",
    "\n",
    "    return x_temp\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "    y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)  # can use conf_mat[0, :], tf.slice()\n",
    "    # precision = TP/TP+FP, recall = TP/TP+FN\n",
    "    rows, cols = conf_mat.get_shape()\n",
    "    size = y_true_class.get_shape()[0]\n",
    "    precision = tf.constant([0, 0, 0])  # change this to use rows/cols as size\n",
    "    recall = tf.constant([0, 0, 0])\n",
    "    class_counts = tf.constant([0, 0, 0])\n",
    "\n",
    "    def get_precision(i, conf_mat):\n",
    "        print(\"prec check\", conf_mat, conf_mat[i, i], tf.reduce_sum(conf_mat[:, i]))\n",
    "        precision[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[:, i]))\n",
    "        recall[i].assign(conf_mat[i, i] / tf.reduce_sum(conf_mat[i, :]))\n",
    "        tf.add(i, 1)\n",
    "        return i, conf_mat, precision, recall\n",
    "\n",
    "    def tf_count(i):\n",
    "        elements_equal_to_value = tf.equal(y_true_class, i)\n",
    "        as_ints = tf.cast(elements_equal_to_value, tf.int32)\n",
    "        count = tf.reduce_sum(as_ints)\n",
    "        class_counts[i].assign(count)\n",
    "        tf.add(i, 1)\n",
    "        return count\n",
    "\n",
    "    def condition(i, conf_mat):\n",
    "        return tf.less(i, 3)\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    i, conf_mat = tf.while_loop(condition, get_precision, [i, conf_mat])\n",
    "\n",
    "    i = tf.constant(3)\n",
    "    c = lambda i: tf.less(i, 3)\n",
    "    b = tf_count(i)\n",
    "    tf.while_loop(c, b, [i])\n",
    "\n",
    "    weights = tf.math.divide(class_counts, size)\n",
    "    numerators = tf.math.multiply(tf.math.multiply(precision, recall), tf.constant(2))\n",
    "    denominators = tf.math.add(precision, recall)\n",
    "    f1s = tf.math.divide(numerators, denominators)\n",
    "    weighted_f1 = tf.reduce_sum(f.math.multiply(f1s, weights))\n",
    "    return weighted_f1\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    this calculates precision & recall \n",
    "    \"\"\"\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # mistake: y_pred of 0.3 is also considered 1\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    # y_true_class = tf.math.argmax(y_true, axis=1, output_type=tf.dtypes.int32)\n",
    "    # y_pred_class = tf.math.argmax(y_pred, axis=1, output_type=tf.dtypes.int32)\n",
    "    # conf_mat = tf.math.confusion_matrix(y_true_class, y_pred_class)\n",
    "    # tf.Print(conf_mat, [conf_mat], \"confusion_matrix\")\n",
    "\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "get_custom_objects().update({\"f1_metric\": f1_metric, \"f1_weighted\": f1_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "v_U-bNseO3Ln",
    "outputId": "b0eeb537-aaaf-43c2-95fa-60f63d16ee2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real class weights are [5.92424242 5.66666667 0.37668593] [0 1 2]\n",
      "value_counts (array([0, 1, 2]), array([ 44,  46, 692]))\n",
      "Test sample_weights\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      "[0.37668593 0.37668593 0.37668593 0.37668593 0.37668593 0.37668593\n",
      " 0.37668593 0.37668593 0.37668593 0.37668593 5.66666667 0.37668593]\n"
     ]
    }
   ],
   "source": [
    "sample_weights = get_sample_weights(y_train)\n",
    "print(\"Test sample_weights\")\n",
    "rand_idx = np.random.randint(0, 400, 12)\n",
    "print(y_train[rand_idx])\n",
    "print(sample_weights[rand_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sHvSJD5bO47K",
    "outputId": "c7ff6203-cd76-4a49-8df7-aa589f1052a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (782, 3)\n"
     ]
    }
   ],
   "source": [
    "one_hot_enc = OneHotEncoder(sparse=False, categories='auto')  # , categories='auto'\n",
    "y_train = one_hot_enc.fit_transform(y_train.reshape(-1, 1))\n",
    "print(\"y_train\",y_train.shape)\n",
    "y_cv = one_hot_enc.transform(y_cv.reshape(-1, 1))\n",
    "y_test = one_hot_enc.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vzbz6zPcO7Bk",
    "outputId": "89b0abd0-4f66-439d-f4db-930c5309ac38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape of x, y train/test (782, 15, 15, 3) (782, 3) (245, 15, 15, 3) (245, 3)\n"
     ]
    }
   ],
   "source": [
    "dim = int(np.sqrt(num_features))\n",
    "x_train = reshape_as_image(x_train, dim, dim)\n",
    "x_cv = reshape_as_image(x_cv, dim, dim)\n",
    "x_test = reshape_as_image(x_test, dim, dim)\n",
    "# adding a 1-dim for channels (3)\n",
    "x_train = np.stack((x_train,) * 3, axis=-1)\n",
    "x_test = np.stack((x_test,) * 3, axis=-1)\n",
    "x_cv = np.stack((x_cv,) * 3, axis=-1)\n",
    "print(\"final shape of x, y train/test {} {} {} {}\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "colab_type": "code",
    "id": "sZdVgo2PPdDH",
    "outputId": "3929ae17-8c74-4f05-f9b4-36d87eb19979"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAANLCAYAAACdWnYxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlCYAAICE0gQAAJD4//l/fVjmTx8FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "columns = rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    index = np.random.randint(len(x_train))\n",
    "    img = x_train[index]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('image_'+str(index)+'_class_'+str(np.argmax(y_train[index])), fontsize=10)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U7Lc49vPgFI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "params = {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.22, 'conv2d_filters_1': 35, 'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2, \n",
    "                                              'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.05, \n",
    "                                              'conv2d_filters_2': 20, 'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2, \n",
    "                                              'kernel_regularizer_2': 0.0, 'layers': 'two'}, \n",
    "          'dense_layers': {'dense_do_1': 0.22, 'dense_nodes_1': 100, 'kernel_regularizer_1': 0.0, 'layers': 'one'},\n",
    "          'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam'}\n",
    "\n",
    "# Original paper CNN params: input layer (15x15), two convolutional layers (15x15x32, 15x15x64),\n",
    "# a max pooling (7x7x64), two dropout (0.25, 0.50), fully connected layers (128), and an out-\n",
    "# put layer (3). stride?\n",
    "# params = {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.25, 'conv2d_filters_1': 32, 'conv2d_kernel_size_1': 3, 'conv2d_mp_1': 0, \n",
    "#                                                'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.5, \n",
    "#                                                'conv2d_filters_2': 64, 'conv2d_kernel_size_2': 3, 'conv2d_mp_2': 7, 'conv2d_strides_2': 1, \n",
    "#                                                'kernel_regularizer_2': 0.0, 'layers': 'two'}, \n",
    "#            'dense_layers': {'dense_do_1': 0.0, 'dense_nodes_1': 128, 'kernel_regularizer_1': 0.0, 'layers': 'one'},\n",
    "#            'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTrscnd6PhCg"
   },
   "outputs": [],
   "source": [
    "from functools import *\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "def f1_custom(y_true, y_pred):\n",
    "    y_t = np.argmax(y_true, axis=1)\n",
    "    y_p = np.argmax(y_pred, axis=1)\n",
    "    f1_score(y_t, y_p, labels=None, average='weighted', sample_weight=None, zero_division='warn')\n",
    "\n",
    "def create_model_cnn(params):\n",
    "    model = Sequential()\n",
    "\n",
    "    print(\"Training with params {}\".format(params))\n",
    "    # (batch_size, timesteps, data_dim)\n",
    "    # x_train, y_train = get_data_cnn(df, df.head(1).iloc[0][\"timestamp\"])[0:2]\n",
    "    conv2d_layer1 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_1\"],\n",
    "                           params[\"conv2d_layers\"][\"conv2d_kernel_size_1\"],\n",
    "                           strides=params[\"conv2d_layers\"][\"conv2d_strides_1\"],\n",
    "                           kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_1\"]), \n",
    "                           padding='valid',activation=\"relu\", use_bias=True,\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           input_shape=(x_train[0].shape[0],\n",
    "                                        x_train[0].shape[1], x_train[0].shape[2]))\n",
    "    model.add(conv2d_layer1)\n",
    "    if params[\"conv2d_layers\"]['conv2d_mp_1'] == 1:\n",
    "        model.add(MaxPool2D(pool_size=2))\n",
    "    model.add(Dropout(params['conv2d_layers']['conv2d_do_1']))\n",
    "    if params[\"conv2d_layers\"]['layers'] == 'two':\n",
    "        conv2d_layer2 = Conv2D(params[\"conv2d_layers\"][\"conv2d_filters_2\"],\n",
    "                               params[\"conv2d_layers\"][\"conv2d_kernel_size_2\"],\n",
    "                               strides=params[\"conv2d_layers\"][\"conv2d_strides_2\"],\n",
    "                               kernel_regularizer=regularizers.l2(params[\"conv2d_layers\"][\"kernel_regularizer_2\"]),\n",
    "                               padding='valid',activation=\"relu\", use_bias=True,\n",
    "                               kernel_initializer='glorot_uniform')\n",
    "        model.add(conv2d_layer2)\n",
    "        if params[\"conv2d_layers\"]['conv2d_mp_2'] == 1:\n",
    "            model.add(MaxPool2D(pool_size=2))\n",
    "        model.add(Dropout(params['conv2d_layers']['conv2d_do_2']))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(params['dense_layers'][\"dense_nodes_1\"], activation='relu'))\n",
    "    model.add(Dropout(params['dense_layers']['dense_do_1']))\n",
    "\n",
    "    if params['dense_layers'][\"layers\"] == 'two':\n",
    "        model.add(Dense(params['dense_layers'][\"dense_nodes_2\"], activation='relu', \n",
    "                        kernel_regularizer=params['dense_layers'][\"kernel_regularizer_1\"]))\n",
    "        model.add(Dropout(params['dense_layers']['dense_do_2']))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    if params[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    elif params[\"optimizer\"] == 'sgd':\n",
    "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif params[\"optimizer\"] == 'adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=params[\"lr\"], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_metric])\n",
    "    # from keras.utils.vis_utils import plot_model use this too for diagram with plot\n",
    "    # model.summary(print_fn=lambda x: print(x + '\\n'))\n",
    "    return model\n",
    "\n",
    "def check_baseline(pred, y_test):\n",
    "    print(\"size of test set\", len(y_test))\n",
    "    e = np.equal(pred, y_test)\n",
    "    print(\"TP class counts\", np.unique(y_test[e], return_counts=True))\n",
    "    print(\"True class counts\", np.unique(y_test, return_counts=True))\n",
    "    print(\"Pred class counts\", np.unique(pred, return_counts=True))\n",
    "    holds = np.unique(y_test, return_counts=True)[1][2]  # number 'hold' predictions\n",
    "    print(\"baseline acc:\", (holds/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7XfW5WUfPksH",
    "outputId": "7acd5c5d-7d1b-4666-e093-b0059d928fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params {'batch_size': 80, 'conv2d_layers': {'conv2d_do_1': 0.22, 'conv2d_filters_1': 35, 'conv2d_kernel_size_1': 2, 'conv2d_mp_1': 2, 'conv2d_strides_1': 1, 'kernel_regularizer_1': 0.0, 'conv2d_do_2': 0.05, 'conv2d_filters_2': 20, 'conv2d_kernel_size_2': 2, 'conv2d_mp_2': 2, 'conv2d_strides_2': 2, 'kernel_regularizer_2': 0.0, 'layers': 'two'}, 'dense_layers': {'dense_do_1': 0.22, 'dense_nodes_1': 100, 'kernel_regularizer_1': 0.0, 'layers': 'one'}, 'epochs': 3000, 'lr': 0.001, 'optimizer': 'adam'}\n",
      "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAO/CAYAAABC3jSFAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "\n",
    "model = create_model_cnn(params)\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nn3KW-EJPpKO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "best_model_path = os.path.join('/content/drive/My Drive/Colab Notebooks/cnn output/', 'best_model_keras/bestModel.h5')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                   patience=100, min_delta=0.0001)\n",
    "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'log_training_batch.log'), append=True)\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=20, verbose=1, mode='min',\n",
    "                        min_delta=0.001, cooldown=1, min_lr=0.0001)\n",
    "mcp = ModelCheckpoint(best_model_path, monitor='f1_metric', verbose=1,\n",
    "                      save_best_only=True, save_weights_only=False, mode='max', save_freq=1)  # val_f1_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DVFHWvEaW5qW",
    "outputId": "ea202697-6276-41f8-f06a-e7dc19ad2280"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782,)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VRxojnoNPsLF",
    "outputId": "dec91b77-c72b-4c0b-e938-10ddc1c4b4c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 782 samples, validate on 196 samples\n",
      "Epoch 1/3000\n",
      "\n",
      "Epoch 00001: f1_metric improved from -inf to 0.00000, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 3s - loss: 1.0413 - acc: 0.1562 - f1_metric: 0.0000e+00\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 1.0710 - acc: 0.3086 - f1_metric: 0.0000e+00\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "448/782 [================>.............] - ETA: 0s - loss: 1.0998 - acc: 0.3549 - f1_metric: 0.0000e+00\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 1.0780 - acc: 0.3922 - f1_metric: 0.0000e+00\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00001: f1_metric did not improve from 0.00000\n",
      "782/782 [==============================] - 1s 819us/sample - loss: 1.0982 - acc: 0.4258 - f1_metric: 0.0000e+00 - val_loss: 1.1114 - val_acc: 0.0969 - val_f1_metric: 0.0000e+00\n",
      "Epoch 2/3000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 1.3440 - acc: 0.3594 - f1_metric: 0.0000e+00\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 1.1421 - acc: 0.2812 - f1_metric: 0.0000e+00\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "448/782 [================>.............] - ETA: 0s - loss: 1.1103 - acc: 0.2143 - f1_metric: 0.0000e+00\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 1.0804 - acc: 0.2000 - f1_metric: 0.0000e+00\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: f1_metric did not improve from 0.00000\n",
      "782/782 [==============================] - 0s 354us/sample - loss: 1.0559 - acc: 0.1969 - f1_metric: 0.0000e+00 - val_loss: 1.1289 - val_acc: 0.1071 - val_f1_metric: 0.0000e+00\n",
      "Epoch 3/3000\n",
      "\n",
      "Epoch 00003: f1_metric did not improve from 0.00000\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.7821 - acc: 0.4531 - f1_metric: 0.0000e+00\n",
      "Epoch 00003: f1_metric did not improve from 0.00000\n",
      "\n",
      "Epoch 00003: f1_metric improved from 0.00000 to 0.00980, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.8165 - acc: 0.4792 - f1_metric: 0.0098    \n",
      "Epoch 00003: f1_metric improved from 0.00980 to 0.05596, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.8060 - acc: 0.5469 - f1_metric: 0.0560\n",
      "Epoch 00003: f1_metric improved from 0.05596 to 0.10977, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "320/782 [===========>..................] - ETA: 0s - loss: 0.9005 - acc: 0.5719 - f1_metric: 0.1098\n",
      "Epoch 00003: f1_metric improved from 0.10977 to 0.14909, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "384/782 [=============>................] - ETA: 0s - loss: 1.0296 - acc: 0.5859 - f1_metric: 0.1491\n",
      "Epoch 00003: f1_metric improved from 0.14909 to 0.17717, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.9908 - acc: 0.6071 - f1_metric: 0.1772\n",
      "Epoch 00003: f1_metric improved from 0.17717 to 0.19300, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.9557 - acc: 0.6250 - f1_metric: 0.1930\n",
      "Epoch 00003: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00003: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00003: f1_metric did not improve from 0.19300\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 1.0129 - acc: 0.6094 - f1_metric: 0.1875\n",
      "Epoch 00003: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00003: f1_metric did not improve from 0.19300\n",
      "782/782 [==============================] - 1s 684us/sample - loss: 1.0262 - acc: 0.5895 - f1_metric: 0.1697 - val_loss: 1.1652 - val_acc: 0.0918 - val_f1_metric: 0.0263\n",
      "Epoch 4/3000\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 1.0213 - acc: 0.3438 - f1_metric: 0.0541\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.9643 - acc: 0.2109 - f1_metric: 0.0624\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.9450 - acc: 0.1741 - f1_metric: 0.0459\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.9920 - acc: 0.1719 - f1_metric: 0.0579\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00004: f1_metric did not improve from 0.19300\n",
      "782/782 [==============================] - 0s 358us/sample - loss: 0.9795 - acc: 0.1752 - f1_metric: 0.0526 - val_loss: 1.0986 - val_acc: 0.2143 - val_f1_metric: 0.0490\n",
      "Epoch 5/3000\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.9333 - acc: 0.4219 - f1_metric: 0.1798\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.9012 - acc: 0.4492 - f1_metric: 0.1222\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.9732 - acc: 0.4888 - f1_metric: 0.1687\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.19300\n",
      "\n",
      "Epoch 00005: f1_metric improved from 0.19300 to 0.19551, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.9637 - acc: 0.4984 - f1_metric: 0.1955\n",
      "Epoch 00005: f1_metric improved from 0.19551 to 0.20399, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.9569 - acc: 0.5000 - f1_metric: 0.2040\n",
      "Epoch 00005: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00005: f1_metric did not improve from 0.20399\n",
      "782/782 [==============================] - 0s 503us/sample - loss: 0.9262 - acc: 0.4949 - f1_metric: 0.1969 - val_loss: 1.0793 - val_acc: 0.2908 - val_f1_metric: 0.0829\n",
      "Epoch 6/3000\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.8902 - acc: 0.3750 - f1_metric: 0.1556\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.9257 - acc: 0.3945 - f1_metric: 0.1792\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.9310 - acc: 0.3884 - f1_metric: 0.1903\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "\n",
      "Epoch 00006: f1_metric did not improve from 0.20399\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.9051 - acc: 0.3828 - f1_metric: 0.1948\n",
      "Epoch 00006: f1_metric improved from 0.20399 to 0.20602, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.8745 - acc: 0.3864 - f1_metric: 0.2060\n",
      "Epoch 00006: f1_metric improved from 0.20602 to 0.21367, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.8749 - acc: 0.3919 - f1_metric: 0.2137\n",
      "Epoch 00006: f1_metric improved from 0.21367 to 0.21730, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "782/782 [==============================] - 0s 588us/sample - loss: 0.8776 - acc: 0.3926 - f1_metric: 0.2173 - val_loss: 1.0313 - val_acc: 0.3929 - val_f1_metric: 0.2703\n",
      "Epoch 7/3000\n",
      "\n",
      "Epoch 00007: f1_metric improved from 0.21730 to 0.44444, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.8214 - acc: 0.5000 - f1_metric: 0.4444\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.7828 - acc: 0.4570 - f1_metric: 0.4118\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.8008 - acc: 0.4888 - f1_metric: 0.4341\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.8373 - acc: 0.4703 - f1_metric: 0.4013\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00007: f1_metric did not improve from 0.44444\n",
      "782/782 [==============================] - 0s 407us/sample - loss: 0.8165 - acc: 0.4476 - f1_metric: 0.3707 - val_loss: 1.2206 - val_acc: 0.2449 - val_f1_metric: 0.1942\n",
      "Epoch 8/3000\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6527 - acc: 0.2500 - f1_metric: 0.2069\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.8058 - acc: 0.3789 - f1_metric: 0.2649\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.7803 - acc: 0.4420 - f1_metric: 0.3522\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.7803 - acc: 0.4594 - f1_metric: 0.3702\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "\n",
      "Epoch 00008: f1_metric did not improve from 0.44444\n",
      "782/782 [==============================] - 0s 348us/sample - loss: 0.7765 - acc: 0.4744 - f1_metric: 0.3853 - val_loss: 0.9555 - val_acc: 0.4490 - val_f1_metric: 0.3507\n",
      "Epoch 9/3000\n",
      "\n",
      "Epoch 00009: f1_metric improved from 0.44444 to 0.48696, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.7727 - acc: 0.5312 - f1_metric: 0.4870\n",
      "Epoch 00009: f1_metric improved from 0.48696 to 0.49573, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "128/782 [===>..........................] - ETA: 0s - loss: 0.7204 - acc: 0.5312 - f1_metric: 0.4957\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "320/782 [===========>..................] - ETA: 0s - loss: 0.7793 - acc: 0.4969 - f1_metric: 0.4465\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.8180 - acc: 0.4883 - f1_metric: 0.4444\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.7794 - acc: 0.4659 - f1_metric: 0.4220\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00009: f1_metric did not improve from 0.49573\n",
      "782/782 [==============================] - 0s 473us/sample - loss: 0.7573 - acc: 0.4604 - f1_metric: 0.4294 - val_loss: 1.0503 - val_acc: 0.3622 - val_f1_metric: 0.4181\n",
      "Epoch 10/3000\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.7074 - acc: 0.4375 - f1_metric: 0.3670\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.7028 - acc: 0.4414 - f1_metric: 0.3924\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.6959 - acc: 0.4509 - f1_metric: 0.4036\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.7400 - acc: 0.4719 - f1_metric: 0.4191\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "\n",
      "Epoch 00010: f1_metric did not improve from 0.49573\n",
      "782/782 [==============================] - 0s 365us/sample - loss: 0.7286 - acc: 0.4987 - f1_metric: 0.4646 - val_loss: 0.8549 - val_acc: 0.5255 - val_f1_metric: 0.4390\n",
      "Epoch 11/3000\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.49573\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6164 - acc: 0.5156 - f1_metric: 0.4576\n",
      "Epoch 00011: f1_metric improved from 0.49573 to 0.56780, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "128/782 [===>..........................] - ETA: 0s - loss: 0.5257 - acc: 0.6172 - f1_metric: 0.5678\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "320/782 [===========>..................] - ETA: 0s - loss: 0.7029 - acc: 0.5719 - f1_metric: 0.5336\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.7004 - acc: 0.5723 - f1_metric: 0.5312\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.7015 - acc: 0.5384 - f1_metric: 0.4978\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00011: f1_metric did not improve from 0.56780\n",
      "782/782 [==============================] - 0s 409us/sample - loss: 0.7171 - acc: 0.5320 - f1_metric: 0.4637 - val_loss: 1.2384 - val_acc: 0.3265 - val_f1_metric: 0.2431\n",
      "Epoch 12/3000\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6347 - acc: 0.3438 - f1_metric: 0.2807\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.8311 - acc: 0.3594 - f1_metric: 0.3158\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.8426 - acc: 0.3802 - f1_metric: 0.3325\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.7485 - acc: 0.4253 - f1_metric: 0.3841\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.7006 - acc: 0.4674 - f1_metric: 0.4274\n",
      "Epoch 00012: f1_metric did not improve from 0.56780\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.6937 - acc: 0.4693 - f1_metric: 0.4376 - val_loss: 0.7098 - val_acc: 0.6429 - val_f1_metric: 0.5067\n",
      "Epoch 13/3000\n",
      "\n",
      "Epoch 00013: f1_metric improved from 0.56780 to 0.68376, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.9235 - acc: 0.7188 - f1_metric: 0.6838\n",
      "Epoch 00013: f1_metric improved from 0.68376 to 0.68614, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "128/782 [===>..........................] - ETA: 0s - loss: 0.8104 - acc: 0.7109 - f1_metric: 0.6861\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "320/782 [===========>..................] - ETA: 0s - loss: 0.7916 - acc: 0.6531 - f1_metric: 0.6347\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.6875 - acc: 0.5957 - f1_metric: 0.5615\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.6709 - acc: 0.5668 - f1_metric: 0.5348\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00013: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 461us/sample - loss: 0.6706 - acc: 0.5588 - f1_metric: 0.5236 - val_loss: 0.9407 - val_acc: 0.4439 - val_f1_metric: 0.4625\n",
      "Epoch 14/3000\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6835 - acc: 0.4531 - f1_metric: 0.4310\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6067 - acc: 0.5117 - f1_metric: 0.4914\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5693 - acc: 0.5223 - f1_metric: 0.4878\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.6292 - acc: 0.5609 - f1_metric: 0.5203\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00014: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 354us/sample - loss: 0.6339 - acc: 0.5767 - f1_metric: 0.5364 - val_loss: 1.0228 - val_acc: 0.4235 - val_f1_metric: 0.4901\n",
      "Epoch 15/3000\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.7615 - acc: 0.3438 - f1_metric: 0.3529\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6630 - acc: 0.3984 - f1_metric: 0.3722\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.6434 - acc: 0.3884 - f1_metric: 0.3572\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.6365 - acc: 0.4094 - f1_metric: 0.3766\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00015: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 365us/sample - loss: 0.6456 - acc: 0.4412 - f1_metric: 0.4246 - val_loss: 0.7771 - val_acc: 0.5459 - val_f1_metric: 0.6057\n",
      "Epoch 16/3000\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6522 - acc: 0.6875 - f1_metric: 0.6829\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5899 - acc: 0.6328 - f1_metric: 0.6039\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5527 - acc: 0.6473 - f1_metric: 0.6288\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5988 - acc: 0.6453 - f1_metric: 0.6223\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00016: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 358us/sample - loss: 0.6298 - acc: 0.6151 - f1_metric: 0.5842 - val_loss: 1.0135 - val_acc: 0.4082 - val_f1_metric: 0.3509\n",
      "Epoch 17/3000\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.5713 - acc: 0.6406 - f1_metric: 0.6400\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6795 - acc: 0.4492 - f1_metric: 0.4310\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.6260 - acc: 0.4442 - f1_metric: 0.4266\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.6562 - acc: 0.4469 - f1_metric: 0.4276\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00017: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 0.6432 - acc: 0.4731 - f1_metric: 0.4629 - val_loss: 0.7418 - val_acc: 0.6020 - val_f1_metric: 0.5680\n",
      "Epoch 18/3000\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6194 - acc: 0.5469 - f1_metric: 0.5600\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6021 - acc: 0.6484 - f1_metric: 0.6427\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.6067 - acc: 0.6146 - f1_metric: 0.5965\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.5818 - acc: 0.6074 - f1_metric: 0.5842\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.5836 - acc: 0.6051 - f1_metric: 0.5877\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00018: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 417us/sample - loss: 0.5872 - acc: 0.6100 - f1_metric: 0.5982 - val_loss: 0.8727 - val_acc: 0.4847 - val_f1_metric: 0.4182\n",
      "Epoch 19/3000\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6861 - acc: 0.5469 - f1_metric: 0.5366\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5600 - acc: 0.5352 - f1_metric: 0.5010\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5615 - acc: 0.5312 - f1_metric: 0.4935\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.6114 - acc: 0.5281 - f1_metric: 0.4957\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00019: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 385us/sample - loss: 0.5983 - acc: 0.5320 - f1_metric: 0.4988 - val_loss: 0.8280 - val_acc: 0.5816 - val_f1_metric: 0.5541\n",
      "Epoch 20/3000\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6444 - acc: 0.6406 - f1_metric: 0.5714\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6677 - acc: 0.5938 - f1_metric: 0.5771\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.6115 - acc: 0.5915 - f1_metric: 0.5807\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5959 - acc: 0.6109 - f1_metric: 0.5938\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00020: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 368us/sample - loss: 0.5610 - acc: 0.6176 - f1_metric: 0.5886 - val_loss: 0.8027 - val_acc: 0.5459 - val_f1_metric: 0.4530\n",
      "Epoch 21/3000\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6357 - acc: 0.5469 - f1_metric: 0.5645\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6158 - acc: 0.5586 - f1_metric: 0.5358\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5642 - acc: 0.5491 - f1_metric: 0.5162\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5658 - acc: 0.5422 - f1_metric: 0.5105\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00021: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 367us/sample - loss: 0.5647 - acc: 0.5396 - f1_metric: 0.5166 - val_loss: 0.7527 - val_acc: 0.5663 - val_f1_metric: 0.5574\n",
      "Epoch 22/3000\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3479 - acc: 0.6094 - f1_metric: 0.5854\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5321 - acc: 0.6680 - f1_metric: 0.6581\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5271 - acc: 0.6674 - f1_metric: 0.6587\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5385 - acc: 0.6562 - f1_metric: 0.6383\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00022: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 371us/sample - loss: 0.5497 - acc: 0.6407 - f1_metric: 0.6121 - val_loss: 0.9360 - val_acc: 0.4592 - val_f1_metric: 0.5100\n",
      "Epoch 23/3000\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3615 - acc: 0.4688 - f1_metric: 0.4538\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5057 - acc: 0.5039 - f1_metric: 0.4854\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.6088 - acc: 0.5223 - f1_metric: 0.5092\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.6114 - acc: 0.5297 - f1_metric: 0.5077\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00023: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 371us/sample - loss: 0.5730 - acc: 0.5332 - f1_metric: 0.5030 - val_loss: 0.8577 - val_acc: 0.5357 - val_f1_metric: 0.4541\n",
      "Epoch 24/3000\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4029 - acc: 0.5469 - f1_metric: 0.5289\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5245 - acc: 0.6016 - f1_metric: 0.5926\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5400 - acc: 0.6272 - f1_metric: 0.6176\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5194 - acc: 0.6547 - f1_metric: 0.6483\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00024: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 388us/sample - loss: 0.5191 - acc: 0.6573 - f1_metric: 0.6626 - val_loss: 0.8505 - val_acc: 0.5408 - val_f1_metric: 0.5155\n",
      "Epoch 25/3000\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4134 - acc: 0.6719 - f1_metric: 0.6393\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4790 - acc: 0.5742 - f1_metric: 0.5550\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5479 - acc: 0.5469 - f1_metric: 0.5332\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5379 - acc: 0.5656 - f1_metric: 0.5543\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "\n",
      "Epoch 00025: f1_metric did not improve from 0.68614\n",
      "782/782 [==============================] - 0s 375us/sample - loss: 0.5167 - acc: 0.5831 - f1_metric: 0.5769 - val_loss: 0.7408 - val_acc: 0.6429 - val_f1_metric: 0.6990\n",
      "Epoch 26/3000\n",
      "\n",
      "Epoch 00026: f1_metric improved from 0.68614 to 0.69355, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4539 - acc: 0.7188 - f1_metric: 0.6935\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4553 - acc: 0.6406 - f1_metric: 0.6172\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4650 - acc: 0.6429 - f1_metric: 0.6302\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.4734 - acc: 0.6632 - f1_metric: 0.6456\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.5058 - acc: 0.6536 - f1_metric: 0.6426\n",
      "Epoch 00026: f1_metric did not improve from 0.69355\n",
      "782/782 [==============================] - 0s 451us/sample - loss: 0.5044 - acc: 0.6522 - f1_metric: 0.6371 - val_loss: 0.8441 - val_acc: 0.5255 - val_f1_metric: 0.5040\n",
      "Epoch 27/3000\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4245 - acc: 0.6562 - f1_metric: 0.6452\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5360 - acc: 0.6211 - f1_metric: 0.6033\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5416 - acc: 0.5580 - f1_metric: 0.5421\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5175 - acc: 0.5391 - f1_metric: 0.5197\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "\n",
      "Epoch 00027: f1_metric did not improve from 0.69355\n",
      "782/782 [==============================] - 0s 369us/sample - loss: 0.5050 - acc: 0.5486 - f1_metric: 0.5380 - val_loss: 0.6366 - val_acc: 0.6633 - val_f1_metric: 0.6363\n",
      "Epoch 28/3000\n",
      "\n",
      "Epoch 00028: f1_metric improved from 0.69355 to 0.74797, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3790 - acc: 0.7812 - f1_metric: 0.7480\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5316 - acc: 0.7070 - f1_metric: 0.6962\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4898 - acc: 0.6920 - f1_metric: 0.6866\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4868 - acc: 0.6625 - f1_metric: 0.6532\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00028: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 402us/sample - loss: 0.4989 - acc: 0.6343 - f1_metric: 0.6238 - val_loss: 0.8091 - val_acc: 0.5510 - val_f1_metric: 0.5244\n",
      "Epoch 29/3000\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.5251 - acc: 0.6406 - f1_metric: 0.6167\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4286 - acc: 0.6406 - f1_metric: 0.6246\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4623 - acc: 0.6362 - f1_metric: 0.6168\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5250 - acc: 0.6328 - f1_metric: 0.6173\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00029: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 363us/sample - loss: 0.5069 - acc: 0.6292 - f1_metric: 0.6137 - val_loss: 0.7735 - val_acc: 0.5867 - val_f1_metric: 0.4950\n",
      "Epoch 30/3000\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4711 - acc: 0.5156 - f1_metric: 0.5161\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4837 - acc: 0.6328 - f1_metric: 0.6229\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5144 - acc: 0.6384 - f1_metric: 0.6272\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.5166 - acc: 0.6424 - f1_metric: 0.6354\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.6497 - f1_metric: 0.6361\n",
      "Epoch 00030: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 393us/sample - loss: 0.4894 - acc: 0.6535 - f1_metric: 0.6498 - val_loss: 0.7228 - val_acc: 0.5969 - val_f1_metric: 0.6864\n",
      "Epoch 31/3000\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4672 - acc: 0.6562 - f1_metric: 0.6400\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5513 - acc: 0.5859 - f1_metric: 0.5728\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5276 - acc: 0.6116 - f1_metric: 0.5952\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4823 - acc: 0.6250 - f1_metric: 0.6073\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00031: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 371us/sample - loss: 0.4738 - acc: 0.6458 - f1_metric: 0.6253 - val_loss: 0.6454 - val_acc: 0.6531 - val_f1_metric: 0.6141\n",
      "Epoch 32/3000\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.6094 - acc: 0.6094 - f1_metric: 0.6190\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5169 - acc: 0.6445 - f1_metric: 0.6357\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5360 - acc: 0.6719 - f1_metric: 0.6597\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5245 - acc: 0.6328 - f1_metric: 0.6192\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00032: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 372us/sample - loss: 0.5006 - acc: 0.6087 - f1_metric: 0.5830 - val_loss: 0.7430 - val_acc: 0.5969 - val_f1_metric: 0.6111\n",
      "Epoch 33/3000\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3684 - acc: 0.5938 - f1_metric: 0.5600\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3579 - acc: 0.6875 - f1_metric: 0.6760\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3601 - acc: 0.7321 - f1_metric: 0.7255\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4465 - acc: 0.7375 - f1_metric: 0.7316\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00033: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 383us/sample - loss: 0.4796 - acc: 0.7084 - f1_metric: 0.6852 - val_loss: 0.8341 - val_acc: 0.5459 - val_f1_metric: 0.5241\n",
      "Epoch 34/3000\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.7051 - acc: 0.4219 - f1_metric: 0.4098\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5560 - acc: 0.5156 - f1_metric: 0.5082\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5041 - acc: 0.5469 - f1_metric: 0.5316\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4735 - acc: 0.5500 - f1_metric: 0.5316\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00034: f1_metric did not improve from 0.74797\n",
      "782/782 [==============================] - 0s 363us/sample - loss: 0.4722 - acc: 0.5793 - f1_metric: 0.5709 - val_loss: 0.5773 - val_acc: 0.7041 - val_f1_metric: 0.6499\n",
      "Epoch 35/3000\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.74797\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4893 - acc: 0.6250 - f1_metric: 0.6080\n",
      "Epoch 00035: f1_metric did not improve from 0.74797\n",
      "\n",
      "Epoch 00035: f1_metric improved from 0.74797 to 0.75068, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.4206 - acc: 0.7552 - f1_metric: 0.7507\n",
      "Epoch 00035: f1_metric improved from 0.75068 to 0.77501, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4288 - acc: 0.7773 - f1_metric: 0.7750\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4587 - acc: 0.7500 - f1_metric: 0.7466\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4535 - acc: 0.7234 - f1_metric: 0.7143\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00035: f1_metric did not improve from 0.77501\n",
      "782/782 [==============================] - 0s 474us/sample - loss: 0.4615 - acc: 0.7008 - f1_metric: 0.6985 - val_loss: 0.7725 - val_acc: 0.5969 - val_f1_metric: 0.5572\n",
      "Epoch 36/3000\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.5666 - acc: 0.5312 - f1_metric: 0.5041\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.6191 - acc: 0.6016 - f1_metric: 0.5904\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5380 - acc: 0.6027 - f1_metric: 0.5919\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.5028 - acc: 0.5891 - f1_metric: 0.5753\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00036: f1_metric did not improve from 0.77501\n",
      "782/782 [==============================] - 0s 375us/sample - loss: 0.4842 - acc: 0.6074 - f1_metric: 0.6005 - val_loss: 0.6420 - val_acc: 0.6633 - val_f1_metric: 0.6194\n",
      "Epoch 37/3000\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.7660 - acc: 0.6406 - f1_metric: 0.6341\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.5209 - acc: 0.6992 - f1_metric: 0.6907\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4363 - acc: 0.7121 - f1_metric: 0.6964\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4099 - acc: 0.7234 - f1_metric: 0.7113\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00037: f1_metric did not improve from 0.77501\n",
      "782/782 [==============================] - 0s 376us/sample - loss: 0.4142 - acc: 0.7148 - f1_metric: 0.6943 - val_loss: 0.5846 - val_acc: 0.7041 - val_f1_metric: 0.6541\n",
      "Epoch 38/3000\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3686 - acc: 0.7188 - f1_metric: 0.7187\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4320 - acc: 0.7344 - f1_metric: 0.7283\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4315 - acc: 0.7165 - f1_metric: 0.7102\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4277 - acc: 0.7109 - f1_metric: 0.7031\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00038: f1_metric did not improve from 0.77501\n",
      "782/782 [==============================] - 0s 365us/sample - loss: 0.4147 - acc: 0.6893 - f1_metric: 0.6778 - val_loss: 0.7168 - val_acc: 0.6224 - val_f1_metric: 0.6741\n",
      "Epoch 39/3000\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2728 - acc: 0.6250 - f1_metric: 0.6250\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3205 - acc: 0.6836 - f1_metric: 0.6733\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3375 - acc: 0.7612 - f1_metric: 0.7548\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4223 - acc: 0.7734 - f1_metric: 0.7674\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00039: f1_metric did not improve from 0.77501\n",
      "782/782 [==============================] - 0s 370us/sample - loss: 0.4214 - acc: 0.7494 - f1_metric: 0.7417 - val_loss: 0.8808 - val_acc: 0.5102 - val_f1_metric: 0.4509\n",
      "Epoch 40/3000\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4374 - acc: 0.5469 - f1_metric: 0.5323\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4964 - acc: 0.5391 - f1_metric: 0.5271\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4633 - acc: 0.5312 - f1_metric: 0.5183\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4465 - acc: 0.5531 - f1_metric: 0.5403\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "\n",
      "Epoch 00040: f1_metric did not improve from 0.77501\n",
      "782/782 [==============================] - 0s 367us/sample - loss: 0.4298 - acc: 0.5882 - f1_metric: 0.5857 - val_loss: 0.4756 - val_acc: 0.7653 - val_f1_metric: 0.7645\n",
      "Epoch 41/3000\n",
      "\n",
      "Epoch 00041: f1_metric improved from 0.77501 to 0.79365, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.5640 - acc: 0.7969 - f1_metric: 0.7937\n",
      "Epoch 00041: f1_metric did not improve from 0.79365\n",
      "\n",
      "Epoch 00041: f1_metric improved from 0.79365 to 0.79894, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.4423 - acc: 0.8021 - f1_metric: 0.7989\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.4519 - acc: 0.7682 - f1_metric: 0.7584\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.4087 - acc: 0.7656 - f1_metric: 0.7600\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.4018 - acc: 0.7526 - f1_metric: 0.7468\n",
      "Epoch 00041: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 477us/sample - loss: 0.3997 - acc: 0.7506 - f1_metric: 0.7388 - val_loss: 0.6956 - val_acc: 0.6378 - val_f1_metric: 0.5345\n",
      "Epoch 42/3000\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4054 - acc: 0.6875 - f1_metric: 0.6720\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4143 - acc: 0.6367 - f1_metric: 0.6293\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3839 - acc: 0.6607 - f1_metric: 0.6528\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4046 - acc: 0.6828 - f1_metric: 0.6754\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00042: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 375us/sample - loss: 0.4080 - acc: 0.7020 - f1_metric: 0.7008 - val_loss: 0.6168 - val_acc: 0.7041 - val_f1_metric: 0.7299\n",
      "Epoch 43/3000\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4209 - acc: 0.7188 - f1_metric: 0.6880\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4910 - acc: 0.6758 - f1_metric: 0.6522\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.5100 - acc: 0.6384 - f1_metric: 0.6075\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4875 - acc: 0.6031 - f1_metric: 0.5761\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00043: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 366us/sample - loss: 0.4741 - acc: 0.6023 - f1_metric: 0.5787 - val_loss: 0.6975 - val_acc: 0.6429 - val_f1_metric: 0.5318\n",
      "Epoch 44/3000\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4006 - acc: 0.6719 - f1_metric: 0.6772\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3887 - acc: 0.6914 - f1_metric: 0.6810\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3552 - acc: 0.7433 - f1_metric: 0.7310\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4334 - acc: 0.7312 - f1_metric: 0.7235\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00044: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 368us/sample - loss: 0.4341 - acc: 0.7084 - f1_metric: 0.6903 - val_loss: 0.6762 - val_acc: 0.6378 - val_f1_metric: 0.6491\n",
      "Epoch 45/3000\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.5352 - acc: 0.7500 - f1_metric: 0.7581\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4431 - acc: 0.6445 - f1_metric: 0.6373\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.4103 - acc: 0.6585 - f1_metric: 0.6476\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.4030 - acc: 0.6547 - f1_metric: 0.6378\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00045: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.3929 - acc: 0.6650 - f1_metric: 0.6612 - val_loss: 0.5159 - val_acc: 0.7602 - val_f1_metric: 0.6975\n",
      "Epoch 46/3000\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2698 - acc: 0.7188 - f1_metric: 0.7244\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3846 - acc: 0.7461 - f1_metric: 0.7364\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3562 - acc: 0.7500 - f1_metric: 0.7431\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3777 - acc: 0.7531 - f1_metric: 0.7459\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00046: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 369us/sample - loss: 0.3672 - acc: 0.7366 - f1_metric: 0.7250 - val_loss: 0.6404 - val_acc: 0.6684 - val_f1_metric: 0.6819\n",
      "Epoch 47/3000\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4698 - acc: 0.6719 - f1_metric: 0.6719\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3948 - acc: 0.7188 - f1_metric: 0.7145\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3658 - acc: 0.7277 - f1_metric: 0.7218\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3563 - acc: 0.7484 - f1_metric: 0.7418\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00047: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 379us/sample - loss: 0.3517 - acc: 0.7468 - f1_metric: 0.7496 - val_loss: 0.5940 - val_acc: 0.7041 - val_f1_metric: 0.7750\n",
      "Epoch 48/3000\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4387 - acc: 0.6406 - f1_metric: 0.6349\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.4195 - acc: 0.7305 - f1_metric: 0.7230\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3680 - acc: 0.7344 - f1_metric: 0.7287\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3653 - acc: 0.7250 - f1_metric: 0.7195\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00048: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 384us/sample - loss: 0.3611 - acc: 0.7263 - f1_metric: 0.7113 - val_loss: 0.6279 - val_acc: 0.6939 - val_f1_metric: 0.7208\n",
      "Epoch 49/3000\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3551 - acc: 0.6719 - f1_metric: 0.6772\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3007 - acc: 0.7383 - f1_metric: 0.7354\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3386 - acc: 0.7299 - f1_metric: 0.7262\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3439 - acc: 0.7375 - f1_metric: 0.7340\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "\n",
      "Epoch 00049: f1_metric did not improve from 0.79894\n",
      "782/782 [==============================] - 0s 366us/sample - loss: 0.3453 - acc: 0.7442 - f1_metric: 0.7461 - val_loss: 0.5084 - val_acc: 0.7602 - val_f1_metric: 0.7529\n",
      "Epoch 50/3000\n",
      "\n",
      "Epoch 00050: f1_metric improved from 0.79894 to 0.80315, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2737 - acc: 0.7969 - f1_metric: 0.8031\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3506 - acc: 0.7461 - f1_metric: 0.7405\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3487 - acc: 0.7545 - f1_metric: 0.7507\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3378 - acc: 0.7672 - f1_metric: 0.7623\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "\n",
      "Epoch 00050: f1_metric did not improve from 0.80315\n",
      "782/782 [==============================] - 0s 424us/sample - loss: 0.3289 - acc: 0.7634 - f1_metric: 0.7491 - val_loss: 0.5527 - val_acc: 0.7602 - val_f1_metric: 0.6915\n",
      "Epoch 51/3000\n",
      "\n",
      "Epoch 00051: f1_metric improved from 0.80315 to 0.84127, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2781 - acc: 0.8281 - f1_metric: 0.8413\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3359 - acc: 0.7578 - f1_metric: 0.7573\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3540 - acc: 0.7165 - f1_metric: 0.7119\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3468 - acc: 0.7266 - f1_metric: 0.7217\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00051: f1_metric did not improve from 0.84127\n",
      "782/782 [==============================] - 0s 400us/sample - loss: 0.3341 - acc: 0.7340 - f1_metric: 0.7280 - val_loss: 0.4493 - val_acc: 0.8112 - val_f1_metric: 0.7939\n",
      "Epoch 52/3000\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2763 - acc: 0.7969 - f1_metric: 0.8031\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.3216 - acc: 0.8333 - f1_metric: 0.8316\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.4229 - acc: 0.8177 - f1_metric: 0.8184\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.4040 - acc: 0.7951 - f1_metric: 0.7956\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.3953 - acc: 0.7383 - f1_metric: 0.7369\n",
      "Epoch 00052: f1_metric did not improve from 0.84127\n",
      "782/782 [==============================] - 0s 405us/sample - loss: 0.4002 - acc: 0.7366 - f1_metric: 0.7296 - val_loss: 0.7778 - val_acc: 0.6224 - val_f1_metric: 0.6468\n",
      "Epoch 53/3000\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2760 - acc: 0.6250 - f1_metric: 0.6179\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3009 - acc: 0.6719 - f1_metric: 0.6623\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3165 - acc: 0.7031 - f1_metric: 0.6978\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3757 - acc: 0.7359 - f1_metric: 0.7304\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00053: f1_metric did not improve from 0.84127\n",
      "782/782 [==============================] - 0s 374us/sample - loss: 0.3578 - acc: 0.7379 - f1_metric: 0.7287 - val_loss: 0.5243 - val_acc: 0.7551 - val_f1_metric: 0.7498\n",
      "Epoch 54/3000\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2097 - acc: 0.8125 - f1_metric: 0.8000\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2866 - acc: 0.7188 - f1_metric: 0.7030\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2984 - acc: 0.7076 - f1_metric: 0.6971\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2979 - acc: 0.7344 - f1_metric: 0.7274\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00054: f1_metric did not improve from 0.84127\n",
      "782/782 [==============================] - 0s 373us/sample - loss: 0.3126 - acc: 0.7391 - f1_metric: 0.7300 - val_loss: 0.5179 - val_acc: 0.7755 - val_f1_metric: 0.8238\n",
      "Epoch 55/3000\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4782 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3249 - acc: 0.7734 - f1_metric: 0.7699\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3556 - acc: 0.7321 - f1_metric: 0.7280\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3610 - acc: 0.7063 - f1_metric: 0.7015\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00055: f1_metric did not improve from 0.84127\n",
      "782/782 [==============================] - 0s 364us/sample - loss: 0.3422 - acc: 0.7059 - f1_metric: 0.7028 - val_loss: 0.4811 - val_acc: 0.7908 - val_f1_metric: 0.8410\n",
      "Epoch 56/3000\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84127\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2424 - acc: 0.7500 - f1_metric: 0.7559\n",
      "Epoch 00056: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84127\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3184 - acc: 0.8242 - f1_metric: 0.8235\n",
      "Epoch 00056: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84127\n",
      "\n",
      "Epoch 00056: f1_metric improved from 0.84127 to 0.84560, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3329 - acc: 0.8460 - f1_metric: 0.8456\n",
      "Epoch 00056: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84560\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3581 - acc: 0.8359 - f1_metric: 0.8361\n",
      "Epoch 00056: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00056: f1_metric did not improve from 0.84560\n",
      "782/782 [==============================] - 0s 426us/sample - loss: 0.3430 - acc: 0.8146 - f1_metric: 0.8002 - val_loss: 0.7464 - val_acc: 0.6684 - val_f1_metric: 0.6774\n",
      "Epoch 57/3000\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3956 - acc: 0.6094 - f1_metric: 0.6240\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3368 - acc: 0.6797 - f1_metric: 0.6719\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3364 - acc: 0.6830 - f1_metric: 0.6735\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3105 - acc: 0.7047 - f1_metric: 0.6956\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "\n",
      "Epoch 00057: f1_metric did not improve from 0.84560\n",
      "782/782 [==============================] - 0s 369us/sample - loss: 0.3179 - acc: 0.7251 - f1_metric: 0.7277 - val_loss: 0.4081 - val_acc: 0.8265 - val_f1_metric: 0.8651\n",
      "Epoch 58/3000\n",
      "\n",
      "Epoch 00058: f1_metric improved from 0.84560 to 0.89062, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1922 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2425 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2820 - acc: 0.8482 - f1_metric: 0.8492\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3724 - acc: 0.8266 - f1_metric: 0.8263\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00058: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 405us/sample - loss: 0.3569 - acc: 0.8069 - f1_metric: 0.8121 - val_loss: 0.8016 - val_acc: 0.5816 - val_f1_metric: 0.5022\n",
      "Epoch 59/3000\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3188 - acc: 0.5938 - f1_metric: 0.5984\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3127 - acc: 0.6367 - f1_metric: 0.6362\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3321 - acc: 0.6473 - f1_metric: 0.6394\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3320 - acc: 0.6734 - f1_metric: 0.6644\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00059: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 372us/sample - loss: 0.3313 - acc: 0.7072 - f1_metric: 0.7028 - val_loss: 0.4842 - val_acc: 0.7857 - val_f1_metric: 0.7740\n",
      "Epoch 60/3000\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4041 - acc: 0.7969 - f1_metric: 0.7969\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3165 - acc: 0.7422 - f1_metric: 0.7427\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3130 - acc: 0.7344 - f1_metric: 0.7343\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3308 - acc: 0.7156 - f1_metric: 0.7164\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00060: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 380us/sample - loss: 0.3142 - acc: 0.7289 - f1_metric: 0.7362 - val_loss: 0.5070 - val_acc: 0.7755 - val_f1_metric: 0.7718\n",
      "Epoch 61/3000\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3572 - acc: 0.7500 - f1_metric: 0.7500\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3188 - acc: 0.7695 - f1_metric: 0.7699\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2974 - acc: 0.7612 - f1_metric: 0.7617\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2946 - acc: 0.7625 - f1_metric: 0.7635\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00061: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 364us/sample - loss: 0.2845 - acc: 0.7737 - f1_metric: 0.7794 - val_loss: 0.4433 - val_acc: 0.8163 - val_f1_metric: 0.8570\n",
      "Epoch 62/3000\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3676 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.2843 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.2784 - acc: 0.8177 - f1_metric: 0.8173\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.2808 - acc: 0.8021 - f1_metric: 0.8025\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.8021 - f1_metric: 0.8021\n",
      "Epoch 00062: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.2906 - acc: 0.8056 - f1_metric: 0.8174 - val_loss: 0.5720 - val_acc: 0.7398 - val_f1_metric: 0.6851\n",
      "Epoch 63/3000\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3177 - acc: 0.6875 - f1_metric: 0.6875\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3169 - acc: 0.7070 - f1_metric: 0.7034\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.3141 - acc: 0.7277 - f1_metric: 0.7273\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2974 - acc: 0.7406 - f1_metric: 0.7409\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00063: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 380us/sample - loss: 0.3001 - acc: 0.7609 - f1_metric: 0.7619 - val_loss: 0.4369 - val_acc: 0.8367 - val_f1_metric: 0.8197\n",
      "Epoch 64/3000\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2034 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.3393 - acc: 0.7552 - f1_metric: 0.7572\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.3809 - acc: 0.7396 - f1_metric: 0.7381\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.3418 - acc: 0.7188 - f1_metric: 0.7143\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.7174 - f1_metric: 0.7138\n",
      "Epoch 00064: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 394us/sample - loss: 0.3293 - acc: 0.7199 - f1_metric: 0.7248 - val_loss: 0.5792 - val_acc: 0.7347 - val_f1_metric: 0.7973\n",
      "Epoch 65/3000\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3517 - acc: 0.7500 - f1_metric: 0.7200\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.3111 - acc: 0.7708 - f1_metric: 0.7628\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.3571 - acc: 0.8125 - f1_metric: 0.8055\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.3160 - acc: 0.8125 - f1_metric: 0.8079\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2924 - acc: 0.8177 - f1_metric: 0.8142\n",
      "Epoch 00065: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 385us/sample - loss: 0.2900 - acc: 0.8171 - f1_metric: 0.8120 - val_loss: 0.4970 - val_acc: 0.7806 - val_f1_metric: 0.7790\n",
      "Epoch 66/3000\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2132 - acc: 0.8750 - f1_metric: 0.8571\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3003 - acc: 0.8047 - f1_metric: 0.7993\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2898 - acc: 0.7991 - f1_metric: 0.7956\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2821 - acc: 0.7969 - f1_metric: 0.7947\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00066: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.2746 - acc: 0.7903 - f1_metric: 0.7888 - val_loss: 0.4961 - val_acc: 0.7806 - val_f1_metric: 0.7749\n",
      "Epoch 67/3000\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1869 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3112 - acc: 0.8398 - f1_metric: 0.8353\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2860 - acc: 0.8661 - f1_metric: 0.8635\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3220 - acc: 0.8562 - f1_metric: 0.8544\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00067: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.3085 - acc: 0.8376 - f1_metric: 0.8292 - val_loss: 0.6646 - val_acc: 0.6939 - val_f1_metric: 0.7668\n",
      "Epoch 68/3000\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3567 - acc: 0.6562 - f1_metric: 0.6562\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2995 - acc: 0.6992 - f1_metric: 0.6958\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2804 - acc: 0.7433 - f1_metric: 0.7404\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.3041 - acc: 0.7609 - f1_metric: 0.7598\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00068: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 368us/sample - loss: 0.3103 - acc: 0.7647 - f1_metric: 0.7613 - val_loss: 0.5250 - val_acc: 0.7653 - val_f1_metric: 0.8154\n",
      "Epoch 69/3000\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3186 - acc: 0.7656 - f1_metric: 0.7460\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2782 - acc: 0.7891 - f1_metric: 0.7824\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2434 - acc: 0.7902 - f1_metric: 0.7864\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2548 - acc: 0.7828 - f1_metric: 0.7791\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00069: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 373us/sample - loss: 0.2457 - acc: 0.7928 - f1_metric: 0.7901 - val_loss: 0.4145 - val_acc: 0.8367 - val_f1_metric: 0.8097\n",
      "Epoch 70/3000\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3086 - acc: 0.7500 - f1_metric: 0.7500\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2719 - acc: 0.8164 - f1_metric: 0.8164\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2400 - acc: 0.8237 - f1_metric: 0.8234\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2537 - acc: 0.8297 - f1_metric: 0.8295\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00070: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 0.2595 - acc: 0.8235 - f1_metric: 0.8259 - val_loss: 0.5110 - val_acc: 0.7908 - val_f1_metric: 0.7156\n",
      "Epoch 71/3000\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1592 - acc: 0.8438 - f1_metric: 0.8346\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2921 - acc: 0.8242 - f1_metric: 0.8196\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2743 - acc: 0.7991 - f1_metric: 0.7973\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2656 - acc: 0.8047 - f1_metric: 0.7986\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00071: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 373us/sample - loss: 0.2566 - acc: 0.8005 - f1_metric: 0.7869 - val_loss: 0.4164 - val_acc: 0.8469 - val_f1_metric: 0.8861\n",
      "Epoch 72/3000\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3017 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2212 - acc: 0.8555 - f1_metric: 0.8533\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2617 - acc: 0.8661 - f1_metric: 0.8649\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2441 - acc: 0.8484 - f1_metric: 0.8482\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00072: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 366us/sample - loss: 0.2586 - acc: 0.8504 - f1_metric: 0.8506 - val_loss: 0.5512 - val_acc: 0.7755 - val_f1_metric: 0.8233\n",
      "Epoch 73/3000\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2790 - acc: 0.6562 - f1_metric: 0.6614\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2522 - acc: 0.7734 - f1_metric: 0.7747\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2697 - acc: 0.7746 - f1_metric: 0.7739\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2515 - acc: 0.7859 - f1_metric: 0.7825\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00073: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 363us/sample - loss: 0.2582 - acc: 0.7877 - f1_metric: 0.7892 - val_loss: 0.4075 - val_acc: 0.8418 - val_f1_metric: 0.8789\n",
      "Epoch 74/3000\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2268 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3088 - acc: 0.8242 - f1_metric: 0.8221\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2469 - acc: 0.8438 - f1_metric: 0.8435\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2758 - acc: 0.8281 - f1_metric: 0.8269\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00074: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 363us/sample - loss: 0.2676 - acc: 0.8286 - f1_metric: 0.8208 - val_loss: 0.4890 - val_acc: 0.8112 - val_f1_metric: 0.8484\n",
      "Epoch 75/3000\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3292 - acc: 0.7500 - f1_metric: 0.7402\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.2952 - acc: 0.7969 - f1_metric: 0.7936\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "320/782 [===========>..................] - ETA: 0s - loss: 0.2770 - acc: 0.7906 - f1_metric: 0.7887\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.2767 - acc: 0.8027 - f1_metric: 0.8012\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.2619 - acc: 0.8082 - f1_metric: 0.8072\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00075: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 392us/sample - loss: 0.2595 - acc: 0.8095 - f1_metric: 0.8114 - val_loss: 0.4684 - val_acc: 0.8061 - val_f1_metric: 0.8493\n",
      "Epoch 76/3000\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1604 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2683 - acc: 0.8008 - f1_metric: 0.7984\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2499 - acc: 0.8214 - f1_metric: 0.8187\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2629 - acc: 0.8172 - f1_metric: 0.8171\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00076: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 363us/sample - loss: 0.2558 - acc: 0.8223 - f1_metric: 0.8271 - val_loss: 0.4338 - val_acc: 0.8469 - val_f1_metric: 0.8784\n",
      "Epoch 77/3000\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2041 - acc: 0.8281 - f1_metric: 0.8346\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2697 - acc: 0.8477 - f1_metric: 0.8493\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2486 - acc: 0.8438 - f1_metric: 0.8456\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2201 - acc: 0.8438 - f1_metric: 0.8451\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "782/782 [==============================] - 0s 413us/sample - loss: 0.2191 - acc: 0.8402 - f1_metric: 0.8329 - val_loss: 0.4555 - val_acc: 0.8061 - val_f1_metric: 0.7930\n",
      "Epoch 78/3000\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2201 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2213 - acc: 0.8359 - f1_metric: 0.8393\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2545 - acc: 0.8348 - f1_metric: 0.8367\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2763 - acc: 0.8406 - f1_metric: 0.8420\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00078: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 383us/sample - loss: 0.2549 - acc: 0.8478 - f1_metric: 0.8408 - val_loss: 0.4256 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 79/3000\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3416 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2481 - acc: 0.8711 - f1_metric: 0.8711\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2569 - acc: 0.8415 - f1_metric: 0.8424\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2501 - acc: 0.8516 - f1_metric: 0.8522\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00079: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 370us/sample - loss: 0.2440 - acc: 0.8555 - f1_metric: 0.8630 - val_loss: 0.4300 - val_acc: 0.8418 - val_f1_metric: 0.8203\n",
      "Epoch 80/3000\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2589 - acc: 0.8281 - f1_metric: 0.8189\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2278 - acc: 0.8516 - f1_metric: 0.8447\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1956 - acc: 0.8527 - f1_metric: 0.8497\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1974 - acc: 0.8516 - f1_metric: 0.8492\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00080: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.1956 - acc: 0.8453 - f1_metric: 0.8533 - val_loss: 0.4381 - val_acc: 0.8316 - val_f1_metric: 0.8103\n",
      "Epoch 81/3000\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2948 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3084 - acc: 0.8555 - f1_metric: 0.8555\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2686 - acc: 0.8460 - f1_metric: 0.8460\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2451 - acc: 0.8391 - f1_metric: 0.8396\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00081: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 0.2351 - acc: 0.8363 - f1_metric: 0.8337 - val_loss: 0.4537 - val_acc: 0.8214 - val_f1_metric: 0.8040\n",
      "Epoch 82/3000\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2035 - acc: 0.7500 - f1_metric: 0.7500\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1984 - acc: 0.8164 - f1_metric: 0.8164\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.2058 - acc: 0.8411 - f1_metric: 0.8396\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.1974 - acc: 0.8594 - f1_metric: 0.8584\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.8477 - f1_metric: 0.8459\n",
      "Epoch 00082: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 397us/sample - loss: 0.2088 - acc: 0.8478 - f1_metric: 0.8467 - val_loss: 0.4481 - val_acc: 0.8265 - val_f1_metric: 0.8079\n",
      "Epoch 83/3000\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1498 - acc: 0.8125 - f1_metric: 0.8189\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2251 - acc: 0.8516 - f1_metric: 0.8532\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2081 - acc: 0.8594 - f1_metric: 0.8612\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2214 - acc: 0.8438 - f1_metric: 0.8430\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00083: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 380us/sample - loss: 0.2276 - acc: 0.8402 - f1_metric: 0.8277 - val_loss: 0.4445 - val_acc: 0.8367 - val_f1_metric: 0.8118\n",
      "Epoch 84/3000\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2658 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2198 - acc: 0.8242 - f1_metric: 0.8242\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2188 - acc: 0.8482 - f1_metric: 0.8479\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2314 - acc: 0.8547 - f1_metric: 0.8559\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00084: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 370us/sample - loss: 0.2275 - acc: 0.8555 - f1_metric: 0.8565 - val_loss: 0.4598 - val_acc: 0.8214 - val_f1_metric: 0.8610\n",
      "Epoch 85/3000\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1907 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2226 - acc: 0.8359 - f1_metric: 0.8359\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2245 - acc: 0.8170 - f1_metric: 0.8138\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2343 - acc: 0.8297 - f1_metric: 0.8274\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00085: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 373us/sample - loss: 0.2308 - acc: 0.8338 - f1_metric: 0.8285 - val_loss: 0.4553 - val_acc: 0.8265 - val_f1_metric: 0.8080\n",
      "Epoch 86/3000\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2630 - acc: 0.6875 - f1_metric: 0.6875\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.2269 - acc: 0.7969 - f1_metric: 0.7969\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "320/782 [===========>..................] - ETA: 0s - loss: 0.2248 - acc: 0.8313 - f1_metric: 0.8326\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "512/782 [==================>...........] - ETA: 0s - loss: 0.2185 - acc: 0.8379 - f1_metric: 0.8376\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "704/782 [==========================>...] - ETA: 0s - loss: 0.2425 - acc: 0.8395 - f1_metric: 0.8399\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00086: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 404us/sample - loss: 0.2340 - acc: 0.8376 - f1_metric: 0.8391 - val_loss: 0.4436 - val_acc: 0.8316 - val_f1_metric: 0.8689\n",
      "Epoch 87/3000\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1193 - acc: 0.8594 - f1_metric: 0.8504\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1446 - acc: 0.8633 - f1_metric: 0.8587\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1778 - acc: 0.8661 - f1_metric: 0.8635\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2010 - acc: 0.8656 - f1_metric: 0.8630\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00087: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 391us/sample - loss: 0.2052 - acc: 0.8568 - f1_metric: 0.8503 - val_loss: 0.4419 - val_acc: 0.8316 - val_f1_metric: 0.8118\n",
      "Epoch 88/3000\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1890 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1992 - acc: 0.8438 - f1_metric: 0.8392\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2378 - acc: 0.8393 - f1_metric: 0.8364\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2463 - acc: 0.8313 - f1_metric: 0.8283\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00088: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 371us/sample - loss: 0.2353 - acc: 0.8363 - f1_metric: 0.8358 - val_loss: 0.4728 - val_acc: 0.8163 - val_f1_metric: 0.7985\n",
      "Epoch 89/3000\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1614 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2162 - acc: 0.8203 - f1_metric: 0.8180\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2014 - acc: 0.8192 - f1_metric: 0.8179\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2112 - acc: 0.8188 - f1_metric: 0.8170\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00089: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.2084 - acc: 0.8338 - f1_metric: 0.8350 - val_loss: 0.4587 - val_acc: 0.8214 - val_f1_metric: 0.8047\n",
      "Epoch 90/3000\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1474 - acc: 0.8594 - f1_metric: 0.8413\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1895 - acc: 0.8320 - f1_metric: 0.8275\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1914 - acc: 0.8460 - f1_metric: 0.8434\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2004 - acc: 0.8328 - f1_metric: 0.8291\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00090: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 365us/sample - loss: 0.2064 - acc: 0.8350 - f1_metric: 0.8421 - val_loss: 0.4454 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 91/3000\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1593 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2096 - acc: 0.8398 - f1_metric: 0.8414\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2302 - acc: 0.8393 - f1_metric: 0.8402\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2094 - acc: 0.8516 - f1_metric: 0.8513\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "\n",
      "Epoch 00091: f1_metric did not improve from 0.89062\n",
      "782/782 [==============================] - 0s 364us/sample - loss: 0.2147 - acc: 0.8504 - f1_metric: 0.8463 - val_loss: 0.4432 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 92/3000\n",
      "\n",
      "Epoch 00092: f1_metric improved from 0.89062 to 0.92187, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.239986). Check your callbacks.\n",
      " 64/782 [=>............................] - ETA: 2s - loss: 0.0835 - acc: 0.9219 - f1_metric: 0.9219\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.120098). Check your callbacks.\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1799 - acc: 0.8789 - f1_metric: 0.8789\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2036 - acc: 0.8549 - f1_metric: 0.8545\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2114 - acc: 0.8500 - f1_metric: 0.8497\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00092: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 1s 658us/sample - loss: 0.2063 - acc: 0.8491 - f1_metric: 0.8537 - val_loss: 0.4393 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 93/3000\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2321 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1923 - acc: 0.8633 - f1_metric: 0.8588\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1935 - acc: 0.8482 - f1_metric: 0.8456\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1939 - acc: 0.8531 - f1_metric: 0.8513\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00093: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 343us/sample - loss: 0.2101 - acc: 0.8593 - f1_metric: 0.8584 - val_loss: 0.4223 - val_acc: 0.8367 - val_f1_metric: 0.7555\n",
      "Epoch 94/3000\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2104 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2021 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1767 - acc: 0.8772 - f1_metric: 0.8772\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1911 - acc: 0.8672 - f1_metric: 0.8669\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00094: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 366us/sample - loss: 0.1815 - acc: 0.8670 - f1_metric: 0.8624 - val_loss: 0.4370 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 95/3000\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2028 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1771 - acc: 0.8789 - f1_metric: 0.8789\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1843 - acc: 0.8683 - f1_metric: 0.8683\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2144 - acc: 0.8687 - f1_metric: 0.8687\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00095: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 362us/sample - loss: 0.2000 - acc: 0.8734 - f1_metric: 0.8681 - val_loss: 0.4314 - val_acc: 0.8316 - val_f1_metric: 0.7539\n",
      "Epoch 96/3000\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1533 - acc: 0.9062 - f1_metric: 0.8976\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2438 - acc: 0.8555 - f1_metric: 0.8550\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2363 - acc: 0.8549 - f1_metric: 0.8556\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2250 - acc: 0.8594 - f1_metric: 0.8605\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00096: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 354us/sample - loss: 0.2208 - acc: 0.8581 - f1_metric: 0.8589 - val_loss: 0.4280 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 97/3000\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1618 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2026 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1904 - acc: 0.8571 - f1_metric: 0.8571\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2036 - acc: 0.8687 - f1_metric: 0.8695\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00097: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 355us/sample - loss: 0.1987 - acc: 0.8645 - f1_metric: 0.8646 - val_loss: 0.4343 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 98/3000\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1738 - acc: 0.9062 - f1_metric: 0.9062\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1895 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2218 - acc: 0.8549 - f1_metric: 0.8559\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2310 - acc: 0.8562 - f1_metric: 0.8569\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00098: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 371us/sample - loss: 0.2233 - acc: 0.8517 - f1_metric: 0.8568 - val_loss: 0.4442 - val_acc: 0.8316 - val_f1_metric: 0.8688\n",
      "Epoch 99/3000\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1946 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1995 - acc: 0.8320 - f1_metric: 0.8297\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1984 - acc: 0.8549 - f1_metric: 0.8536\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1936 - acc: 0.8578 - f1_metric: 0.8575\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00099: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 382us/sample - loss: 0.1866 - acc: 0.8657 - f1_metric: 0.8693 - val_loss: 0.4417 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 100/3000\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1963 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1711 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1821 - acc: 0.8482 - f1_metric: 0.8470\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1907 - acc: 0.8453 - f1_metric: 0.8445\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00100: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 383us/sample - loss: 0.1826 - acc: 0.8529 - f1_metric: 0.8568 - val_loss: 0.4281 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 101/3000\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1685 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1863 - acc: 0.8516 - f1_metric: 0.8510\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1928 - acc: 0.8616 - f1_metric: 0.8623\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2071 - acc: 0.8531 - f1_metric: 0.8536\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00101: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 389us/sample - loss: 0.2001 - acc: 0.8593 - f1_metric: 0.8681 - val_loss: 0.4199 - val_acc: 0.8418 - val_f1_metric: 0.8789\n",
      "Epoch 102/3000\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4394 - acc: 0.7656 - f1_metric: 0.7656\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2495 - acc: 0.8281 - f1_metric: 0.8259\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2266 - acc: 0.8438 - f1_metric: 0.8413\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2186 - acc: 0.8562 - f1_metric: 0.8536\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00102: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 367us/sample - loss: 0.2220 - acc: 0.8465 - f1_metric: 0.8409 - val_loss: 0.4439 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 103/3000\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1866 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2556 - acc: 0.8359 - f1_metric: 0.8336\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2480 - acc: 0.8371 - f1_metric: 0.8357\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2412 - acc: 0.8391 - f1_metric: 0.8372\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00103: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 374us/sample - loss: 0.2258 - acc: 0.8338 - f1_metric: 0.8337 - val_loss: 0.4613 - val_acc: 0.8214 - val_f1_metric: 0.8042\n",
      "Epoch 104/3000\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2068 - acc: 0.7500 - f1_metric: 0.7619\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1908 - acc: 0.8320 - f1_metric: 0.8328\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2272 - acc: 0.8237 - f1_metric: 0.8241\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2148 - acc: 0.8438 - f1_metric: 0.8448\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00104: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 392us/sample - loss: 0.2192 - acc: 0.8440 - f1_metric: 0.8491 - val_loss: 0.4451 - val_acc: 0.8367 - val_f1_metric: 0.7555\n",
      "Epoch 105/3000\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4651 - acc: 0.7969 - f1_metric: 0.7874\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2491 - acc: 0.8711 - f1_metric: 0.8687\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2327 - acc: 0.8638 - f1_metric: 0.8625\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2264 - acc: 0.8594 - f1_metric: 0.8575\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00105: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 395us/sample - loss: 0.2236 - acc: 0.8542 - f1_metric: 0.8487 - val_loss: 0.4550 - val_acc: 0.8316 - val_f1_metric: 0.8688\n",
      "Epoch 106/3000\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1412 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1761 - acc: 0.8633 - f1_metric: 0.8633\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1875 - acc: 0.8482 - f1_metric: 0.8469\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1851 - acc: 0.8500 - f1_metric: 0.8491\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00106: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 380us/sample - loss: 0.1921 - acc: 0.8440 - f1_metric: 0.8318 - val_loss: 0.4423 - val_acc: 0.8367 - val_f1_metric: 0.8158\n",
      "Epoch 107/3000\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2167 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2006 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1980 - acc: 0.8460 - f1_metric: 0.8460\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2078 - acc: 0.8578 - f1_metric: 0.8569\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00107: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.2219 - acc: 0.8581 - f1_metric: 0.8645 - val_loss: 0.4308 - val_acc: 0.8367 - val_f1_metric: 0.8766\n",
      "Epoch 108/3000\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1970 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2404 - acc: 0.8867 - f1_metric: 0.8867\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2316 - acc: 0.8549 - f1_metric: 0.8536\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2155 - acc: 0.8594 - f1_metric: 0.8585\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.8581 - f1_metric: 0.8566\n",
      "Epoch 00108: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 401us/sample - loss: 0.2025 - acc: 0.8568 - f1_metric: 0.8511 - val_loss: 0.4608 - val_acc: 0.8316 - val_f1_metric: 0.8332\n",
      "Epoch 109/3000\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2310 - acc: 0.7969 - f1_metric: 0.8031\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2453 - acc: 0.8516 - f1_metric: 0.8531\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2597 - acc: 0.8326 - f1_metric: 0.8335\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2636 - acc: 0.8281 - f1_metric: 0.8288\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00109: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 373us/sample - loss: 0.2583 - acc: 0.8223 - f1_metric: 0.8253 - val_loss: 0.4514 - val_acc: 0.8316 - val_f1_metric: 0.7492\n",
      "Epoch 110/3000\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1119 - acc: 0.9062 - f1_metric: 0.9062\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2161 - acc: 0.8555 - f1_metric: 0.8531\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1906 - acc: 0.8661 - f1_metric: 0.8658\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1945 - acc: 0.8500 - f1_metric: 0.8498\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00110: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 381us/sample - loss: 0.2253 - acc: 0.8427 - f1_metric: 0.8305 - val_loss: 0.4462 - val_acc: 0.8316 - val_f1_metric: 0.6953\n",
      "Epoch 111/3000\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1979 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1948 - acc: 0.8516 - f1_metric: 0.8516\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2317 - acc: 0.8527 - f1_metric: 0.8527\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2389 - acc: 0.8469 - f1_metric: 0.8469\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00111: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 381us/sample - loss: 0.2385 - acc: 0.8517 - f1_metric: 0.8513 - val_loss: 0.4304 - val_acc: 0.8418 - val_f1_metric: 0.8766\n",
      "Epoch 112/3000\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2297 - acc: 0.7969 - f1_metric: 0.8031\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1998 - acc: 0.8281 - f1_metric: 0.8297\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1978 - acc: 0.8259 - f1_metric: 0.8268\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2009 - acc: 0.8313 - f1_metric: 0.8309\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.8333 - f1_metric: 0.8323\n",
      "Epoch 00112: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 394us/sample - loss: 0.2128 - acc: 0.8363 - f1_metric: 0.8452 - val_loss: 0.4446 - val_acc: 0.8265 - val_f1_metric: 0.8292\n",
      "Epoch 113/3000\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1949 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1595 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1991 - acc: 0.8795 - f1_metric: 0.8782\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1949 - acc: 0.8594 - f1_metric: 0.8605\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00113: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 0.1990 - acc: 0.8645 - f1_metric: 0.8685 - val_loss: 0.4373 - val_acc: 0.8367 - val_f1_metric: 0.8681\n",
      "Epoch 114/3000\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1904 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1991 - acc: 0.8438 - f1_metric: 0.8430\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1985 - acc: 0.8594 - f1_metric: 0.8590\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.2042 - acc: 0.8628 - f1_metric: 0.8641\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.8659 - f1_metric: 0.8668\n",
      "Epoch 00114: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 395us/sample - loss: 0.1940 - acc: 0.8645 - f1_metric: 0.8606 - val_loss: 0.4334 - val_acc: 0.8367 - val_f1_metric: 0.7533\n",
      "Epoch 115/3000\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1758 - acc: 0.9219 - f1_metric: 0.9219\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2294 - acc: 0.8516 - f1_metric: 0.8468\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2397 - acc: 0.8393 - f1_metric: 0.8366\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2505 - acc: 0.8344 - f1_metric: 0.8331\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00115: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 380us/sample - loss: 0.2335 - acc: 0.8427 - f1_metric: 0.8462 - val_loss: 0.4646 - val_acc: 0.8214 - val_f1_metric: 0.8610\n",
      "Epoch 116/3000\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1738 - acc: 0.9062 - f1_metric: 0.9062\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1849 - acc: 0.8828 - f1_metric: 0.8806\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1760 - acc: 0.8683 - f1_metric: 0.8670\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1744 - acc: 0.8594 - f1_metric: 0.8576\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00116: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 387us/sample - loss: 0.1831 - acc: 0.8529 - f1_metric: 0.8598 - val_loss: 0.4450 - val_acc: 0.8214 - val_f1_metric: 0.7436\n",
      "Epoch 117/3000\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2700 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1752 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1823 - acc: 0.8527 - f1_metric: 0.8527\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1827 - acc: 0.8547 - f1_metric: 0.8545\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00117: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 390us/sample - loss: 0.1946 - acc: 0.8568 - f1_metric: 0.8663 - val_loss: 0.4422 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 118/3000\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2473 - acc: 0.8594 - f1_metric: 0.8504\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2450 - acc: 0.8516 - f1_metric: 0.8469\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2052 - acc: 0.8683 - f1_metric: 0.8666\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2082 - acc: 0.8547 - f1_metric: 0.8542\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00118: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 381us/sample - loss: 0.1991 - acc: 0.8619 - f1_metric: 0.8655 - val_loss: 0.4542 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 119/3000\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1958 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1890 - acc: 0.8477 - f1_metric: 0.8453\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2090 - acc: 0.8638 - f1_metric: 0.8625\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2121 - acc: 0.8453 - f1_metric: 0.8444\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.8503 - f1_metric: 0.8501\n",
      "Epoch 00119: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 408us/sample - loss: 0.2059 - acc: 0.8491 - f1_metric: 0.8451 - val_loss: 0.4595 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 120/3000\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3119 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2244 - acc: 0.8398 - f1_metric: 0.8398\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2090 - acc: 0.8460 - f1_metric: 0.8460\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2336 - acc: 0.8453 - f1_metric: 0.8453\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00120: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 384us/sample - loss: 0.2348 - acc: 0.8440 - f1_metric: 0.8362 - val_loss: 0.4581 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 121/3000\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1760 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1635 - acc: 0.8711 - f1_metric: 0.8711\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1768 - acc: 0.8482 - f1_metric: 0.8492\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2044 - acc: 0.8453 - f1_metric: 0.8460\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00121: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 387us/sample - loss: 0.2061 - acc: 0.8453 - f1_metric: 0.8551 - val_loss: 0.4502 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 122/3000\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1880 - acc: 0.7969 - f1_metric: 0.7969\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1903 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1955 - acc: 0.8393 - f1_metric: 0.8393\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2097 - acc: 0.8453 - f1_metric: 0.8453\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00122: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 379us/sample - loss: 0.2073 - acc: 0.8529 - f1_metric: 0.8525 - val_loss: 0.4386 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 123/3000\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1952 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2003 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1893 - acc: 0.8482 - f1_metric: 0.8482\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1974 - acc: 0.8531 - f1_metric: 0.8531\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00123: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 370us/sample - loss: 0.1960 - acc: 0.8491 - f1_metric: 0.8446 - val_loss: 0.4393 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 124/3000\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1544 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1730 - acc: 0.8516 - f1_metric: 0.8516\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1817 - acc: 0.8504 - f1_metric: 0.8504\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1733 - acc: 0.8656 - f1_metric: 0.8656\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00124: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.1826 - acc: 0.8645 - f1_metric: 0.8554 - val_loss: 0.4400 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 125/3000\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2322 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1513 - acc: 0.8828 - f1_metric: 0.8828\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1384 - acc: 0.8884 - f1_metric: 0.8884\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.1454 - acc: 0.8872 - f1_metric: 0.8872\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.8698 - f1_metric: 0.8698\n",
      "Epoch 00125: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 397us/sample - loss: 0.1911 - acc: 0.8708 - f1_metric: 0.8743 - val_loss: 0.4439 - val_acc: 0.8265 - val_f1_metric: 0.7500\n",
      "Epoch 126/3000\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1780 - acc: 0.8125 - f1_metric: 0.8031\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2130 - acc: 0.8594 - f1_metric: 0.8548\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2140 - acc: 0.8504 - f1_metric: 0.8487\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.2138 - acc: 0.8542 - f1_metric: 0.8528\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.8594 - f1_metric: 0.8577\n",
      "Epoch 00126: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 410us/sample - loss: 0.2068 - acc: 0.8593 - f1_metric: 0.8576 - val_loss: 0.4468 - val_acc: 0.8214 - val_f1_metric: 0.8633\n",
      "Epoch 127/3000\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1637 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1675 - acc: 0.8828 - f1_metric: 0.8828\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1765 - acc: 0.8683 - f1_metric: 0.8683\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1921 - acc: 0.8641 - f1_metric: 0.8641\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00127: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 383us/sample - loss: 0.1969 - acc: 0.8619 - f1_metric: 0.8616 - val_loss: 0.4420 - val_acc: 0.8214 - val_f1_metric: 0.8633\n",
      "Epoch 128/3000\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3562 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2504 - acc: 0.8359 - f1_metric: 0.8359\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2262 - acc: 0.8482 - f1_metric: 0.8482\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2122 - acc: 0.8422 - f1_metric: 0.8429\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00128: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 0.2041 - acc: 0.8504 - f1_metric: 0.8556 - val_loss: 0.4507 - val_acc: 0.8214 - val_f1_metric: 0.8633\n",
      "Epoch 129/3000\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1636 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1840 - acc: 0.8516 - f1_metric: 0.8516\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1861 - acc: 0.8415 - f1_metric: 0.8415\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1896 - acc: 0.8391 - f1_metric: 0.8391\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00129: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 385us/sample - loss: 0.1891 - acc: 0.8491 - f1_metric: 0.8582 - val_loss: 0.4413 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 130/3000\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1811 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1950 - acc: 0.8594 - f1_metric: 0.8571\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2430 - acc: 0.8571 - f1_metric: 0.8568\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2271 - acc: 0.8594 - f1_metric: 0.8583\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00130: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 387us/sample - loss: 0.2088 - acc: 0.8683 - f1_metric: 0.8668 - val_loss: 0.4398 - val_acc: 0.8265 - val_f1_metric: 0.7500\n",
      "Epoch 131/3000\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.0741 - acc: 0.9219 - f1_metric: 0.9219\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1736 - acc: 0.8516 - f1_metric: 0.8508\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1721 - acc: 0.8594 - f1_metric: 0.8590\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1802 - acc: 0.8578 - f1_metric: 0.8575\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "\n",
      "Epoch 00131: f1_metric did not improve from 0.92187\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.1925 - acc: 0.8581 - f1_metric: 0.8621 - val_loss: 0.4322 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 132/3000\n",
      "\n",
      "Epoch 00132: f1_metric improved from 0.92187 to 0.93750, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.194213). Check your callbacks.\n",
      " 64/782 [=>............................] - ETA: 2s - loss: 0.1222 - acc: 0.9375 - f1_metric: 0.9375\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1353 - acc: 0.9180 - f1_metric: 0.9180\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1711 - acc: 0.8973 - f1_metric: 0.8973\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1773 - acc: 0.8797 - f1_metric: 0.8797\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00132: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 616us/sample - loss: 0.1739 - acc: 0.8747 - f1_metric: 0.8722 - val_loss: 0.4386 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 133/3000\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2171 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1720 - acc: 0.8711 - f1_metric: 0.8711\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1527 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1851 - acc: 0.8703 - f1_metric: 0.8703\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00133: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 359us/sample - loss: 0.1959 - acc: 0.8696 - f1_metric: 0.8681 - val_loss: 0.4272 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 134/3000\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2835 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1904 - acc: 0.8516 - f1_metric: 0.8472\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2152 - acc: 0.8438 - f1_metric: 0.8412\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2065 - acc: 0.8594 - f1_metric: 0.8576\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00134: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 389us/sample - loss: 0.1979 - acc: 0.8619 - f1_metric: 0.8560 - val_loss: 0.4352 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 135/3000\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1249 - acc: 0.9219 - f1_metric: 0.9219\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1636 - acc: 0.8672 - f1_metric: 0.8689\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1615 - acc: 0.8795 - f1_metric: 0.8804\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1891 - acc: 0.8719 - f1_metric: 0.8726\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.8620 - f1_metric: 0.8626\n",
      "Epoch 00135: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 403us/sample - loss: 0.2044 - acc: 0.8593 - f1_metric: 0.8511 - val_loss: 0.4356 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 136/3000\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1025 - acc: 0.9219 - f1_metric: 0.9219\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1775 - acc: 0.8477 - f1_metric: 0.8470\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1833 - acc: 0.8527 - f1_metric: 0.8510\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1697 - acc: 0.8625 - f1_metric: 0.8604\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00136: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 393us/sample - loss: 0.1854 - acc: 0.8517 - f1_metric: 0.8332 - val_loss: 0.4341 - val_acc: 0.8367 - val_f1_metric: 0.8164\n",
      "Epoch 137/3000\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1557 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1685 - acc: 0.8516 - f1_metric: 0.8516\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1987 - acc: 0.8549 - f1_metric: 0.8549\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1981 - acc: 0.8531 - f1_metric: 0.8538\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00137: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 389us/sample - loss: 0.1897 - acc: 0.8606 - f1_metric: 0.8652 - val_loss: 0.4382 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 138/3000\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2300 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2232 - acc: 0.8359 - f1_metric: 0.8375\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1945 - acc: 0.8549 - f1_metric: 0.8555\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1952 - acc: 0.8516 - f1_metric: 0.8520\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.8490 - f1_metric: 0.8493\n",
      "Epoch 00138: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 394us/sample - loss: 0.1953 - acc: 0.8491 - f1_metric: 0.8499 - val_loss: 0.4338 - val_acc: 0.8367 - val_f1_metric: 0.7578\n",
      "Epoch 139/3000\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2248 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2057 - acc: 0.8477 - f1_metric: 0.8477\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2408 - acc: 0.8549 - f1_metric: 0.8536\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2269 - acc: 0.8594 - f1_metric: 0.8585\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00139: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 379us/sample - loss: 0.2196 - acc: 0.8606 - f1_metric: 0.8554 - val_loss: 0.4467 - val_acc: 0.8265 - val_f1_metric: 0.7500\n",
      "Epoch 140/3000\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1868 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1658 - acc: 0.8516 - f1_metric: 0.8494\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1638 - acc: 0.8549 - f1_metric: 0.8537\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1891 - acc: 0.8500 - f1_metric: 0.8492\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00140: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 391us/sample - loss: 0.1855 - acc: 0.8555 - f1_metric: 0.8635 - val_loss: 0.4345 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 141/3000\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2118 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2209 - acc: 0.8398 - f1_metric: 0.8376\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2114 - acc: 0.8460 - f1_metric: 0.8447\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2146 - acc: 0.8594 - f1_metric: 0.8576\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00141: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.2043 - acc: 0.8581 - f1_metric: 0.8524 - val_loss: 0.4388 - val_acc: 0.8316 - val_f1_metric: 0.8354\n",
      "Epoch 142/3000\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1872 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1907 - acc: 0.8789 - f1_metric: 0.8784\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1959 - acc: 0.8415 - f1_metric: 0.8412\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1828 - acc: 0.8516 - f1_metric: 0.8513\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00142: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 387us/sample - loss: 0.1957 - acc: 0.8491 - f1_metric: 0.8537 - val_loss: 0.4366 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 143/3000\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4008 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2487 - acc: 0.8477 - f1_metric: 0.8477\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2000 - acc: 0.8728 - f1_metric: 0.8715\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1875 - acc: 0.8734 - f1_metric: 0.8726\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00143: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 390us/sample - loss: 0.1876 - acc: 0.8632 - f1_metric: 0.8664 - val_loss: 0.4354 - val_acc: 0.8265 - val_f1_metric: 0.8086\n",
      "Epoch 144/3000\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2502 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1653 - acc: 0.8984 - f1_metric: 0.8984\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1762 - acc: 0.8906 - f1_metric: 0.8894\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1863 - acc: 0.8844 - f1_metric: 0.8835\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.8776 - f1_metric: 0.8769\n",
      "Epoch 00144: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 392us/sample - loss: 0.1895 - acc: 0.8772 - f1_metric: 0.8754 - val_loss: 0.4373 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 145/3000\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1306 - acc: 0.8125 - f1_metric: 0.8189\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1960 - acc: 0.8281 - f1_metric: 0.8297\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1799 - acc: 0.8482 - f1_metric: 0.8491\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1937 - acc: 0.8594 - f1_metric: 0.8600\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00145: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.1944 - acc: 0.8517 - f1_metric: 0.8482 - val_loss: 0.4499 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 146/3000\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2139 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1909 - acc: 0.8516 - f1_metric: 0.8532\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1911 - acc: 0.8661 - f1_metric: 0.8670\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1984 - acc: 0.8687 - f1_metric: 0.8694\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00146: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 372us/sample - loss: 0.1964 - acc: 0.8696 - f1_metric: 0.8607 - val_loss: 0.4383 - val_acc: 0.8265 - val_f1_metric: 0.7500\n",
      "Epoch 147/3000\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2292 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2176 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2175 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2129 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00147: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 383us/sample - loss: 0.2123 - acc: 0.8542 - f1_metric: 0.8420 - val_loss: 0.4482 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 148/3000\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1468 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2121 - acc: 0.8320 - f1_metric: 0.8320\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2092 - acc: 0.8371 - f1_metric: 0.8371\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1912 - acc: 0.8406 - f1_metric: 0.8406\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00148: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 388us/sample - loss: 0.1988 - acc: 0.8453 - f1_metric: 0.8465 - val_loss: 0.4468 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 149/3000\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2154 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1862 - acc: 0.8555 - f1_metric: 0.8555\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1819 - acc: 0.8616 - f1_metric: 0.8626\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1878 - acc: 0.8547 - f1_metric: 0.8544\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00149: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 383us/sample - loss: 0.1894 - acc: 0.8619 - f1_metric: 0.8657 - val_loss: 0.4264 - val_acc: 0.8265 - val_f1_metric: 0.8688\n",
      "Epoch 150/3000\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1149 - acc: 0.9062 - f1_metric: 0.9062\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1489 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1516 - acc: 0.8728 - f1_metric: 0.8728\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1576 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00150: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 389us/sample - loss: 0.1706 - acc: 0.8760 - f1_metric: 0.8791 - val_loss: 0.4194 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 151/3000\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1045 - acc: 0.9062 - f1_metric: 0.9062\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2039 - acc: 0.8828 - f1_metric: 0.8828\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2077 - acc: 0.8772 - f1_metric: 0.8772\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1994 - acc: 0.8687 - f1_metric: 0.8678\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00151: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 371us/sample - loss: 0.2031 - acc: 0.8619 - f1_metric: 0.8609 - val_loss: 0.4319 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 152/3000\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2014 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1883 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1900 - acc: 0.8571 - f1_metric: 0.8571\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2038 - acc: 0.8656 - f1_metric: 0.8656\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00152: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 421us/sample - loss: 0.1959 - acc: 0.8696 - f1_metric: 0.8774 - val_loss: 0.4319 - val_acc: 0.8316 - val_f1_metric: 0.8102\n",
      "Epoch 153/3000\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1284 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1373 - acc: 0.8672 - f1_metric: 0.8689\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1815 - acc: 0.8504 - f1_metric: 0.8523\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1716 - acc: 0.8547 - f1_metric: 0.8557\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00153: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 393us/sample - loss: 0.1707 - acc: 0.8632 - f1_metric: 0.8679 - val_loss: 0.4412 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 154/3000\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3063 - acc: 0.7969 - f1_metric: 0.7969\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2043 - acc: 0.8477 - f1_metric: 0.8477\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1929 - acc: 0.8549 - f1_metric: 0.8549\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.1883 - acc: 0.8646 - f1_metric: 0.8646\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.8685 - f1_metric: 0.8678\n",
      "Epoch 00154: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 410us/sample - loss: 0.1782 - acc: 0.8708 - f1_metric: 0.8780 - val_loss: 0.4501 - val_acc: 0.8214 - val_f1_metric: 0.8047\n",
      "Epoch 155/3000\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1860 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1843 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1950 - acc: 0.8705 - f1_metric: 0.8705\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1834 - acc: 0.8734 - f1_metric: 0.8734\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00155: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 379us/sample - loss: 0.1784 - acc: 0.8683 - f1_metric: 0.8762 - val_loss: 0.4329 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 156/3000\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2540 - acc: 0.8125 - f1_metric: 0.8125\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2708 - acc: 0.8633 - f1_metric: 0.8633\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2278 - acc: 0.8638 - f1_metric: 0.8638\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2091 - acc: 0.8578 - f1_metric: 0.8585\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00156: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 386us/sample - loss: 0.2091 - acc: 0.8517 - f1_metric: 0.8482 - val_loss: 0.4293 - val_acc: 0.8316 - val_f1_metric: 0.8688\n",
      "Epoch 157/3000\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4202 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2431 - acc: 0.8477 - f1_metric: 0.8477\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2069 - acc: 0.8504 - f1_metric: 0.8491\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2005 - acc: 0.8609 - f1_metric: 0.8600\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00157: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 376us/sample - loss: 0.1964 - acc: 0.8593 - f1_metric: 0.8499 - val_loss: 0.4354 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 158/3000\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1830 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1772 - acc: 0.8789 - f1_metric: 0.8789\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1844 - acc: 0.8504 - f1_metric: 0.8504\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1875 - acc: 0.8578 - f1_metric: 0.8569\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00158: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 378us/sample - loss: 0.1833 - acc: 0.8632 - f1_metric: 0.8664 - val_loss: 0.4298 - val_acc: 0.8316 - val_f1_metric: 0.7554\n",
      "Epoch 159/3000\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1608 - acc: 0.8594 - f1_metric: 0.8594\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1851 - acc: 0.8789 - f1_metric: 0.8789\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1846 - acc: 0.8772 - f1_metric: 0.8759\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1779 - acc: 0.8687 - f1_metric: 0.8676\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00159: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 0.1826 - acc: 0.8606 - f1_metric: 0.8681 - val_loss: 0.4321 - val_acc: 0.8367 - val_f1_metric: 0.8164\n",
      "Epoch 160/3000\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.4878 - acc: 0.7969 - f1_metric: 0.7969\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.3024 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2430 - acc: 0.8482 - f1_metric: 0.8491\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2100 - acc: 0.8672 - f1_metric: 0.8670\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00160: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 374us/sample - loss: 0.1960 - acc: 0.8657 - f1_metric: 0.8736 - val_loss: 0.4410 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 161/3000\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1817 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2108 - acc: 0.8555 - f1_metric: 0.8555\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1798 - acc: 0.8661 - f1_metric: 0.8658\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1870 - acc: 0.8703 - f1_metric: 0.8701\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00161: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 364us/sample - loss: 0.1903 - acc: 0.8657 - f1_metric: 0.8651 - val_loss: 0.4349 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 162/3000\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1696 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1948 - acc: 0.8438 - f1_metric: 0.8414\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1957 - acc: 0.8371 - f1_metric: 0.8357\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1810 - acc: 0.8516 - f1_metric: 0.8506\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00162: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 381us/sample - loss: 0.1822 - acc: 0.8632 - f1_metric: 0.8578 - val_loss: 0.4407 - val_acc: 0.8418 - val_f1_metric: 0.7617\n",
      "Epoch 163/3000\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1362 - acc: 0.8906 - f1_metric: 0.8906\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2076 - acc: 0.8867 - f1_metric: 0.8867\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2010 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1908 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00163: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 359us/sample - loss: 0.1821 - acc: 0.8772 - f1_metric: 0.8803 - val_loss: 0.4549 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 164/3000\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1976 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "192/782 [======>.......................] - ETA: 0s - loss: 0.1894 - acc: 0.8646 - f1_metric: 0.8646\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "384/782 [=============>................] - ETA: 0s - loss: 0.1948 - acc: 0.8516 - f1_metric: 0.8516\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.1802 - acc: 0.8698 - f1_metric: 0.8698\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.8633 - f1_metric: 0.8638\n",
      "Epoch 00164: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 381us/sample - loss: 0.1855 - acc: 0.8619 - f1_metric: 0.8578 - val_loss: 0.4536 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 165/3000\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1947 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1747 - acc: 0.8594 - f1_metric: 0.8571\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1705 - acc: 0.8884 - f1_metric: 0.8871\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1732 - acc: 0.8813 - f1_metric: 0.8803\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00165: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 373us/sample - loss: 0.1855 - acc: 0.8734 - f1_metric: 0.8717 - val_loss: 0.4328 - val_acc: 0.8316 - val_f1_metric: 0.8125\n",
      "Epoch 166/3000\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1802 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1734 - acc: 0.8711 - f1_metric: 0.8711\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1948 - acc: 0.8884 - f1_metric: 0.8884\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1942 - acc: 0.8719 - f1_metric: 0.8719\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00166: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 374us/sample - loss: 0.1990 - acc: 0.8734 - f1_metric: 0.8638 - val_loss: 0.4260 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 167/3000\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.2834 - acc: 0.8750 - f1_metric: 0.8819\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1927 - acc: 0.8555 - f1_metric: 0.8572\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1818 - acc: 0.8638 - f1_metric: 0.8648\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1842 - acc: 0.8703 - f1_metric: 0.8710\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00167: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 380us/sample - loss: 0.1843 - acc: 0.8734 - f1_metric: 0.8772 - val_loss: 0.4289 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 168/3000\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1931 - acc: 0.9375 - f1_metric: 0.9375\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1917 - acc: 0.8711 - f1_metric: 0.8729\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1773 - acc: 0.8728 - f1_metric: 0.8738\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1723 - acc: 0.8797 - f1_metric: 0.8804\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00168: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 388us/sample - loss: 0.1907 - acc: 0.8657 - f1_metric: 0.8615 - val_loss: 0.4358 - val_acc: 0.8367 - val_f1_metric: 0.8750\n",
      "Epoch 169/3000\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1846 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1941 - acc: 0.8438 - f1_metric: 0.8437\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1853 - acc: 0.8772 - f1_metric: 0.8772\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "576/782 [=====================>........] - ETA: 0s - loss: 0.2208 - acc: 0.8767 - f1_metric: 0.8767\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "768/782 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.8737 - f1_metric: 0.8737\n",
      "Epoch 00169: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 393us/sample - loss: 0.1969 - acc: 0.8747 - f1_metric: 0.8779 - val_loss: 0.4297 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 170/3000\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.3228 - acc: 0.9062 - f1_metric: 0.9062\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.2110 - acc: 0.8711 - f1_metric: 0.8711\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2139 - acc: 0.8549 - f1_metric: 0.8559\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.2063 - acc: 0.8562 - f1_metric: 0.8569\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00170: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 370us/sample - loss: 0.1990 - acc: 0.8581 - f1_metric: 0.8610 - val_loss: 0.4350 - val_acc: 0.8316 - val_f1_metric: 0.8711\n",
      "Epoch 171/3000\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1695 - acc: 0.8281 - f1_metric: 0.8281\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1887 - acc: 0.8672 - f1_metric: 0.8672\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.2077 - acc: 0.8571 - f1_metric: 0.8571\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1974 - acc: 0.8594 - f1_metric: 0.8600\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "\n",
      "Epoch 00171: f1_metric did not improve from 0.93750\n",
      "782/782 [==============================] - 0s 390us/sample - loss: 0.2004 - acc: 0.8606 - f1_metric: 0.8523 - val_loss: 0.4453 - val_acc: 0.8214 - val_f1_metric: 0.8633\n",
      "Epoch 172/3000\n",
      "\n",
      "Epoch 00172: f1_metric improved from 0.93750 to 0.95312, saving model to /content/drive/My Drive/Colab Notebooks/cnn output/best_model_keras/bestModel.h5\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.204070). Check your callbacks.\n",
      " 64/782 [=>............................] - ETA: 2s - loss: 0.1804 - acc: 0.9531 - f1_metric: 0.9531\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.102146). Check your callbacks.\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1708 - acc: 0.9102 - f1_metric: 0.9080\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1762 - acc: 0.8839 - f1_metric: 0.8827\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1729 - acc: 0.8797 - f1_metric: 0.8795\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00172: f1_metric did not improve from 0.95312\n",
      "782/782 [==============================] - 0s 637us/sample - loss: 0.1950 - acc: 0.8683 - f1_metric: 0.8675 - val_loss: 0.4532 - val_acc: 0.8214 - val_f1_metric: 0.8047\n",
      "Epoch 173/3000\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      " 64/782 [=>............................] - ETA: 0s - loss: 0.1703 - acc: 0.8750 - f1_metric: 0.8750\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "256/782 [========>.....................] - ETA: 0s - loss: 0.1605 - acc: 0.8398 - f1_metric: 0.8376\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "448/782 [================>.............] - ETA: 0s - loss: 0.1608 - acc: 0.8571 - f1_metric: 0.8559\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "640/782 [=======================>......] - ETA: 0s - loss: 0.1763 - acc: 0.8562 - f1_metric: 0.8561\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "\n",
      "Epoch 00173: f1_metric did not improve from 0.95312\n",
      "782/782 [==============================] - 0s 368us/sample - loss: 0.1816 - acc: 0.8645 - f1_metric: 0.8675 - val_loss: 0.4374 - val_acc: 0.8265 - val_f1_metric: 0.8672\n",
      "Epoch 00173: early stopping\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "from keras.utils import to_categorical\n",
    "# history = model.compile(sample_weight_mode=\"temporal\", loss =\"sparse_categorical_crossentropy\")\n",
    "history = model.fit(x_train, y_train, epochs=params['epochs'], verbose=1,\n",
    "                            batch_size=64, shuffle=True,\n",
    "                            # validation_split=0.3,\n",
    "                            validation_data=(x_cv, y_cv),\n",
    "                            callbacks=[mcp, rlp, es],\n",
    "                            sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "7gBYHjM0Pxp4",
    "outputId": "699a2802-4f7a-4145-c089-6680aefaa139"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np0IgIhJzKgQiIjH3/0SnWlyqSvvdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['f1_metric'])\n",
    "plt.plot(history.history['val_f1_metric'])\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_loss', 'val_loss', 'f1', 'val_f1'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "DA5t__HfP0Oo",
    "outputId": "4b1b1a0c-8c5c-4980-b3c0-490ddf4cfe39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras evaluate= [0.4129285111719248, 0.8122449, 0.8121279]\n",
      "size of test set 245\n",
      "TP class counts (array([0, 1, 2]), array([ 11,   9, 179]))\n",
      "True class counts (array([0, 1, 2]), array([ 14,  14, 217]))\n",
      "Pred class counts (array([0, 1, 2]), array([ 35,  23, 187]))\n",
      "baseline acc: 88.57142857142857\n",
      "[[ 11   0   3]\n",
      " [  0   9   5]\n",
      " [ 24  14 179]]\n",
      "F1 score (weighted) 0.8383208338956976\n",
      "F1 score (macro) 0.6072015640615357\n",
      "F1 score (micro) 0.8122448979591836\n",
      "cohen's Kappa 0.3951915852742298\n",
      "precision of class 0 = 0.79\n",
      "precision of class 1 = 0.64\n",
      "precision of class 2 = 0.82\n",
      "precision avg 0.75\n",
      "Accuracy score: 0.8122448979591836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model(best_model_path)\n",
    "test_res = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"keras evaluate=\", test_res)\n",
    "pred = model.predict(x_test)\n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "check_baseline(pred_classes, y_test_classes)\n",
    "conf_mat = confusion_matrix(y_test_classes, pred_classes)\n",
    "print(conf_mat)\n",
    "labels = [0,1,2]\n",
    "# ax = sns.heatmap(conf_mat, xticklabels=labels, yticklabels=labels, annot=True)\n",
    "# ax.xaxis.set_ticks_position('top')\n",
    "f1_weighted = f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='weighted', sample_weight=None)\n",
    "print(\"F1 score (weighted)\", f1_weighted)\n",
    "print(\"F1 score (macro)\", f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='macro', sample_weight=None))\n",
    "print(\"F1 score (micro)\", f1_score(y_test_classes, pred_classes, labels=None, \n",
    "         average='micro', sample_weight=None))  # weighted and micro preferred in case of imbalance\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-s-kappa --> supports multiclass; ref: https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english\n",
    "print(\"cohen's Kappa\", cohen_kappa_score(y_test_classes, pred_classes))\n",
    "\n",
    "prec = []\n",
    "for i, row in enumerate(conf_mat):\n",
    "    prec.append(np.round(row[i]/np.sum(row), 2))\n",
    "    print(\"precision of class {} = {}\".format(i, prec[i]))\n",
    "print(\"precision avg\", sum(prec)/len(prec))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, pred_classes)\n",
    "print(\"Accuracy score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y8RMYCoko3rT",
    "outputId": "cf07b496-9403-4497-a1d5-aa8e89da1e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profits -2238.270996000002\n"
     ]
    }
   ],
   "source": [
    "x_test_copy['Predictions'] = y_test_classes\n",
    "\n",
    "x_test_copy[['Predictions']]\n",
    "count = 0\n",
    "for index, row in x_test_copy.iterrows():\n",
    "  if row['Predictions'] != 2:\n",
    "    if row['Predictions'] == 1: #buying\n",
    "      price = df.iloc[index]\n",
    "      now_price = price['close']\n",
    "      day7_price = df.iloc[index + 7]\n",
    "      day7_price = day7_price['close']\n",
    "      profit = day7_price - now_price\n",
    "      count += profit\n",
    "    \n",
    "    else:\n",
    "      price = df.iloc[index]\n",
    "      now_price = price['close']\n",
    "      day7_price = df.iloc[index + 7]\n",
    "      day7_price = day7_price['close']\n",
    "      profit = now_price - day7_price\n",
    "      count += profit\n",
    "\n",
    "print(\"Profits\", count)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_CNN_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ae67cd0a9d4efeb2e20ed4a66c63d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "060725c9a10049aca8828560223b771e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0614912bc11e41afb3aaca59bb5bc897": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0696d9d321c84cb4852a979567f78d4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0761d4f6f80b40a2b44c3a9d4a37c523": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "07c4ec4c40534ebc9f198b45ed4d401e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09839334122342b5b4caa30b26ec5c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0c030a196eb64c46981a10d3884895ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c049603a126498eacf07207bda7ce0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0dc3fef18a95477999010b3d48d0cfed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ffd634a8ef047698c737716816db9d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10890ed21887419d8eb2373dfe040e22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3dd3ed71bbe94b10b160d51426455fd3",
       "IPY_MODEL_2309c7a489be4cf993c546a8709328d3"
      ],
      "layout": "IPY_MODEL_4006080f11e94ef68ef60e242ff04f93"
     }
    },
    "11c5c103a57d4527bf7e39b88e05d3b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a1ef815f6304e33a8484125e66c1781",
       "IPY_MODEL_92c341bba3bd4dc2a492f5edca87c5f9"
      ],
      "layout": "IPY_MODEL_aa3b8d2e6f2348eaab7d4ba077aba51a"
     }
    },
    "130cbf45f8d644d69e92450f8a7d641e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e64fcb3239d0435cb451594180983a7b",
       "IPY_MODEL_56fce9af36d24f36a4cc0ef76b070ea1"
      ],
      "layout": "IPY_MODEL_aed49ef6598d4edf8ca15450c02f26fc"
     }
    },
    "18a754719a0843e4989d90c3a81d6c00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1a1ef815f6304e33a8484125e66c1781": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7b84e6242664454acaf9e0e695ad6af",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fe3bb50154f47c38e70f501563c4fa3",
      "value": 21
     }
    },
    "1de81f9a9af848f6ae47150d6abcd2a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83298fe3d4a94fe89cb2d893d69fdaf3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6aacb5769eba4da1877b24302eae253b",
      "value": " 21/21 [00:00&lt;00:00, 133.34it/s]"
     }
    },
    "1e2ede8aaf7d4e3ea914ea51d95e0d4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1eb035604fe243a0888e1a0809404021": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fa09044523c4d12ba6f20b5341b7ffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c030a196eb64c46981a10d3884895ed",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0c049603a126498eacf07207bda7ce0e",
      "value": " 21/21 [00:00&lt;00:00, 123.51it/s]"
     }
    },
    "21ac5a39e8d74613a0b1cb7d54b1af6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c21ecb9244134ba9a755e70c4aa9ce60",
       "IPY_MODEL_1de81f9a9af848f6ae47150d6abcd2a5"
      ],
      "layout": "IPY_MODEL_22a17159740c4056b1f7bcd6c4986fe1"
     }
    },
    "22a17159740c4056b1f7bcd6c4986fe1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2309c7a489be4cf993c546a8709328d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de4dcebd102f4126a2b00ff7822c33b0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9184d5bf77ef4c92b1a9d8f3dcd2698e",
      "value": " 21/? [00:07&lt;00:00,  2.79it/s]"
     }
    },
    "2622d06ecacb465391ed302c213bb41d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2724e94a000743289da58c82f87c72fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c60905265b459e8e3b46dab7ff84e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc14e06d73de49a6b606d8bc3dcd4109",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db5b59af5e6a4703843f95eeccce94ca",
      "value": 21
     }
    },
    "29a54a5ac7ec469385b8d4210ae5ca38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_653fbb0b52914a01829532f7a5e0859f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e99b054546bc42929687aba29b675ed3",
      "value": " 1233/1233 [00:09&lt;00:00, 136.69it/s]"
     }
    },
    "2a1176d868254285ab0bcb5d81354ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a5364d8c6e940c98b622dde8bfc6d3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aabe89dc7e74025bd11c35dcd2a58d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c41da071c8a4c59920b09161e004c24": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2edb4ad9554d4cae9c041447d9babedc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2fac6f0a80564d3494612eb1da4b633e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fe3bb50154f47c38e70f501563c4fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "314d574139464c9e96c408113fc937a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_553596b1a8b14b42aa4824ba640dd342",
       "IPY_MODEL_7d1213448dd04e0f9333c234868698d6"
      ],
      "layout": "IPY_MODEL_f415406fb038471fb8acde6052aacd3b"
     }
    },
    "3172522c8af24419a399bb17921b5074": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "31e417dadc404936bc8a10f6aefec0b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f82b4f2e1b404e7484a830a75fac2b3d",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3172522c8af24419a399bb17921b5074",
      "value": 21
     }
    },
    "326b756495a7458cb0977bc89b30f49a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32be88bb3e734feb849e0b9ab2122e08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "352ea20759b14465a07d267e41239325": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0614912bc11e41afb3aaca59bb5bc897",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0761d4f6f80b40a2b44c3a9d4a37c523",
      "value": 21
     }
    },
    "378f441ab6d143f2b2f871c5316a0509": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dc71009ee4549bf8195d659becab687": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3dd3ed71bbe94b10b160d51426455fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e194c1e27f74fcaac53956b5c2d23f4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dc71009ee4549bf8195d659becab687",
      "value": 1
     }
    },
    "4006080f11e94ef68ef60e242ff04f93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41db5c499d47415cba26b8697d5d625d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43910c49210f4ca5bc76c40d1634eb85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43b345adc4e24ed6be202f57d7cb937c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "440c95fafd9b42669ec3b65b959718af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9aa3ffdb566e42848fe407b4134690a9",
       "IPY_MODEL_74b77a1585334c52ac9874fe24fe0ec4"
      ],
      "layout": "IPY_MODEL_519f2f50dfd64fe799859f21f901ab74"
     }
    },
    "4865af1774de48b19a65d5885c9a7b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4a8acc6cc12d43afba1b2f8f38280be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66b5bb6c6d844a96b419f83a600e382e",
       "IPY_MODEL_7900c8adc13a4594853e10d2b6bac6a1"
      ],
      "layout": "IPY_MODEL_71aff620da6c4fd1b430e1bb1bcb2d9d"
     }
    },
    "4f0f924547fb4400a7397fbd01a081b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "519f2f50dfd64fe799859f21f901ab74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51f1fc397e8549b58efc04b045a7a1af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "553596b1a8b14b42aa4824ba640dd342": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6af6f38653ce484aa528d7eebead2c98",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51f1fc397e8549b58efc04b045a7a1af",
      "value": 21
     }
    },
    "55f311d50f9f470e8a67d04705ceb59c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_970b943576584f54bfcb686b4351e8ba",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a5364d8c6e940c98b622dde8bfc6d3a",
      "value": " 21/21 [00:10&lt;00:00,  1.97it/s]"
     }
    },
    "56fce9af36d24f36a4cc0ef76b070ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f832020735bb43d6a473a1946dac2e7e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7578e5eb20384debad7a59896d236dfc",
      "value": " 21/21 [00:00&lt;00:00, 70.07it/s]"
     }
    },
    "574f64422d8a42d9b96fd0235f7b7f73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a02839558f34e1e803ed700d03e268f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca6314938bc34cf8934ffe02f5f66aab",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eeabfba080444eeeb79027f4e6690ac7",
      "value": 21
     }
    },
    "60519771bbcf4e2cab050c747a6392e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a3c83016cb4def868ac7151b88d8a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "622073b8d6bf45ad8e431cc911169547": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "650e5386dc14417f9e64362f2c25a29e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27c60905265b459e8e3b46dab7ff84e5",
       "IPY_MODEL_82a56e2fc3b744b1b8fae5b8cf616a92"
      ],
      "layout": "IPY_MODEL_69fd5dd6942d4a6a8af467e48fc46ffd"
     }
    },
    "653fbb0b52914a01829532f7a5e0859f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65a457b099714e32991c04b7cf3bd70e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b11da0d4cad242a389d97248988147de",
       "IPY_MODEL_29a54a5ac7ec469385b8d4210ae5ca38"
      ],
      "layout": "IPY_MODEL_6c83d0e9abc74f448d2ed580bb0059ca"
     }
    },
    "65b127e3f63a4a55a310f48375ea47b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "660c447a80bb480e81f36ab9df519215": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60519771bbcf4e2cab050c747a6392e4",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2edb4ad9554d4cae9c041447d9babedc",
      "value": 21
     }
    },
    "66b5bb6c6d844a96b419f83a600e382e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65b127e3f63a4a55a310f48375ea47b6",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09839334122342b5b4caa30b26ec5c0b",
      "value": 21
     }
    },
    "6820314d5fdd421bbd0ab098ad7b6d97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "69fd5dd6942d4a6a8af467e48fc46ffd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a1c811760fb4cbc853e2a16539a07ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aacb5769eba4da1877b24302eae253b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6af6f38653ce484aa528d7eebead2c98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bf28b23a2404a688b5209d8906fe37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c83d0e9abc74f448d2ed580bb0059ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d3b7546ce3749e4a1d9df6dae725c14": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d5427a4009f447a9e3e775351cc1ddb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6efc1ad12e664dfc874621537d50f012": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_352ea20759b14465a07d267e41239325",
       "IPY_MODEL_cb1658bf31064250a6401ba5beeeb6c6"
      ],
      "layout": "IPY_MODEL_43b345adc4e24ed6be202f57d7cb937c"
     }
    },
    "7040ecec65a94b0c99dbb3be68fba73c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "70af28b309c54e499d53894566baf071": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eed55ce024ec4defbcf75d9b45fa1646",
       "IPY_MODEL_d62cde84a2994136a198c8399a2f8b60"
      ],
      "layout": "IPY_MODEL_6d5427a4009f447a9e3e775351cc1ddb"
     }
    },
    "712127d8a2f44648b33af907ee0a5369": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32be88bb3e734feb849e0b9ab2122e08",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6bf28b23a2404a688b5209d8906fe37c",
      "value": " 21/21 [00:34&lt;00:00,  1.63s/it]"
     }
    },
    "71aff620da6c4fd1b430e1bb1bcb2d9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74738398ade143c0af1bafcdd992c526": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b77a1585334c52ac9874fe24fe0ec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_574f64422d8a42d9b96fd0235f7b7f73",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9d996941a9de4f19a4734866a345df46",
      "value": " 21/21 [00:00&lt;00:00, 234.67it/s]"
     }
    },
    "7578e5eb20384debad7a59896d236dfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75915d5d34a24b10a752a39acc104ab6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31e417dadc404936bc8a10f6aefec0b0",
       "IPY_MODEL_d88ae53a0542444fa58c2c84fb2e6ba4"
      ],
      "layout": "IPY_MODEL_2c41da071c8a4c59920b09161e004c24"
     }
    },
    "762a0912d4b04be896cb1eefbced75ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_378f441ab6d143f2b2f871c5316a0509",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e0fae300fe54616996d7a8c57428113",
      "value": 21
     }
    },
    "7900c8adc13a4594853e10d2b6bac6a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d444b51aadf24fe6b6a81e0fece9020e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_41db5c499d47415cba26b8697d5d625d",
      "value": " 21/21 [00:46&lt;00:00,  2.19s/it]"
     }
    },
    "7a0bc724007845699743c67d8d1e931b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c27fa700103444ab85c4e7e743f82e67",
       "IPY_MODEL_99fffc50683e4440bfc4f270918d90b6"
      ],
      "layout": "IPY_MODEL_0dc3fef18a95477999010b3d48d0cfed"
     }
    },
    "7c6c7ecf234544398a0c65a9343fe5e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c81a66c1eaf473485ba1ed03668bf1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6b85d1d9f7a4e4a97ee5241c0d34de4",
       "IPY_MODEL_712127d8a2f44648b33af907ee0a5369"
      ],
      "layout": "IPY_MODEL_ae732ef2221541d7870f37e6ba7f3ebc"
     }
    },
    "7d1213448dd04e0f9333c234868698d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c1e874ab8aa4e10801bd7bb520b1402",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0ffd634a8ef047698c737716816db9d5",
      "value": " 21/21 [00:11&lt;00:00,  1.75it/s]"
     }
    },
    "7e194c1e27f74fcaac53956b5c2d23f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82588216b02f4bf9bfdae19b2d44309a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_622073b8d6bf45ad8e431cc911169547",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cdb2a58e1ab4448cb44dd97a586bc0fa",
      "value": " 21/21 [00:11&lt;00:00,  1.85it/s]"
     }
    },
    "82a56e2fc3b744b1b8fae5b8cf616a92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43910c49210f4ca5bc76c40d1634eb85",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2fac6f0a80564d3494612eb1da4b633e",
      "value": " 21/21 [00:02&lt;00:00,  7.79it/s]"
     }
    },
    "830fec76a0234999aa45a3382b79dc84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83298fe3d4a94fe89cb2d893d69fdaf3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8634a4e95d474ab6ac931a1c941f3093": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a02839558f34e1e803ed700d03e268f",
       "IPY_MODEL_82588216b02f4bf9bfdae19b2d44309a"
      ],
      "layout": "IPY_MODEL_f2f0e9d99f3a4e22815fcc60409bfe1f"
     }
    },
    "89887da8a61943e1829ccb9059ff69a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d58491d17cc4ccb8dc000febae4fafc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e0fae300fe54616996d7a8c57428113": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9184d5bf77ef4c92b1a9d8f3dcd2698e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92c341bba3bd4dc2a492f5edca87c5f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f99cc264b8e41cb8181e55830e18334",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fe912619d71f4a8aaa0ef8eb6359fc1c",
      "value": " 21/21 [00:10&lt;00:00,  1.93it/s]"
     }
    },
    "951abd488d5c4e4ebf62dcaab085caed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_660c447a80bb480e81f36ab9df519215",
       "IPY_MODEL_c843ad0c66e4438b9394cb8141047a15"
      ],
      "layout": "IPY_MODEL_2a1176d868254285ab0bcb5d81354ce0"
     }
    },
    "969b1dec7b384109bfd066f06fc7eb1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "970b943576584f54bfcb686b4351e8ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97992ef125824d62847596a0fb2db05b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99fffc50683e4440bfc4f270918d90b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e049d88fdd234c2c9ccb252dcf7f0e22",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_61a3c83016cb4def868ac7151b88d8a0",
      "value": " 21/21 [00:00&lt;00:00, 199.47it/s]"
     }
    },
    "9aa3ffdb566e42848fe407b4134690a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74738398ade143c0af1bafcdd992c526",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4865af1774de48b19a65d5885c9a7b0f",
      "value": 21
     }
    },
    "9c1e874ab8aa4e10801bd7bb520b1402": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cfee08fa5bc43e09263c235ecf952ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b572c9e1eac04a10918c8c9ef8e53b9d",
       "IPY_MODEL_1fa09044523c4d12ba6f20b5341b7ffa"
      ],
      "layout": "IPY_MODEL_830fec76a0234999aa45a3382b79dc84"
     }
    },
    "9d996941a9de4f19a4734866a345df46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f99cc264b8e41cb8181e55830e18334": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6b85d1d9f7a4e4a97ee5241c0d34de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aabe89dc7e74025bd11c35dcd2a58d9",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7040ecec65a94b0c99dbb3be68fba73c",
      "value": 21
     }
    },
    "a6d30f6bb3764891b430afa6fa0be4d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a7305bcf024a4c27bab65de63e299d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da318d4e4fcc4736a3aaf0f0a97a2965",
       "IPY_MODEL_a93d077f01df4f83922d940ed1eb3205"
      ],
      "layout": "IPY_MODEL_ef8be51b5d2b4ef7ba3bca2e4c8ca30f"
     }
    },
    "a8169e8c3cee42178fd585eeaf16f240": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93d077f01df4f83922d940ed1eb3205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01ae67cd0a9d4efeb2e20ed4a66c63d1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e2a97501720d490293c1148277502dce",
      "value": " 21/21 [01:24&lt;00:00,  4.03s/it]"
     }
    },
    "aa3b8d2e6f2348eaab7d4ba077aba51a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae732ef2221541d7870f37e6ba7f3ebc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aed49ef6598d4edf8ca15450c02f26fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b11da0d4cad242a389d97248988147de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2209049bf3c4a8d8920c86f299acded",
      "max": 1233,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_060725c9a10049aca8828560223b771e",
      "value": 1233
     }
    },
    "b2209049bf3c4a8d8920c86f299acded": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b572c9e1eac04a10918c8c9ef8e53b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_969b1dec7b384109bfd066f06fc7eb1f",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6820314d5fdd421bbd0ab098ad7b6d97",
      "value": 21
     }
    },
    "bc14e06d73de49a6b606d8bc3dcd4109": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c21ecb9244134ba9a755e70c4aa9ce60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2622d06ecacb465391ed302c213bb41d",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dbafcbad760e46259c7547254fb40422",
      "value": 21
     }
    },
    "c27fa700103444ab85c4e7e743f82e67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d3b7546ce3749e4a1d9df6dae725c14",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f005f01b4dc74a2ba012bacf349cd3b8",
      "value": 21
     }
    },
    "c843ad0c66e4438b9394cb8141047a15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_326b756495a7458cb0977bc89b30f49a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_89887da8a61943e1829ccb9059ff69a5",
      "value": " 21/21 [01:13&lt;00:00,  3.51s/it]"
     }
    },
    "c86e9997bd5d4549b1c578fb406fdb69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e2ede8aaf7d4e3ea914ea51d95e0d4d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ec2c830161e6492eaba93c492a553e67",
      "value": " 21/21 [00:00&lt;00:00, 141.71it/s]"
     }
    },
    "ca6314938bc34cf8934ffe02f5f66aab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb1658bf31064250a6401ba5beeeb6c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6197a270ca641bf874484983166d45f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_07c4ec4c40534ebc9f198b45ed4d401e",
      "value": " 21/21 [00:34&lt;00:00,  1.63s/it]"
     }
    },
    "cd1baf459a004106a2a87ee5d73661fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cdb2a58e1ab4448cb44dd97a586bc0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d444b51aadf24fe6b6a81e0fece9020e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d62cde84a2994136a198c8399a2f8b60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8169e8c3cee42178fd585eeaf16f240",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7c6c7ecf234544398a0c65a9343fe5e3",
      "value": " 21/21 [00:39&lt;00:00,  1.87s/it]"
     }
    },
    "d88ae53a0542444fa58c2c84fb2e6ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f526180e0b9e43b9aa4f312c902d79a0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e2352837cf6b4d9cba5da219b0ea9736",
      "value": " 21/21 [00:00&lt;00:00, 93.51it/s]"
     }
    },
    "da318d4e4fcc4736a3aaf0f0a97a2965": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97992ef125824d62847596a0fb2db05b",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd1baf459a004106a2a87ee5d73661fc",
      "value": 21
     }
    },
    "db5b59af5e6a4703843f95eeccce94ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dbafcbad760e46259c7547254fb40422": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "de4dcebd102f4126a2b00ff7822c33b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e049d88fdd234c2c9ccb252dcf7f0e22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0ffd983779d4b96b5feead72ca0ced1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a1c811760fb4cbc853e2a16539a07ce",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f0f924547fb4400a7397fbd01a081b0",
      "value": 21
     }
    },
    "e2352837cf6b4d9cba5da219b0ea9736": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2a97501720d490293c1148277502dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e64fcb3239d0435cb451594180983a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0696d9d321c84cb4852a979567f78d4c",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6d30f6bb3764891b430afa6fa0be4d5",
      "value": 21
     }
    },
    "e99b054546bc42929687aba29b675ed3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec2c830161e6492eaba93c492a553e67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eeabfba080444eeeb79027f4e6690ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "eed55ce024ec4defbcf75d9b45fa1646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eb035604fe243a0888e1a0809404021",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18a754719a0843e4989d90c3a81d6c00",
      "value": 21
     }
    },
    "ef8be51b5d2b4ef7ba3bca2e4c8ca30f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f005f01b4dc74a2ba012bacf349cd3b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1e0c11a0670473a9370fc6b5969b02f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0ffd983779d4b96b5feead72ca0ced1",
       "IPY_MODEL_55f311d50f9f470e8a67d04705ceb59c"
      ],
      "layout": "IPY_MODEL_2724e94a000743289da58c82f87c72fc"
     }
    },
    "f2f0e9d99f3a4e22815fcc60409bfe1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f415406fb038471fb8acde6052aacd3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f526180e0b9e43b9aa4f312c902d79a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6197a270ca641bf874484983166d45f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7b84e6242664454acaf9e0e695ad6af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f82b4f2e1b404e7484a830a75fac2b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f832020735bb43d6a473a1946dac2e7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdb6a825d3024b3faa4f9283ee10bbdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_762a0912d4b04be896cb1eefbced75ba",
       "IPY_MODEL_c86e9997bd5d4549b1c578fb406fdb69"
      ],
      "layout": "IPY_MODEL_8d58491d17cc4ccb8dc000febae4fafc"
     }
    },
    "fe912619d71f4a8aaa0ef8eb6359fc1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
